# WFV Guide

# Motivation:

##  GA + WFV Optimal Stopping Strategy

## Core Concept

Traditional genetic algorithms suffer from overfitting when run to full convergence. Instead of naive early stopping, **Optimal Stopping** uses data-driven validation to find the generation that consistently generalizes best across multiple time periods.

## The Problem with Standard GA

```
Generation 1:  [Random weights] → Fitness: 1.2
Generation 10: [Good signal]    → Fitness: 1.6
Generation 25: [Still robust]  → Fitness: 1.9
Generation 40: [Getting fitted] → Fitness: 2.3
Generation 60: [Overfit noise] → Fitness: 2.7 ← Traditional stopping point
```

**Issue:** Taking the final generation (highest training fitness) often captures noise rather than signal.

## GA + WFV Optimal Stopping Solution

### Step 1: Generation Sensitivity Analysis
For each Walk-Forward Validation window:
- Run GA to full convergence (save all generations)
- Test the **last X generations** (e.g., last 10) on validation period
- Record validation performance for each generation offset

### Step 2: Cross-Window Generation Analysis
Across all WFV windows, identify which generation offset:
- Has highest **mean validation performance**
- Shows most **consistent performance** (low standard deviation)
- Demonstrates best **generalization** (smallest train/validation gap)

### Step 3: Optimal Generation Selection
Select the generation offset that performs best across validation windows, not the final generation.

## Visual Framework

```
Training Period 1:
GA Evolution: [Gen1] → [Gen10] → [Gen20] → [Gen30] → [Convergence]
                                    ↑
Test Last 10 Gens:              [Gen21-30] → Best: Gen 25
Validation Results:              Gen25 = 1.4 Sharpe

Training Period 2:
GA Evolution: [Gen1] → [Gen10] → [Gen20] → [Gen30] → [Convergence]
                                    ↑  
Test Last 10 Gens:              [Gen21-30] → Best: Gen 26
Validation Results:              Gen26 = 1.3 Sharpe

Training Period 3:
GA Evolution: [Gen1] → [Gen10] → [Gen20] → [Gen30] → [Convergence]
                                    ↑
Test Last 10 Gens:              [Gen21-30] → Best: Gen 24
Validation Results:              Gen24 = 1.5 Sharpe

CONCLUSION: Generation ~25 (5 from end) consistently generalizes best
```

## Key Advantages

1. **Data-Driven**: Uses empirical evidence across multiple time periods
2. **Robust**: Finds generation that consistently generalizes, not just performs well once
3. **Sensitivity-Based**: Tests multiple generation candidates rather than arbitrary stopping
4. **Overfitting Protection**: Explicitly guards against taking the most overfit final generation

## Implementation Framework

1. **Run Full GA**: Let genetic algorithm converge completely on training data
2. **Test Generation Range**: Validate last 10-15 generations on held-out validation period
3. **Repeat Across Windows**: Execute this process for each walk-forward validation window
4. **Aggregate Results**: Find generation offset with best consistency across all windows
5. **Apply Optimal Stopping**: Use identified generation offset for final strategy deployment

## Why This Works

- **Signal vs Noise**: Earlier generations capture genuine market signal
- **Overfitting Progression**: Later generations increasingly fit training noise
- **Consistency Metric**: Robust generations perform well across different time periods
- **Validation-Based**: Decision based on out-of-sample performance, not training metrics

## Expected Outcome

Instead of using Generation 60 (overfit), consistently select Generation 25 (robust signal) based on empirical validation evidence across multiple time periods.

User approved Claude's plan:
  ⎿  Study-Level Directory Organization for WFV

     Enhanced CLI Arguments

     --results-dir momentum_wfv_study    # Study-level directory name
     --wfv-windows 5                     # Total WFV windows  
     --wfv-window 2                      # Execute specific window
     --phase train                       # Training or test phase
     --strategies "momentum:lookback=10,20,30"
     --parameters optimal.json           # Load selected parameters

     Improved Workspace Structure

     workspaces/
     └── momentum_wfv_study/              # Study-level directory (from --results-dir)
         ├── window_01_train/             # Window 1 training phase
         │   ├── signals/
         │   ├── generations/             # All GA generations  
         │   │   ├── gen_01.json
         │   │   ├── gen_25.json
         │   │   └── gen_50.json
         │   └── analytics.db
         ├── window_01_test/              # Window 1 test phase
         │   ├── signals/
         │   └── analytics.db
         ├── window_02_train/             # Window 2 training phase
         │   ├── signals/
         │   ├── generations/
         │   └── analytics.db
         ├── window_02_test/              # Window 2 test phase
         │   ├── signals/
         │   └── analytics.db
         ├── study_summary.json           # Cross-window analysis
         └── final_test/                  # Final held-out validation
             ├── signals/
             └── analytics.db

     Directory Auto-Generation Logic

     The system automatically creates subdirectories based on:
     - Study Name: From --results-dir momentum_wfv_study
     - Window Number: From --wfv-window 2 → window_02_
     - Phase: From --phase train → _train or _test
     - Final Result: workspaces/momentum_wfv_study/window_02_train/

     CLI Workflow Examples

     Window 1 Training

     python main.py --signal-generation \
         --strategies "momentum:lookback=10,20,30" \
         --dataset train \
         --results-dir momentum_wfv_study \
         --wfv-windows=5 --wfv-window=1 --phase=train
     Output: workspaces/momentum_wfv_study/window_01_train/

     Window 1 Testing (after manual analysis)

     python main.py --signal-generation \
         --parameters optimal_gen25_w1.json \
         --dataset train \
         --results-dir momentum_wfv_study \
         --wfv-windows=5 --wfv-window=1 --phase=test
     Output: workspaces/momentum_wfv_study/window_01_test/

     Final Validation (held-out test)

     python main.py --backtest \
         --parameters final_optimal_params.json \
         --dataset test \
         --results-dir momentum_wfv_study
     Output: workspaces/momentum_wfv_study/final_test/

     Implementation Changes

     1. Enhanced MultiStrategyTracer Workspace Logic

     def _setup_multi_strategy_tracer(self, topology, context, tracing_config):
         # Get study directory from CLI args
         results_dir = context.get('results_dir', 'default_study')
         wfv_window = context.get('wfv_window')
         phase = context.get('phase')
         
         if wfv_window and phase:
             # WFV execution: study_name/window_XX_phase/
             workspace_name = f"window_{wfv_window:02d}_{phase}"
             full_path = f"workspaces/{results_dir}/{workspace_name}"
         else:
             # Regular execution: study_name/run_unique_id/
             workspace_name = f"run_{unique_id}"
             full_path = f"workspaces/{results_dir}/{workspace_name}"

     2. Cross-Window Analysis Support

     # Study-level analysis file
     study_summary = {
         "study_name": "momentum_wfv_study",
         "windows_completed": [1, 2],
         "optimal_generations": {
             "window_01": 25,
             "window_02": 22
         },
         "performance_summary": {...}
     }

     Benefits of Study-Level Organization

     1. Clean Separation: Each study in its own directory
     2. Easy Navigation: All related WFV runs grouped together  
     3. Cross-Window Analysis: Study-level summary files
     4. Multiple Studies: Run different strategies/timeframes in parallel
     5. Archive Management: Easy to zip/backup entire studies
     6. Parameter Tracking: Clear progression of selected parameters across windows

     Multiple Study Management

     # Study 1: Momentum strategies
     python main.py --results-dir momentum_wfv_study --wfv-window=1 --phase=train

     # Study 2: Mean reversion strategies  
     python main.py --results-dir mean_reversion_study --wfv-window=1 --phase=train

     # Study 3: Multi-timeframe analysis
     python main.py --results-dir multi_tf_study --wfv-window=1 --phase=train

     This organization makes it much easier to manage multiple concurrent studies and provides clean separation of different research projects.

