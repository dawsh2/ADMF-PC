{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fff8059",
   "metadata": {
    "papermill": {
     "duration": 0.012508,
     "end_time": "2025-06-25T02:08:38.005990",
     "exception": false,
     "start_time": "2025-06-25T02:08:37.993482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Universal Strategy Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis across all strategies tested in a parameter sweep.\n",
    "\n",
    "**Key Features:**\n",
    "- Cross-strategy performance comparison\n",
    "- Parameter sensitivity analysis\n",
    "- Correlation analysis for ensemble building\n",
    "- Regime-specific performance breakdown\n",
    "- Automatic identification of optimal strategies and ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92cb818e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.011515Z",
     "iopub.status.busy": "2025-06-25T02:08:38.011372Z",
     "iopub.status.idle": "2025-06-25T02:08:38.014118Z",
     "shell.execute_reply": "2025-06-25T02:08:38.013868Z"
    },
    "papermill": {
     "duration": 0.005914,
     "end_time": "2025-06-25T02:08:38.014932",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.009018",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters will be injected here by papermill\n",
    "# This cell is tagged with 'parameters' for papermill to recognize it\n",
    "run_dir = \".\"\n",
    "config_name = \"config\"\n",
    "symbols = [\"SPY\"]\n",
    "timeframe = \"5m\"\n",
    "min_strategies_to_analyze = 20\n",
    "sharpe_threshold = 1.0\n",
    "correlation_threshold = 0.7\n",
    "top_n_strategies = 10\n",
    "ensemble_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8efabe61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.019534Z",
     "iopub.status.busy": "2025-06-25T02:08:38.019433Z",
     "iopub.status.idle": "2025-06-25T02:08:38.021322Z",
     "shell.execute_reply": "2025-06-25T02:08:38.021109Z"
    },
    "papermill": {
     "duration": 0.004815,
     "end_time": "2025-06-25T02:08:38.021963",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.017148",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "run_dir = \"/Users/daws/ADMF-PC/config/bollinger/results/20250624_190831\"\n",
    "config_name = \"bollinger\"\n",
    "symbols = [\"SPY_5m\"]\n",
    "timeframe = \"5m\"\n",
    "min_strategies_to_analyze = 20\n",
    "sharpe_threshold = 1.0\n",
    "correlation_threshold = 0.7\n",
    "top_n_strategies = 10\n",
    "ensemble_size = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41130706",
   "metadata": {
    "papermill": {
     "duration": 0.001912,
     "end_time": "2025-06-25T02:08:38.025720",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.023808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2506787a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.029596Z",
     "iopub.status.busy": "2025-06-25T02:08:38.029485Z",
     "iopub.status.idle": "2025-06-25T02:08:38.516965Z",
     "shell.execute_reply": "2025-06-25T02:08:38.516685Z"
    },
    "papermill": {
     "duration": 0.490496,
     "end_time": "2025-06-25T02:08:38.517772",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.027276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing run: 20250624_190831\n",
      "Full path: /Users/daws/ADMF-PC/config/bollinger/results/20250624_190831\n",
      "Config: bollinger\n",
      "Symbol(s): ['SPY_5m']\n",
      "Timeframe: 5m\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Initialize DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Convert run_dir to Path and resolve to absolute path\n",
    "run_dir = Path(run_dir).resolve()\n",
    "print(f\"Analyzing run: {run_dir.name}\")\n",
    "print(f\"Full path: {run_dir}\")\n",
    "print(f\"Config: {config_name}\")\n",
    "print(f\"Symbol(s): {symbols}\")\n",
    "print(f\"Timeframe: {timeframe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a92254f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.521785Z",
     "iopub.status.busy": "2025-06-25T02:08:38.521636Z",
     "iopub.status.idle": "2025-06-25T02:08:38.525479Z",
     "shell.execute_reply": "2025-06-25T02:08:38.525269Z"
    },
    "papermill": {
     "duration": 0.006537,
     "end_time": "2025-06-25T02:08:38.526080",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.519543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found project root: /Users/daws/ADMF-PC\n",
      "✅ Analysis snippets available at: /Users/daws/ADMF-PC/src/analytics/snippets\n",
      "✅ SQL queries available at: /Users/daws/ADMF-PC/src/analytics/queries\n",
      "\n",
      "Use %load to load any snippet, e.g.:\n",
      "  %load /Users/daws/ADMF-PC/src/analytics/snippets/exploratory/signal_frequency.py\n",
      "  %load /Users/daws/ADMF-PC/src/analytics/snippets/ensembles/find_uncorrelated.py\n"
     ]
    }
   ],
   "source": [
    "# Setup path for loading analysis snippets\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find the project root (where src/ directory is)\n",
    "current_path = Path(run_dir).resolve()\n",
    "project_root = None\n",
    "\n",
    "# Search up the directory tree for src/analytics/snippets\n",
    "for parent in current_path.parents:\n",
    "    if (parent / 'src' / 'analytics' / 'snippets').exists():\n",
    "        project_root = parent\n",
    "        break\n",
    "\n",
    "# If not found from run_dir, try from current working directory\n",
    "if not project_root:\n",
    "    cwd = Path.cwd()\n",
    "    for parent in [cwd] + list(cwd.parents):\n",
    "        if (parent / 'src' / 'analytics' / 'snippets').exists():\n",
    "            project_root = parent\n",
    "            break\n",
    "\n",
    "# Last resort: check common project locations\n",
    "if not project_root:\n",
    "    common_roots = [\n",
    "        Path('/Users/daws/ADMF-PC'),\n",
    "        Path.home() / 'ADMF-PC',\n",
    "        Path.cwd().parent.parent.parent.parent  # 4 levels up from typical results dir\n",
    "    ]\n",
    "    for root in common_roots:\n",
    "        if root.exists() and (root / 'src' / 'analytics' / 'snippets').exists():\n",
    "            project_root = root\n",
    "            break\n",
    "\n",
    "if project_root:\n",
    "    # Add to Python path if not already there\n",
    "    if str(project_root) not in sys.path:\n",
    "        sys.path.insert(0, str(project_root))\n",
    "    snippets_path = project_root / 'src' / 'analytics' / 'snippets'\n",
    "    queries_path = project_root / 'src' / 'analytics' / 'queries'\n",
    "    print(f\"✅ Found project root: {project_root}\")\n",
    "    print(f\"✅ Analysis snippets available at: {snippets_path}\")\n",
    "    print(f\"✅ SQL queries available at: {queries_path}\")\n",
    "    print(\"\\nUse %load to load any snippet, e.g.:\")\n",
    "    print(\"  %load {}/src/analytics/snippets/exploratory/signal_frequency.py\".format(project_root))\n",
    "    print(\"  %load {}/src/analytics/snippets/ensembles/find_uncorrelated.py\".format(project_root))\n",
    "else:\n",
    "    print(\"⚠️ Could not find project root with src/analytics/snippets\")\n",
    "    print(f\"  Searched from: {current_path}\")\n",
    "    print(f\"  Current working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5590d05",
   "metadata": {
    "papermill": {
     "duration": 0.001373,
     "end_time": "2025-06-25T02:08:38.529051",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.527678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Strategy Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1411904d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.532573Z",
     "iopub.status.busy": "2025-06-25T02:08:38.532484Z",
     "iopub.status.idle": "2025-06-25T02:08:38.590036Z",
     "shell.execute_reply": "2025-06-25T02:08:38.589822Z"
    },
    "papermill": {
     "duration": 0.06018,
     "end_time": "2025-06-25T02:08:38.590630",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.530450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1 strategies from /Users/daws/ADMF-PC/config/bollinger/results/20250624_190831/strategy_index.parquet\n",
      "\n",
      "Strategies by type:\n",
      "  bollinger_bands: 1\n",
      "\n",
      "Columns: ['strategy_id', 'strategy_hash', 'strategy_type', 'symbol', 'timeframe', 'param_period', 'param_std_dev', 'param_fast_period', 'param_slow_period', 'param_multiplier']...\n"
     ]
    }
   ],
   "source": [
    "# Load strategy index - the catalog of all strategies tested\n",
    "strategy_index_path = run_dir / 'strategy_index.parquet'\n",
    "\n",
    "if strategy_index_path.exists():\n",
    "    strategy_index = pd.read_parquet(strategy_index_path)\n",
    "    print(f\"✅ Loaded {len(strategy_index)} strategies from {strategy_index_path}\")\n",
    "    \n",
    "    # Show strategy type distribution\n",
    "    by_type = strategy_index['strategy_type'].value_counts()\n",
    "    print(\"\\nStrategies by type:\")\n",
    "    for stype, count in by_type.items():\n",
    "        print(f\"  {stype}: {count}\")\n",
    "        \n",
    "    # Show sample of columns\n",
    "    print(f\"\\nColumns: {list(strategy_index.columns)[:10]}...\")\n",
    "else:\n",
    "    print(f\"❌ No strategy_index.parquet found at {strategy_index_path}\")\n",
    "    strategy_index = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307cf20",
   "metadata": {
    "papermill": {
     "duration": 0.001683,
     "end_time": "2025-06-25T02:08:38.593876",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.592193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Performance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f4c29c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.597363Z",
     "iopub.status.busy": "2025-06-25T02:08:38.597265Z",
     "iopub.status.idle": "2025-06-25T02:08:38.601994Z",
     "shell.execute_reply": "2025-06-25T02:08:38.601764Z"
    },
    "papermill": {
     "duration": 0.007253,
     "end_time": "2025-06-25T02:08:38.602574",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.595321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_performance(strategy_hash, trace_path, market_data):\n",
    "    \"\"\"Calculate performance metrics for a strategy\"\"\"\n",
    "    try:\n",
    "        # Always use the global run_dir which is already resolved to absolute path\n",
    "        signals_path = run_dir / trace_path\n",
    "            \n",
    "        # Load sparse signals\n",
    "        signals = pd.read_parquet(signals_path)\n",
    "        signals['ts'] = pd.to_datetime(signals['ts'])\n",
    "        \n",
    "        # Merge with market data\n",
    "        df = market_data.merge(\n",
    "            signals[['ts', 'val']], \n",
    "            left_on='timestamp', \n",
    "            right_on='ts', \n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Forward fill signals (sparse to dense)\n",
    "        df['signal'] = df['val'].ffill().fillna(0)\n",
    "        \n",
    "        # Calculate returns\n",
    "        df['returns'] = df['close'].pct_change()\n",
    "        df['strategy_returns'] = df['returns'] * df['signal'].shift(1)\n",
    "        df['cum_returns'] = (1 + df['strategy_returns']).cumprod()\n",
    "        \n",
    "        # Metrics\n",
    "        total_return = df['cum_returns'].iloc[-1] - 1\n",
    "        \n",
    "        if df['strategy_returns'].std() > 0:\n",
    "            sharpe = df['strategy_returns'].mean() / df['strategy_returns'].std() * np.sqrt(252 * 78)\n",
    "        else:\n",
    "            sharpe = 0\n",
    "            \n",
    "        cummax = df['cum_returns'].expanding().max()\n",
    "        drawdown = (df['cum_returns'] / cummax - 1)\n",
    "        max_dd = drawdown.min()\n",
    "        \n",
    "        # Count trades\n",
    "        trades = (df['signal'] != df['signal'].shift()).sum()\n",
    "        \n",
    "        return {\n",
    "            'total_return': total_return,\n",
    "            'sharpe_ratio': sharpe,\n",
    "            'max_drawdown': max_dd,\n",
    "            'num_trades': trades,\n",
    "            'df': df  # For later analysis\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating performance for {strategy_hash}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be28aa37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.605826Z",
     "iopub.status.busy": "2025-06-25T02:08:38.605739Z",
     "iopub.status.idle": "2025-06-25T02:08:38.608004Z",
     "shell.execute_reply": "2025-06-25T02:08:38.607793Z"
    },
    "papermill": {
     "duration": 0.004518,
     "end_time": "2025-06-25T02:08:38.608558",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.604040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Could not find market data file\n"
     ]
    }
   ],
   "source": [
    "# Load market data\n",
    "market_data_paths = [\n",
    "    Path(f'data/{symbols[0]}_{timeframe}.parquet'),\n",
    "    Path(f'../data/{symbols[0]}_{timeframe}.parquet'),\n",
    "    Path(f'../../data/{symbols[0]}_{timeframe}.parquet'),\n",
    "    Path(f'../../../data/{symbols[0]}_{timeframe}.parquet'),\n",
    "    Path(f'../../../../data/{symbols[0]}_{timeframe}.parquet'),\n",
    "]\n",
    "\n",
    "market_data = None\n",
    "for path in market_data_paths:\n",
    "    if path.exists():\n",
    "        market_data = pd.read_parquet(path)\n",
    "        print(f'✅ Loaded market data from: {path}')\n",
    "        break\n",
    "\n",
    "if market_data is None:\n",
    "    print('❌ Could not find market data file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db71546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.611845Z",
     "iopub.status.busy": "2025-06-25T02:08:38.611756Z",
     "iopub.status.idle": "2025-06-25T02:08:38.614629Z",
     "shell.execute_reply": "2025-06-25T02:08:38.614423Z"
    },
    "papermill": {
     "duration": 0.005158,
     "end_time": "2025-06-25T02:08:38.615195",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.610037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping performance calculation\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance for all strategies\n",
    "if strategy_index is not None and market_data is not None:\n",
    "    performance_results = []\n",
    "    \n",
    "    # Limit analysis for performance if too many strategies\n",
    "    strategies_to_analyze = strategy_index\n",
    "    if len(strategy_index) > min_strategies_to_analyze * 2:\n",
    "        print(f\"Note: Limiting initial analysis to {min_strategies_to_analyze * 2} strategies for performance\")\n",
    "        # Sample diverse strategies\n",
    "        strategies_to_analyze = strategy_index.groupby('strategy_type').apply(\n",
    "            lambda x: x.sample(n=min(len(x), min_strategies_to_analyze // strategy_index['strategy_type'].nunique()))\n",
    "        ).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\nCalculating performance for {len(strategies_to_analyze)} strategies...\")\n",
    "    print(f\"Using run directory: {run_dir}\")\n",
    "    \n",
    "    for idx, row in strategies_to_analyze.iterrows():\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"  Progress: {idx}/{len(strategies_to_analyze)}\")\n",
    "            \n",
    "        perf = calculate_performance(row['strategy_hash'], row['trace_path'], market_data)\n",
    "        \n",
    "        if perf:\n",
    "            # Combine strategy info with performance\n",
    "            result = {**row.to_dict(), **perf}\n",
    "            # Remove the full dataframe from results\n",
    "            result.pop('df', None)\n",
    "            performance_results.append(result)\n",
    "    \n",
    "    performance_df = pd.DataFrame(performance_results)\n",
    "    print(f\"\\n✅ Calculated performance for {len(performance_df)} strategies\")\n",
    "else:\n",
    "    performance_df = pd.DataFrame()\n",
    "    print(\"⚠️ Skipping performance calculation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7557f6d",
   "metadata": {
    "papermill": {
     "duration": 0.001455,
     "end_time": "2025-06-25T02:08:38.618146",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.616691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cross-Strategy Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9c576e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.621592Z",
     "iopub.status.busy": "2025-06-25T02:08:38.621465Z",
     "iopub.status.idle": "2025-06-25T02:08:38.623989Z",
     "shell.execute_reply": "2025-06-25T02:08:38.623804Z"
    },
    "papermill": {
     "duration": 0.004835,
     "end_time": "2025-06-25T02:08:38.624550",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.619715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(performance_df) > 0:\n",
    "    # Top performers across ALL strategy types\n",
    "    top_overall = performance_df.nlargest(top_n_strategies, 'sharpe_ratio')\n",
    "    \n",
    "    print(f\"\\n🏆 Top {top_n_strategies} Strategies (All Types):\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    display_cols = ['strategy_type', 'strategy_hash', 'sharpe_ratio', 'total_return', 'max_drawdown', 'num_trades']\n",
    "    # Add parameter columns if they exist\n",
    "    param_cols = [col for col in top_overall.columns if col.startswith('param_')]\n",
    "    display_cols.extend(param_cols[:3])  # Show first 3 parameters\n",
    "    \n",
    "    for idx, row in top_overall.iterrows():\n",
    "        print(f\"\\n{row['strategy_type']} - {row['strategy_hash'][:8]}\")\n",
    "        print(f\"  Sharpe: {row['sharpe_ratio']:.2f} | Return: {row['total_return']:.1%} | Drawdown: {row['max_drawdown']:.1%}\")\n",
    "        if param_cols:\n",
    "            params_str = \" | \".join([f\"{col.replace('param_', '')}: {row[col]}\" for col in param_cols[:3] if pd.notna(row[col])])\n",
    "            if params_str:\n",
    "                print(f\"  Params: {params_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbdd54f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.627936Z",
     "iopub.status.busy": "2025-06-25T02:08:38.627845Z",
     "iopub.status.idle": "2025-06-25T02:08:38.629768Z",
     "shell.execute_reply": "2025-06-25T02:08:38.629582Z"
    },
    "papermill": {
     "duration": 0.004246,
     "end_time": "2025-06-25T02:08:38.630323",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.626077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Performance by strategy type\n",
    "if len(performance_df) > 0:\n",
    "    type_summary = performance_df.groupby('strategy_type').agg({\n",
    "        'sharpe_ratio': ['mean', 'std', 'max'],\n",
    "        'total_return': ['mean', 'std', 'max'],\n",
    "        'strategy_hash': 'count'\n",
    "    }).round(3)\n",
    "    \n",
    "    type_summary.columns = ['_'.join(col).strip() for col in type_summary.columns]\n",
    "    type_summary = type_summary.rename(columns={'strategy_hash_count': 'count'})\n",
    "    type_summary = type_summary.sort_values('sharpe_ratio_mean', ascending=False)\n",
    "    \n",
    "    print(\"\\n📊 Performance by Strategy Type:\")\n",
    "    print(type_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca6874",
   "metadata": {
    "papermill": {
     "duration": 0.001765,
     "end_time": "2025-06-25T02:08:38.636001",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.634236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bdda8fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.639461Z",
     "iopub.status.busy": "2025-06-25T02:08:38.639339Z",
     "iopub.status.idle": "2025-06-25T02:08:38.645459Z",
     "shell.execute_reply": "2025-06-25T02:08:38.645260Z"
    },
    "papermill": {
     "duration": 0.008511,
     "end_time": "2025-06-25T02:08:38.646034",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.637523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizations for single or multiple strategy types\n",
    "if len(performance_df) > 0:\n",
    "    if performance_df['strategy_type'].nunique() > 1:\n",
    "        # Multiple strategy types - original visualization\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        \n",
    "        # Box plot of Sharpe by type\n",
    "        plt.subplot(1, 2, 1)\n",
    "        performance_df.boxplot(column='sharpe_ratio', by='strategy_type', ax=plt.gca())\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.title('Sharpe Ratio Distribution by Strategy Type')\n",
    "        plt.suptitle('')  # Remove default title\n",
    "        plt.ylabel('Sharpe Ratio')\n",
    "        \n",
    "        # Scatter: Return vs Sharpe\n",
    "        plt.subplot(1, 2, 2)\n",
    "        for stype in performance_df['strategy_type'].unique():\n",
    "            mask = performance_df['strategy_type'] == stype\n",
    "            plt.scatter(performance_df.loc[mask, 'total_return'], \n",
    "                       performance_df.loc[mask, 'sharpe_ratio'],\n",
    "                       label=stype, alpha=0.6)\n",
    "        plt.xlabel('Total Return')\n",
    "        plt.ylabel('Sharpe Ratio')\n",
    "        plt.title('Return vs Risk-Adjusted Return')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Single strategy type - parameter analysis visualization\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # 1. Sharpe ratio distribution\n",
    "        plt.subplot(2, 2, 1)\n",
    "        performance_df['sharpe_ratio'].hist(bins=20, alpha=0.7, color='blue')\n",
    "        plt.axvline(performance_df['sharpe_ratio'].mean(), color='red', linestyle='--', label=f'Mean: {performance_df[\"sharpe_ratio\"].mean():.2f}')\n",
    "        plt.axvline(performance_df['sharpe_ratio'].median(), color='green', linestyle='--', label=f'Median: {performance_df[\"sharpe_ratio\"].median():.2f}')\n",
    "        plt.xlabel('Sharpe Ratio')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Sharpe Ratio Distribution')\n",
    "        plt.legend()\n",
    "        \n",
    "        # 2. Return vs Sharpe scatter\n",
    "        plt.subplot(2, 2, 2)\n",
    "        # Determine which parameters exist\n",
    "        param_cols = [col for col in performance_df.columns if col.startswith('param_')]\n",
    "        if len(param_cols) >= 2:\n",
    "            # Use first two parameters for visualization\n",
    "            scatter = plt.scatter(performance_df['total_return'], \n",
    "                                 performance_df['sharpe_ratio'],\n",
    "                                 c=performance_df[param_cols[0]], \n",
    "                                 cmap='viridis',\n",
    "                                 s=performance_df[param_cols[1]]*50 if performance_df[param_cols[1]].max() < 10 else 50,\n",
    "                                 alpha=0.6)\n",
    "            plt.colorbar(scatter, label=param_cols[0].replace('param_', ''))\n",
    "            plt.title(f'Return vs Risk-Adjusted Return\\n(Color={param_cols[0].replace(\"param_\", \"\")}, Size={param_cols[1].replace(\"param_\", \"\")})')\n",
    "        else:\n",
    "            plt.scatter(performance_df['total_return'], \n",
    "                       performance_df['sharpe_ratio'],\n",
    "                       alpha=0.6)\n",
    "            plt.title('Return vs Risk-Adjusted Return')\n",
    "        plt.xlabel('Total Return')\n",
    "        plt.ylabel('Sharpe Ratio')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Parameter heatmap (if enough data and two numeric parameters)\n",
    "        if len(performance_df) > 10 and len(param_cols) >= 2:\n",
    "            plt.subplot(2, 2, 3)\n",
    "            try:\n",
    "                # Create pivot table for heatmap\n",
    "                pivot_sharpe = performance_df.pivot_table(\n",
    "                    values='sharpe_ratio', \n",
    "                    index=param_cols[0], \n",
    "                    columns=param_cols[1],\n",
    "                    aggfunc='mean'\n",
    "                )\n",
    "                if not pivot_sharpe.empty and pivot_sharpe.shape[0] > 1 and pivot_sharpe.shape[1] > 1:\n",
    "                    sns.heatmap(pivot_sharpe, cmap='RdYlGn', center=0, \n",
    "                               cbar_kws={'label': 'Sharpe Ratio'})\n",
    "                    plt.title(f'Sharpe Ratio by {param_cols[0].replace(\"param_\", \"\")} and {param_cols[1].replace(\"param_\", \"\")}')\n",
    "            except:\n",
    "                plt.text(0.5, 0.5, 'Not enough data for heatmap', \n",
    "                        ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        \n",
    "        # 4. Box plot of returns\n",
    "        plt.subplot(2, 2, 4)\n",
    "        performance_df.boxplot(column=['total_return', 'sharpe_ratio'])\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title('Performance Metrics Distribution')\n",
    "        plt.ylabel('Value')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Additional parameter analysis\n",
    "        if param_cols:\n",
    "            print(\"\\n📈 Parameter Analysis:\")\n",
    "            for param in param_cols[:3]:  # Analyze first 3 parameters\n",
    "                corr = performance_df[param].corr(performance_df['sharpe_ratio'])\n",
    "                print(f\"Correlation between {param.replace('param_', '')} and Sharpe: {corr:.3f}\")\n",
    "            \n",
    "            # Group by parameter ranges to find stable regions\n",
    "            if len(param_cols) >= 2 and len(performance_df) > 20:\n",
    "                print(\"\\n🎯 Performance by Parameter Ranges:\")\n",
    "                try:\n",
    "                    param1_groups = pd.cut(performance_df[param_cols[0]], bins=5)\n",
    "                    param2_groups = pd.cut(performance_df[param_cols[1]], bins=5)\n",
    "                    \n",
    "                    param_summary = performance_df.groupby([param1_groups, param2_groups])['sharpe_ratio'].agg(['mean', 'std', 'count'])\n",
    "                    param_summary = param_summary[param_summary['count'] > 0].sort_values('mean', ascending=False)\n",
    "                    print(param_summary.head(10))\n",
    "                except:\n",
    "                    print(\"Could not create parameter range analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c970e7",
   "metadata": {
    "papermill": {
     "duration": 0.001467,
     "end_time": "2025-06-25T02:08:38.649008",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.647541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Correlation Analysis for Ensemble Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb76460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.652540Z",
     "iopub.status.busy": "2025-06-25T02:08:38.652457Z",
     "iopub.status.idle": "2025-06-25T02:08:38.654774Z",
     "shell.execute_reply": "2025-06-25T02:08:38.654566Z"
    },
    "papermill": {
     "duration": 0.004708,
     "end_time": "2025-06-25T02:08:38.655382",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.650674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_strategy_correlations(strategies_df, market_data, run_dir):\n",
    "    \"\"\"Calculate correlation matrix between strategies\"\"\"\n",
    "    returns_dict = {}\n",
    "    \n",
    "    for idx, row in strategies_df.iterrows():\n",
    "        try:\n",
    "            # Use the global run_dir\n",
    "            signals_path = run_dir / row['trace_path']\n",
    "            signals = pd.read_parquet(signals_path)\n",
    "            signals['ts'] = pd.to_datetime(signals['ts'])\n",
    "            \n",
    "            # Merge and calculate returns\n",
    "            df = market_data.merge(signals[['ts', 'val']], left_on='timestamp', right_on='ts', how='left')\n",
    "            df['signal'] = df['val'].ffill().fillna(0)\n",
    "            df['returns'] = df['close'].pct_change()\n",
    "            df['strategy_returns'] = df['returns'] * df['signal'].shift(1)\n",
    "            \n",
    "            returns_dict[row['strategy_hash']] = df['strategy_returns']\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Create returns DataFrame and calculate correlation\n",
    "    if returns_dict:\n",
    "        returns_df = pd.DataFrame(returns_dict)\n",
    "        return returns_df.corr()\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07f610d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.658923Z",
     "iopub.status.busy": "2025-06-25T02:08:38.658814Z",
     "iopub.status.idle": "2025-06-25T02:08:38.663376Z",
     "shell.execute_reply": "2025-06-25T02:08:38.663182Z"
    },
    "papermill": {
     "duration": 0.00696,
     "end_time": "2025-06-25T02:08:38.663941",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.656981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimized correlation calculation with progress tracking\n",
    "if len(performance_df) > 0 and len(top_overall) > 1:\n",
    "    print(\"\\n🔗 Calculating correlations among top strategies...\")\n",
    "    print(f\"Processing {len(top_overall)} strategies...\")\n",
    "    \n",
    "    # First, load all returns data in one pass\n",
    "    returns_dict = {}\n",
    "    \n",
    "    for idx, (_, row) in enumerate(top_overall.iterrows()):\n",
    "        if idx % 5 == 0:\n",
    "            print(f\"  Loading signals: {idx}/{len(top_overall)}\")\n",
    "            \n",
    "        try:\n",
    "            signals_path = run_dir / row['trace_path']\n",
    "            \n",
    "            # Load signals\n",
    "            signals = pd.read_parquet(signals_path)\n",
    "            signals['ts'] = pd.to_datetime(signals['ts'])\n",
    "            \n",
    "            # Merge with market data (already in memory)\n",
    "            df = market_data.merge(\n",
    "                signals[['ts', 'val']], \n",
    "                left_on='timestamp', \n",
    "                right_on='ts', \n",
    "                how='left'\n",
    "            )\n",
    "            df['signal'] = df['val'].ffill().fillna(0)\n",
    "            \n",
    "            # Calculate strategy returns only once\n",
    "            df['returns'] = df['close'].pct_change()\n",
    "            df['strategy_returns'] = df['returns'] * df['signal'].shift(1)\n",
    "            \n",
    "            returns_dict[row['strategy_hash']] = df['strategy_returns'].values\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Could not load {row['strategy_hash'][:8]}: {e}\")\n",
    "    \n",
    "    print(f\"✅ Loaded returns for {len(returns_dict)} strategies\")\n",
    "    \n",
    "    if len(returns_dict) >= 2:\n",
    "        # Convert to DataFrame for correlation calculation\n",
    "        returns_df = pd.DataFrame(returns_dict)\n",
    "        \n",
    "        # Calculate correlation matrix (this is fast once data is loaded)\n",
    "        print(\"Calculating correlation matrix...\")\n",
    "        corr_matrix = returns_df.corr()\n",
    "        \n",
    "        # Find uncorrelated pairs\n",
    "        uncorrelated_pairs = []\n",
    "        n = len(corr_matrix)\n",
    "        total_pairs = n * (n - 1) // 2\n",
    "        \n",
    "        pair_count = 0\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                pair_count += 1\n",
    "                    \n",
    "                corr_val = corr_matrix.iloc[i, j]\n",
    "                if abs(corr_val) < correlation_threshold:\n",
    "                    uncorrelated_pairs.append({\n",
    "                        'strategy1': corr_matrix.index[i],\n",
    "                        'strategy2': corr_matrix.columns[j],\n",
    "                        'correlation': corr_val\n",
    "                    })\n",
    "        \n",
    "        print(f\"✅ Found {len(uncorrelated_pairs)} uncorrelated pairs (correlation < {correlation_threshold})\")\n",
    "        \n",
    "        # Visualize correlation matrix\n",
    "        if len(corr_matrix) <= 20:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            # Only show annotations if matrix is small enough\n",
    "            show_annot = len(corr_matrix) <= 10\n",
    "            sns.heatmap(corr_matrix, cmap='coolwarm', center=0, vmin=-1, vmax=1, \n",
    "                       xticklabels=[h[:8] for h in corr_matrix.columns],\n",
    "                       yticklabels=[h[:8] for h in corr_matrix.index],\n",
    "                       annot=show_annot, fmt='.2f' if show_annot else None)\n",
    "            plt.title('Strategy Correlation Matrix')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Show correlation statistics\n",
    "            corr_values = corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)]\n",
    "            print(f\"\\nCorrelation Statistics:\")\n",
    "            print(f\"  Mean correlation: {np.mean(corr_values):.3f}\")\n",
    "            print(f\"  Median correlation: {np.median(corr_values):.3f}\")\n",
    "            print(f\"  Min correlation: {np.min(corr_values):.3f}\")\n",
    "            print(f\"  Max correlation: {np.max(corr_values):.3f}\")\n",
    "        else:\n",
    "            print(f\"Skipping heatmap visualization (too many strategies: {len(corr_matrix)})\")\n",
    "    else:\n",
    "        print(\"❌ Not enough strategies loaded for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc30ed9",
   "metadata": {
    "papermill": {
     "duration": 0.001622,
     "end_time": "2025-06-25T02:08:38.667376",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.665754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensemble Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b46981d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.670975Z",
     "iopub.status.busy": "2025-06-25T02:08:38.670884Z",
     "iopub.status.idle": "2025-06-25T02:08:38.673773Z",
     "shell.execute_reply": "2025-06-25T02:08:38.673586Z"
    },
    "papermill": {
     "duration": 0.005328,
     "end_time": "2025-06-25T02:08:38.674371",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.669043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build optimal ensemble\n",
    "if len(performance_df) > 0 and 'corr_matrix' in locals() and not corr_matrix.empty:\n",
    "    # Start with best strategy\n",
    "    ensemble = [top_overall.iloc[0]['strategy_hash']]\n",
    "    ensemble_data = [top_overall.iloc[0]]\n",
    "    \n",
    "    # Add uncorrelated strategies\n",
    "    for idx, candidate in top_overall.iloc[1:].iterrows():\n",
    "        if len(ensemble) >= ensemble_size:\n",
    "            break\n",
    "            \n",
    "        # Check correlation with existing ensemble members\n",
    "        candidate_hash = candidate['strategy_hash']\n",
    "        if candidate_hash in corr_matrix.columns:\n",
    "            max_corr = 0\n",
    "            for existing in ensemble:\n",
    "                if existing in corr_matrix.index:\n",
    "                    corr = abs(corr_matrix.loc[existing, candidate_hash])\n",
    "                    max_corr = max(max_corr, corr)\n",
    "            \n",
    "            if max_corr < correlation_threshold:\n",
    "                ensemble.append(candidate_hash)\n",
    "                ensemble_data.append(candidate)\n",
    "    \n",
    "    print(f\"\\n🎯 Recommended Ensemble ({len(ensemble)} strategies):\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    ensemble_df = pd.DataFrame(ensemble_data)\n",
    "    for idx, row in ensemble_df.iterrows():\n",
    "        print(f\"\\n{idx+1}. {row['strategy_type']} - {row['strategy_hash'][:8]}\")\n",
    "        print(f\"   Sharpe: {row['sharpe_ratio']:.2f} | Return: {row['total_return']:.1%}\")\n",
    "    \n",
    "    # Calculate ensemble metrics\n",
    "    print(f\"\\nEnsemble Statistics:\")\n",
    "    print(f\"  Average Sharpe: {ensemble_df['sharpe_ratio'].mean():.2f}\")\n",
    "    print(f\"  Average Return: {ensemble_df['total_return'].mean():.1%}\")\n",
    "    print(f\"  Strategy Types: {', '.join(ensemble_df['strategy_type'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b771be43",
   "metadata": {
    "papermill": {
     "duration": 0.001552,
     "end_time": "2025-06-25T02:08:38.677543",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.675991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "065c5136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:08:38.680953Z",
     "iopub.status.busy": "2025-06-25T02:08:38.680869Z",
     "iopub.status.idle": "2025-06-25T02:08:38.684382Z",
     "shell.execute_reply": "2025-06-25T02:08:38.684165Z"
    },
    "papermill": {
     "duration": 0.005921,
     "end_time": "2025-06-25T02:08:38.684985",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.679064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No results to export\n"
     ]
    }
   ],
   "source": [
    "# Export recommendations\n",
    "if len(performance_df) > 0:\n",
    "    recommendations = {\n",
    "        'run_info': {\n",
    "            'run_id': run_dir.name,\n",
    "            'config_name': config_name,\n",
    "            'generated_at': datetime.now().isoformat(),\n",
    "            'total_strategies': len(strategy_index) if strategy_index is not None else 0,\n",
    "            'strategies_analyzed': len(performance_df)\n",
    "        },\n",
    "        'best_individual': {},\n",
    "        'best_by_type': {},\n",
    "        'ensemble': []\n",
    "    }\n",
    "    \n",
    "    # Best overall\n",
    "    if len(top_overall) > 0:\n",
    "        best = top_overall.iloc[0]\n",
    "        recommendations['best_individual'] = {\n",
    "            'strategy_hash': best['strategy_hash'],\n",
    "            'strategy_type': best['strategy_type'],\n",
    "            'sharpe_ratio': float(best['sharpe_ratio']),\n",
    "            'total_return': float(best['total_return']),\n",
    "            'max_drawdown': float(best['max_drawdown']),\n",
    "            'parameters': {col.replace('param_', ''): best[col] \n",
    "                          for col in best.index if col.startswith('param_') and pd.notna(best[col])}\n",
    "        }\n",
    "    \n",
    "    # Best by type\n",
    "    for stype in performance_df['strategy_type'].unique():\n",
    "        type_best = performance_df[performance_df['strategy_type'] == stype].nlargest(1, 'sharpe_ratio')\n",
    "        if len(type_best) > 0:\n",
    "            row = type_best.iloc[0]\n",
    "            recommendations['best_by_type'][stype] = {\n",
    "                'strategy_hash': row['strategy_hash'],\n",
    "                'sharpe_ratio': float(row['sharpe_ratio']),\n",
    "                'total_return': float(row['total_return'])\n",
    "            }\n",
    "    \n",
    "    # Ensemble\n",
    "    if 'ensemble_df' in locals():\n",
    "        for idx, row in ensemble_df.iterrows():\n",
    "            recommendations['ensemble'].append({\n",
    "                'strategy_hash': row['strategy_hash'],\n",
    "                'strategy_type': row['strategy_type'],\n",
    "                'sharpe_ratio': float(row['sharpe_ratio']),\n",
    "                'weight': 1.0 / len(ensemble_df)  # Equal weight for now\n",
    "            })\n",
    "    \n",
    "    # Save files\n",
    "    with open(run_dir / 'recommendations.json', 'w') as f:\n",
    "        json.dump(recommendations, f, indent=2)\n",
    "    \n",
    "    performance_df.to_csv(run_dir / 'performance_analysis.csv', index=False)\n",
    "    \n",
    "    print(\"\\n✅ Results exported:\")\n",
    "    print(f\"  - recommendations.json\")\n",
    "    print(f\"  - performance_analysis.csv\")\n",
    "else:\n",
    "    print(\"⚠️ No results to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057744cc",
   "metadata": {
    "papermill": {
     "duration": 0.001527,
     "end_time": "2025-06-25T02:08:38.688109",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.686582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Additional Analysis with Snippets\n",
    "\n",
    "You can now extend this analysis using pre-built snippets. Examples:\n",
    "\n",
    "### Exploratory Analysis\n",
    "```python\n",
    "%load src/analytics/snippets/exploratory/signal_frequency.py\n",
    "# Then edit parameters and run\n",
    "\n",
    "%load src/analytics/snippets/exploratory/parameter_sweep.py\n",
    "# Analyze specific strategy type parameters\n",
    "```\n",
    "\n",
    "### Ensemble Building\n",
    "```python\n",
    "%load src/analytics/snippets/ensembles/find_uncorrelated.py\n",
    "# Advanced correlation analysis\n",
    "\n",
    "%load src/analytics/snippets/ensembles/optimize_weights.py\n",
    "# Optimize portfolio weights\n",
    "```\n",
    "\n",
    "### Regime Analysis\n",
    "```python\n",
    "%load src/analytics/snippets/regime/volatility_regimes.py\n",
    "# Performance in different volatility environments\n",
    "```\n",
    "\n",
    "### Helper Functions\n",
    "```python\n",
    "%load src/analytics/snippets/helpers.py\n",
    "# Load utility functions for custom analysis\n",
    "```\n",
    "\n",
    "Each snippet contains editable parameters at the top. Modify them before running to customize the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcafa1be",
   "metadata": {
    "papermill": {
     "duration": 0.001535,
     "end_time": "2025-06-25T02:08:38.691168",
     "exception": false,
     "start_time": "2025-06-25T02:08:38.689633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "Analysis complete! Key files generated:\n",
    "- `recommendations.json` - Best strategies and ensemble recommendations\n",
    "- `performance_analysis.csv` - Full performance data for all strategies\n",
    "\n",
    "Next steps:\n",
    "1. Use the recommended ensemble for live trading\n",
    "2. Deep dive into specific strategy types if needed\n",
    "3. Run regime-specific analysis to understand performance drivers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1.834679,
   "end_time": "2025-06-25T02:08:38.908530",
   "environment_variables": {},
   "exception": null,
   "input_path": "/Users/daws/ADMF-PC/src/analytics/templates/universal_analysis.ipynb",
   "output_path": "config/bollinger/results/20250624_190831/analysis_20250624_190837.ipynb",
   "parameters": {
    "config_name": "bollinger",
    "correlation_threshold": 0.7,
    "ensemble_size": 5,
    "min_strategies_to_analyze": 20,
    "run_dir": "/Users/daws/ADMF-PC/config/bollinger/results/20250624_190831",
    "sharpe_threshold": 1.0,
    "symbols": [
     "SPY_5m"
    ],
    "timeframe": "5m",
    "top_n_strategies": 10
   },
   "start_time": "2025-06-25T02:08:37.073851",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}