{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800b0d5e",
   "metadata": {
    "papermill": {
     "duration": 0.009511,
     "end_time": "2025-06-29T04:52:59.755298",
     "exception": false,
     "start_time": "2025-06-29T04:52:59.745787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trade & Risk Analysis Notebook\n",
    "\n",
    "This notebook analyzes trading performance through orders, fills, and position events,\n",
    "with special focus on risk management exits (stop loss, take profit, trailing stop).\n",
    "\n",
    "Key features:\n",
    "- Proper handling of LONG and SHORT positions using signal-based return calculation\n",
    "- 1 basis point round-trip execution cost included\n",
    "- Return-based metrics (position-size agnostic)\n",
    "- Validation of stop loss and take profit behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7c0579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T04:52:59.765964Z",
     "iopub.status.busy": "2025-06-29T04:52:59.765683Z",
     "iopub.status.idle": "2025-06-29T04:53:00.228171Z",
     "shell.execute_reply": "2025-06-29T04:53:00.227907Z"
    },
    "papermill": {
     "duration": 0.468243,
     "end_time": "2025-06-29T04:53:00.229088",
     "exception": false,
     "start_time": "2025-06-29T04:52:59.760845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Default execution cost\n",
    "DEFAULT_EXECUTION_COST_BPS = 1.0  # 1 basis point round-trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b160d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T04:53:00.232761Z",
     "iopub.status.busy": "2025-06-29T04:53:00.232615Z",
     "iopub.status.idle": "2025-06-29T04:53:00.234304Z",
     "shell.execute_reply": "2025-06-29T04:53:00.234083Z"
    },
    "papermill": {
     "duration": 0.003996,
     "end_time": "2025-06-29T04:53:00.234898",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.230902",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters cell for papermill\n",
    "# These values will be overridden when the notebook is executed\n",
    "\n",
    "# Path to results directory\n",
    "results_dir = '.'\n",
    "\n",
    "# Execution cost in basis points\n",
    "execution_cost_bps = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531c9493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T04:53:00.237954Z",
     "iopub.status.busy": "2025-06-29T04:53:00.237861Z",
     "iopub.status.idle": "2025-06-29T04:53:00.239517Z",
     "shell.execute_reply": "2025-06-29T04:53:00.239295Z"
    },
    "papermill": {
     "duration": 0.003894,
     "end_time": "2025-06-29T04:53:00.240123",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.236229",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "run_dir = \"/Users/daws/ADMF-PC/config/bollinger/results/20250628_215246\"\n",
    "config_name = \"bollinger\"\n",
    "symbols = [\"SPY\"]\n",
    "timeframe = \"5m\"\n",
    "min_strategies_to_analyze = 20\n",
    "sharpe_threshold = 1.0\n",
    "correlation_threshold = 0.7\n",
    "top_n_strategies = 10\n",
    "ensemble_size = 5\n",
    "calculate_all_performance = True\n",
    "performance_limit = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262616e",
   "metadata": {
    "papermill": {
     "duration": 0.001441,
     "end_time": "2025-06-29T04:53:00.242936",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.241495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Load Trace Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99c4fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T04:53:00.245907Z",
     "iopub.status.busy": "2025-06-29T04:53:00.245819Z",
     "iopub.status.idle": "2025-06-29T04:53:00.249621Z",
     "shell.execute_reply": "2025-06-29T04:53:00.249397Z"
    },
    "papermill": {
     "duration": 0.005996,
     "end_time": "2025-06-29T04:53:00.250214",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.244218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trace files: []\n"
     ]
    }
   ],
   "source": [
    "# Set the results directory\n",
    "results_dir = Path('.')  # Assumes notebook is run from results directory\n",
    "traces_dir = results_dir / 'traces'\n",
    "\n",
    "# Load all trace files\n",
    "def load_trace_files(traces_dir):\n",
    "    \"\"\"Load all trace files and return as dict of DataFrames.\"\"\"\n",
    "    traces = {}\n",
    "    \n",
    "    # Strategy signals\n",
    "    signals_path = list(traces_dir.rglob('signals/*/*.parquet'))\n",
    "    if signals_path:\n",
    "        traces['signals'] = pd.read_parquet(signals_path[0])\n",
    "        print(f\"Loaded signals: {len(traces['signals'])} records\")\n",
    "    \n",
    "    # Portfolio orders\n",
    "    orders_path = traces_dir / 'portfolio' / 'orders' / 'portfolio_orders.parquet'\n",
    "    if orders_path.exists():\n",
    "        traces['orders'] = pd.read_parquet(orders_path)\n",
    "        print(f\"Loaded orders: {len(traces['orders'])} records\")\n",
    "    \n",
    "    # Execution fills\n",
    "    fills_path = traces_dir / 'execution' / 'fills' / 'execution_fills.parquet'\n",
    "    if fills_path.exists():\n",
    "        traces['fills'] = pd.read_parquet(fills_path)\n",
    "        print(f\"Loaded fills: {len(traces['fills'])} records\")\n",
    "    \n",
    "    # Position events - Check both singular and plural forms\n",
    "    pos_open_paths = [\n",
    "        traces_dir / 'portfolio' / 'positions_open' / 'positions_open.parquet',\n",
    "        traces_dir / 'portfolio' / 'positions_open' / 'position_open.parquet',\n",
    "        traces_dir / 'portfolio' / 'position_open' / 'position_open.parquet'\n",
    "    ]\n",
    "    for path in pos_open_paths:\n",
    "        if path.exists():\n",
    "            traces['position_open'] = pd.read_parquet(path)\n",
    "            print(f\"Loaded position opens: {len(traces['position_open'])} records\")\n",
    "            break\n",
    "    \n",
    "    pos_close_paths = [\n",
    "        traces_dir / 'portfolio' / 'positions_close' / 'positions_close.parquet',\n",
    "        traces_dir / 'portfolio' / 'positions_close' / 'position_close.parquet',\n",
    "        traces_dir / 'portfolio' / 'position_close' / 'position_close.parquet'\n",
    "    ]\n",
    "    for path in pos_close_paths:\n",
    "        if path.exists():\n",
    "            traces['position_close'] = pd.read_parquet(path)\n",
    "            print(f\"Loaded position closes: {len(traces['position_close'])} records\")\n",
    "            break\n",
    "    \n",
    "    return traces\n",
    "\n",
    "traces = load_trace_files(traces_dir)\n",
    "print(f\"Loaded trace files: {list(traces.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce601ae",
   "metadata": {
    "papermill": {
     "duration": 0.001348,
     "end_time": "2025-06-29T04:53:00.252936",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.251588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parse JSON metadata for all trace types\n",
    "for trace_type, df in traces.items():\n",
    "    if 'metadata' in df.columns and len(df) > 0:\n",
    "        try:\n",
    "            # Parse metadata - handle both dict and string types\n",
    "            def safe_parse_metadata(x):\n",
    "                if pd.isna(x) or x is None:\n",
    "                    return {}\n",
    "                elif isinstance(x, dict):\n",
    "                    return x\n",
    "                elif isinstance(x, str):\n",
    "                    try:\n",
    "                        return json.loads(x)\n",
    "                    except:\n",
    "                        return {}\n",
    "                else:\n",
    "                    return {}\n",
    "            \n",
    "            metadata_parsed = df['metadata'].apply(safe_parse_metadata)\n",
    "            metadata_df = pd.DataFrame(list(metadata_parsed))\n",
    "            \n",
    "            # Add parsed columns to original dataframe\n",
    "            for col in metadata_df.columns:\n",
    "                if col not in df.columns:\n",
    "                    df[col] = metadata_df[col]\n",
    "            \n",
    "            traces[trace_type] = df  # Update with parsed data\n",
    "            print(f\"Parsed {trace_type} metadata: {list(metadata_df.columns)[:10]}...\")  # Show first 10 cols\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {trace_type} metadata: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49bbd8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T04:53:00.256560Z",
     "iopub.status.busy": "2025-06-29T04:53:00.256457Z",
     "iopub.status.idle": "2025-06-29T04:53:00.259318Z",
     "shell.execute_reply": "2025-06-29T04:53:00.259068Z"
    },
    "papermill": {
     "duration": 0.005493,
     "end_time": "2025-06-29T04:53:00.259928",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.254435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_metadata(df, col='metadata'):\n",
    "    \"\"\"Parse JSON metadata column into separate columns.\"\"\"\n",
    "    if col not in df.columns or len(df) == 0:\n",
    "        return df\n",
    "    \n",
    "    # Parse metadata (handle both JSON strings and dicts)\n",
    "    metadata_list = []\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            if pd.isna(row[col]):\n",
    "                metadata = {}\n",
    "            elif isinstance(row[col], dict):\n",
    "                metadata = row[col]\n",
    "            elif isinstance(row[col], str):\n",
    "                metadata = json.loads(row[col])\n",
    "            else:\n",
    "                metadata = {}\n",
    "            metadata_list.append(metadata)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing metadata at row {idx}: {e}\")\n",
    "            metadata_list.append({})\n",
    "    \n",
    "    # Create DataFrame from metadata\n",
    "    metadata_df = pd.DataFrame(metadata_list)\n",
    "    \n",
    "    # Combine with original, avoiding duplicate columns\n",
    "    for col in metadata_df.columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = metadata_df[col]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Parse metadata for all traces\n",
    "for key in ['orders', 'fills', 'position_open', 'position_close']:\n",
    "    if key in traces:\n",
    "        traces[key] = parse_metadata(traces[key])\n",
    "        print(f\"Parsed {key}: {len(traces[key])} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4256adb7",
   "metadata": {
    "papermill": {
     "duration": 0.001351,
     "end_time": "2025-06-29T04:53:00.262661",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.261310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Match Trades with Signal Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2556fcb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T04:53:00.265984Z",
     "iopub.status.busy": "2025-06-29T04:53:00.265879Z",
     "iopub.status.idle": "2025-06-29T04:53:00.269571Z",
     "shell.execute_reply": "2025-06-29T04:53:00.269335Z"
    },
    "papermill": {
     "duration": 0.00609,
     "end_time": "2025-06-29T04:53:00.270173",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.264083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing position open/close events\n"
     ]
    }
   ],
   "source": [
    "def match_trades_with_signals(traces):\n",
    "    \"\"\"Match position open/close events with signals to determine trade direction.\"\"\"\n",
    "    \n",
    "    if 'position_open' not in traces or 'position_close' not in traces:\n",
    "        print(\"Missing position open/close events\")\n",
    "        return None\n",
    "        \n",
    "    opens = traces['position_open']\n",
    "    closes = traces['position_close']\n",
    "    signals = traces.get('signals', pd.DataFrame())\n",
    "    \n",
    "    trades = []\n",
    "    \n",
    "    # Match each position open/close pair\n",
    "    for i in range(min(len(opens), len(closes))):\n",
    "        open_event = opens.iloc[i]\n",
    "        close_event = closes.iloc[i]\n",
    "        \n",
    "        # Find signal value at entry time\n",
    "        entry_bar = open_event['idx']\n",
    "        if len(signals) > 0:\n",
    "            # Get the most recent signal at or before entry\n",
    "            entry_signals = signals[signals['idx'] <= entry_bar]\n",
    "            signal_value = entry_signals['val'].iloc[-1] if len(entry_signals) > 0 else 1\n",
    "        else:\n",
    "            # Try to extract from metadata if available\n",
    "            signal_value = 1  # Default to LONG\n",
    "            \n",
    "        trades.append({\n",
    "            'entry_bar': open_event['idx'],\n",
    "            'exit_bar': close_event['idx'],\n",
    "            'entry_price': open_event.get('entry_price', open_event.get('px', 0)),\n",
    "            'exit_price': close_event.get('exit_price', close_event.get('px', 0)),\n",
    "            'signal_value': signal_value,\n",
    "            'direction': 'LONG' if signal_value > 0 else 'SHORT' if signal_value < 0 else 'FLAT',\n",
    "            'exit_type': close_event.get('exit_type', 'unknown'),\n",
    "            'exit_reason': close_event.get('exit_reason', ''),\n",
    "            'bars_held': close_event['idx'] - open_event['idx'],\n",
    "            'strategy_id': open_event.get('strategy_id', 'unknown')\n",
    "        })\n",
    "    \n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    print(f\"Matched {len(trades_df)} trades with signal direction\")\n",
    "    \n",
    "    # Show direction breakdown\n",
    "    if len(trades_df) > 0:\n",
    "        direction_counts = trades_df['direction'].value_counts()\n",
    "        print(\"\\nTrade directions:\")\n",
    "        for direction, count in direction_counts.items():\n",
    "            print(f\"  {direction}: {count} trades ({count/len(trades_df)*100:.1f}%)\")\n",
    "    \n",
    "    return trades_df\n",
    "\n",
    "# Match trades with signals\n",
    "trades_df = match_trades_with_signals(traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41e5a0",
   "metadata": {
    "papermill": {
     "duration": 0.001407,
     "end_time": "2025-06-29T04:53:00.273008",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.271601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Calculate Trade Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b8b723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T04:53:00.278715Z",
     "iopub.status.busy": "2025-06-29T04:53:00.278543Z",
     "iopub.status.idle": "2025-06-29T04:53:00.281331Z",
     "shell.execute_reply": "2025-06-29T04:53:00.281129Z"
    },
    "papermill": {
     "duration": 0.00521,
     "end_time": "2025-06-29T04:53:00.282018",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.276808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_trade_returns(trades_df, execution_cost_bps=DEFAULT_EXECUTION_COST_BPS):\n",
    "    \"\"\"\n",
    "    Calculate returns using signal-based formula.\n",
    "    \n",
    "    Formula: return_pct = signal_value * (exit_price - entry_price) / entry_price * 100\n",
    "    \n",
    "    This elegantly handles both LONG and SHORT positions:\n",
    "    - LONG (signal=1): Profits when exit > entry\n",
    "    - SHORT (signal=-1): Profits when exit < entry\n",
    "    \"\"\"\n",
    "    \n",
    "    if trades_df is None or len(trades_df) == 0:\n",
    "        return trades_df\n",
    "    \n",
    "    # Use the unified formula\n",
    "    trades_df['raw_return_pct'] = (\n",
    "        trades_df['signal_value'] * \n",
    "        (trades_df['exit_price'] - trades_df['entry_price']) / \n",
    "        trades_df['entry_price'] * 100\n",
    "    )\n",
    "    \n",
    "    # Apply execution costs\n",
    "    execution_cost_pct = execution_cost_bps / 100  # 1 bps = 0.01%\n",
    "    trades_df['execution_cost_pct'] = execution_cost_pct\n",
    "    trades_df['net_return_pct'] = trades_df['raw_return_pct'] - execution_cost_pct\n",
    "    \n",
    "    # Helper columns\n",
    "    trades_df['is_winner'] = trades_df['net_return_pct'] > 0\n",
    "    \n",
    "    # Calculate per-bar returns\n",
    "    trades_df['return_per_bar'] = trades_df['net_return_pct'] / trades_df['bars_held'].clip(lower=1)\n",
    "    \n",
    "    print(f\"\\nReturn calculation complete:\")\n",
    "    print(f\"  Execution cost: {execution_cost_bps} bps ({execution_cost_pct:.3f}%)\")\n",
    "    print(f\"  Average raw return: {trades_df['raw_return_pct'].mean():.3f}%\")\n",
    "    print(f\"  Average net return: {trades_df['net_return_pct'].mean():.3f}%\")\n",
    "    \n",
    "    return trades_df\n",
    "\n",
    "# Calculate returns with execution costs\n",
    "if trades_df is not None:\n",
    "    trades_df = calculate_trade_returns(trades_df)\n",
    "    \n",
    "    # Show return distribution\n",
    "    print(\"\\nReturn distribution:\")\n",
    "    print(trades_df[['direction', 'exit_type', 'raw_return_pct', 'net_return_pct']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814ec65",
   "metadata": {
    "papermill": {
     "duration": 0.001423,
     "end_time": "2025-06-29T04:53:00.284892",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.283469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Validate Risk Management Exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a47a4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T04:53:00.288601Z",
     "iopub.status.busy": "2025-06-29T04:53:00.288405Z",
     "iopub.status.idle": "2025-06-29T04:53:00.292568Z",
     "shell.execute_reply": "2025-06-29T04:53:00.292349Z"
    },
    "papermill": {
     "duration": 0.00661,
     "end_time": "2025-06-29T04:53:00.293156",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.286546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add validation for risk management exits\n",
    "def validate_risk_exits(trades_df):\n",
    "    \"\"\"Check if stops and targets are behaving correctly.\"\"\"\n",
    "    \n",
    "    if trades_df is None or len(trades_df) == 0:\n",
    "        print(\"No trades to validate\")\n",
    "        return False\n",
    "        \n",
    "    issues = []\n",
    "    \n",
    "    # Check stop losses - should have negative returns\n",
    "    stop_losses = trades_df[trades_df['exit_type'] == 'stop_loss']\n",
    "    if len(stop_losses) > 0:\n",
    "        positive_stops = stop_losses[stop_losses['net_return_pct'] > 0]\n",
    "        if len(positive_stops) > 0:\n",
    "            issues.append(f\"⚠️ {len(positive_stops)}/{len(stop_losses)} stop losses have POSITIVE returns\")\n",
    "            # Show breakdown by direction\n",
    "            for direction in ['LONG', 'SHORT']:\n",
    "                dir_positive = positive_stops[positive_stops['direction'] == direction]\n",
    "                if len(dir_positive) > 0:\n",
    "                    issues.append(f\"   - {len(dir_positive)} {direction} positions\")\n",
    "                    # Show examples\n",
    "                    for _, trade in dir_positive.head(3).iterrows():\n",
    "                        issues.append(f\"     Entry: ${trade['entry_price']:.2f} → Exit: ${trade['exit_price']:.2f} = {trade['net_return_pct']:.3f}%\")\n",
    "    \n",
    "    # Check take profits - should have positive returns\n",
    "    take_profits = trades_df[trades_df['exit_type'] == 'take_profit']\n",
    "    if len(take_profits) > 0:\n",
    "        negative_tps = take_profits[take_profits['net_return_pct'] < 0]\n",
    "        if len(negative_tps) > 0:\n",
    "            issues.append(f\"⚠️ {len(negative_tps)}/{len(take_profits)} take profits have NEGATIVE returns\")\n",
    "            for direction in ['LONG', 'SHORT']:\n",
    "                dir_negative = negative_tps[negative_tps['direction'] == direction]\n",
    "                if len(dir_negative) > 0:\n",
    "                    issues.append(f\"   - {len(dir_negative)} {direction} positions\")\n",
    "                    # Show examples\n",
    "                    for _, trade in dir_negative.head(3).iterrows():\n",
    "                        issues.append(f\"     Entry: ${trade['entry_price']:.2f} → Exit: ${trade['exit_price']:.2f} = {trade['net_return_pct']:.3f}%\")\n",
    "    \n",
    "    if issues:\n",
    "        print(\"=== VALIDATION ISSUES FOUND ===\")\n",
    "        for issue in issues:\n",
    "            print(issue)\n",
    "        print(\"\\n⚠️ These issues suggest a problem with the risk management implementation or data quality\")\n",
    "    else:\n",
    "        print(\"✅ Risk exits validated successfully:\")\n",
    "        print(f\"  - All {len(stop_losses)} stop losses show losses (as expected)\")\n",
    "        print(f\"  - All {len(take_profits)} take profits show gains (as expected)\")\n",
    "    \n",
    "    # Show exit type statistics\n",
    "    print(\"\\n=== Exit Type Statistics ===\")\n",
    "    exit_stats = trades_df.groupby('exit_type').agg({\n",
    "        'net_return_pct': ['count', 'mean', 'std', 'min', 'max'],\n",
    "        'is_winner': 'mean'\n",
    "    }).round(3)\n",
    "    print(exit_stats)\n",
    "    \n",
    "    return len(issues) == 0\n",
    "\n",
    "# Validate risk management\n",
    "if trades_df is not None:\n",
    "    validation_passed = validate_risk_exits(trades_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a459014b",
   "metadata": {
    "papermill": {
     "duration": 0.001416,
     "end_time": "2025-06-29T04:53:00.296071",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.294655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b13a0a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T04:53:00.299356Z",
     "iopub.status.busy": "2025-06-29T04:53:00.299267Z",
     "iopub.status.idle": "2025-06-29T04:53:00.304146Z",
     "shell.execute_reply": "2025-06-29T04:53:00.303941Z"
    },
    "papermill": {
     "duration": 0.007213,
     "end_time": "2025-06-29T04:53:00.304751",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.297538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate comprehensive performance metrics\n",
    "def calculate_performance_metrics(trades_df):\n",
    "    \"\"\"Calculate key performance metrics from trade returns.\"\"\"\n",
    "    \n",
    "    if trades_df is None or len(trades_df) == 0:\n",
    "        print(\"No trades to analyze\")\n",
    "        return {}\n",
    "    \n",
    "    # Basic metrics\n",
    "    total_trades = len(trades_df)\n",
    "    winners = trades_df[trades_df['net_return_pct'] > 0]\n",
    "    losers = trades_df[trades_df['net_return_pct'] < 0]\n",
    "    \n",
    "    metrics = {\n",
    "        'total_trades': total_trades,\n",
    "        'win_rate': len(winners) / total_trades * 100,\n",
    "        'avg_return_per_trade': trades_df['net_return_pct'].mean(),\n",
    "        'median_return': trades_df['net_return_pct'].median(),\n",
    "        'total_return_simple': trades_df['net_return_pct'].sum(),  # Simple sum\n",
    "        'total_return_compound': ((1 + trades_df['net_return_pct']/100).prod() - 1) * 100,  # Compounded\n",
    "        'avg_winner': winners['net_return_pct'].mean() if len(winners) > 0 else 0,\n",
    "        'avg_loser': losers['net_return_pct'].mean() if len(losers) > 0 else 0,\n",
    "        'max_win': trades_df['net_return_pct'].max(),\n",
    "        'max_loss': trades_df['net_return_pct'].min(),\n",
    "        'avg_bars_held': trades_df['bars_held'].mean(),\n",
    "        'profit_factor': abs(winners['net_return_pct'].sum() / losers['net_return_pct'].sum()) if len(losers) > 0 and losers['net_return_pct'].sum() != 0 else np.inf\n",
    "    }\n",
    "    \n",
    "    # Sharpe ratio (annualized)\n",
    "    if trades_df['net_return_pct'].std() > 0:\n",
    "        # Estimate annualization factor based on timeframe\n",
    "        # Assuming 5-minute bars: 78 bars per day, 252 trading days\n",
    "        bars_per_day = 78  # 6.5 hours * 12 bars/hour\n",
    "        total_bars = trades_df['exit_bar'].max() - trades_df['entry_bar'].min()\n",
    "        days_in_sample = total_bars / bars_per_day\n",
    "        \n",
    "        if days_in_sample > 0:\n",
    "            trades_per_day = total_trades / days_in_sample\n",
    "            annualization_factor = np.sqrt(252 * trades_per_day)\n",
    "        else:\n",
    "            annualization_factor = np.sqrt(252)\n",
    "            \n",
    "        metrics['sharpe_ratio'] = (trades_df['net_return_pct'].mean() / trades_df['net_return_pct'].std()) * annualization_factor\n",
    "    else:\n",
    "        metrics['sharpe_ratio'] = 0\n",
    "    \n",
    "    # Calculate max drawdown\n",
    "    cumulative_returns = (1 + trades_df['net_return_pct']/100).cumprod()\n",
    "    running_max = cumulative_returns.expanding().max()\n",
    "    drawdown = (cumulative_returns / running_max - 1) * 100\n",
    "    metrics['max_drawdown'] = drawdown.min()\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate and display performance metrics\n",
    "if trades_df is not None:\n",
    "    print(\"=== PERFORMANCE METRICS ===\")\n",
    "    metrics = calculate_performance_metrics(trades_df)\n",
    "    \n",
    "    print(f\"\\nTotal trades: {metrics['total_trades']}\")\n",
    "    print(f\"Win rate: {metrics['win_rate']:.1f}%\")\n",
    "    print(f\"\\nReturns:\")\n",
    "    print(f\"  Average return per trade: {metrics['avg_return_per_trade']:.3f}%\")\n",
    "    print(f\"  Total return (simple): {metrics['total_return_simple']:.2f}%\")\n",
    "    print(f\"  Total return (compound): {metrics['total_return_compound']:.2f}%\")\n",
    "    print(f\"\\nWin/Loss Analysis:\")\n",
    "    print(f\"  Average winner: {metrics['avg_winner']:.3f}%\")\n",
    "    print(f\"  Average loser: {metrics['avg_loser']:.3f}%\")\n",
    "    print(f\"  Profit factor: {metrics['profit_factor']:.2f}\")\n",
    "    print(f\"\\nRisk Metrics:\")\n",
    "    print(f\"  Sharpe ratio (annualized): {metrics['sharpe_ratio']:.2f}\")\n",
    "    print(f\"  Maximum drawdown: {metrics['max_drawdown']:.2f}%\")\n",
    "    print(f\"\\nTrade Statistics:\")\n",
    "    print(f\"  Average bars held: {metrics['avg_bars_held']:.1f}\")\n",
    "    \n",
    "    # Performance by direction\n",
    "    print(\"\\n=== Performance by Direction ===\")\n",
    "    for direction in ['LONG', 'SHORT']:\n",
    "        dir_trades = trades_df[trades_df['direction'] == direction]\n",
    "        if len(dir_trades) > 0:\n",
    "            print(f\"\\n{direction} positions ({len(dir_trades)} trades):\")\n",
    "            print(f\"  Win rate: {(dir_trades['net_return_pct'] > 0).mean()*100:.1f}%\")\n",
    "            print(f\"  Avg return: {dir_trades['net_return_pct'].mean():.3f}%\")\n",
    "            print(f\"  Total return: {dir_trades['net_return_pct'].sum():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81cd985",
   "metadata": {
    "papermill": {
     "duration": 0.001396,
     "end_time": "2025-06-29T04:53:00.307594",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.306198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf668ab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T04:53:00.310951Z",
     "iopub.status.busy": "2025-06-29T04:53:00.310837Z",
     "iopub.status.idle": "2025-06-29T04:53:00.316063Z",
     "shell.execute_reply": "2025-06-29T04:53:00.315854Z"
    },
    "papermill": {
     "duration": 0.007627,
     "end_time": "2025-06-29T04:53:00.316658",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.309031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create performance visualizations\n",
    "if trades_df is not None and len(trades_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # 1. Return distribution\n",
    "    ax = axes[0, 0]\n",
    "    ax.hist(trades_df['net_return_pct'], bins=50, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(0, color='red', linestyle='--', alpha=0.5, label='Break-even')\n",
    "    ax.axvline(trades_df['net_return_pct'].mean(), color='green', linestyle='--', label=f'Mean: {trades_df[\"net_return_pct\"].mean():.3f}%')\n",
    "    ax.set_xlabel('Return (%)')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Return Distribution')\n",
    "    ax.legend()\n",
    "    \n",
    "    # 2. Cumulative returns\n",
    "    ax = axes[0, 1]\n",
    "    cumulative_returns = (1 + trades_df['net_return_pct']/100).cumprod()\n",
    "    cumulative_pct = (cumulative_returns - 1) * 100\n",
    "    ax.plot(cumulative_pct.values, linewidth=2)\n",
    "    ax.set_xlabel('Trade Number')\n",
    "    ax.set_ylabel('Cumulative Return (%)')\n",
    "    ax.set_title('Equity Curve')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Returns by exit type\n",
    "    ax = axes[0, 2]\n",
    "    exit_types = trades_df['exit_type'].unique()\n",
    "    returns_by_exit = [trades_df[trades_df['exit_type'] == et]['net_return_pct'].values for et in exit_types]\n",
    "    ax.boxplot(returns_by_exit, labels=exit_types)\n",
    "    ax.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.set_ylabel('Return (%)')\n",
    "    ax.set_title('Returns by Exit Type')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 4. Win rate by direction\n",
    "    ax = axes[1, 0]\n",
    "    direction_stats = trades_df.groupby('direction').agg({\n",
    "        'is_winner': 'mean'\n",
    "    }) * 100\n",
    "    direction_stats.plot(kind='bar', ax=ax, legend=False)\n",
    "    ax.axhline(50, color='red', linestyle='--', alpha=0.5, label='50%')\n",
    "    ax.set_xlabel('Direction')\n",
    "    ax.set_ylabel('Win Rate (%)')\n",
    "    ax.set_title('Win Rate by Direction')\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    # 5. Trade duration distribution\n",
    "    ax = axes[1, 1]\n",
    "    ax.hist(trades_df['bars_held'], bins=30, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(trades_df['bars_held'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {trades_df[\"bars_held\"].mean():.1f} bars')\n",
    "    ax.set_xlabel('Bars Held')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Trade Duration Distribution')\n",
    "    ax.legend()\n",
    "    \n",
    "    # 6. Return vs bars held scatter\n",
    "    ax = axes[1, 2]\n",
    "    for direction in ['LONG', 'SHORT']:\n",
    "        dir_trades = trades_df[trades_df['direction'] == direction]\n",
    "        ax.scatter(dir_trades['bars_held'], dir_trades['net_return_pct'], \n",
    "                   alpha=0.5, label=direction, s=30)\n",
    "    ax.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Bars Held')\n",
    "    ax.set_ylabel('Return (%)')\n",
    "    ax.set_title('Return vs Trade Duration')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional visualization: Rolling performance\n",
    "    if len(trades_df) >= 20:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Rolling win rate\n",
    "        window = min(50, len(trades_df) // 4)\n",
    "        rolling_win_rate = trades_df['is_winner'].rolling(window).mean() * 100\n",
    "        \n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(rolling_win_rate.values, linewidth=2)\n",
    "        plt.axhline(50, color='red', linestyle='--', alpha=0.5, label='50%')\n",
    "        plt.xlabel('Trade Number')\n",
    "        plt.ylabel('Win Rate (%)')\n",
    "        plt.title(f'Rolling Win Rate ({window} trade window)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rolling average return\n",
    "        plt.subplot(2, 1, 2)\n",
    "        rolling_avg_return = trades_df['net_return_pct'].rolling(window).mean()\n",
    "        plt.plot(rolling_avg_return.values, linewidth=2)\n",
    "        plt.axhline(0, color='red', linestyle='--', alpha=0.5, label='Break-even')\n",
    "        plt.xlabel('Trade Number')\n",
    "        plt.ylabel('Average Return (%)')\n",
    "        plt.title(f'Rolling Average Return ({window} trade window)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ae395",
   "metadata": {
    "papermill": {
     "duration": 0.001724,
     "end_time": "2025-06-29T04:53:00.319894",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.318170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Order Flow Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78fb3d6",
   "metadata": {
    "papermill": {
     "duration": 0.001372,
     "end_time": "2025-06-29T04:53:00.322759",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.321387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5. Risk Exit Analysis\n",
    "Validate that stop losses and take profits are working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f285268d",
   "metadata": {
    "papermill": {
     "duration": 0.001388,
     "end_time": "2025-06-29T04:53:00.325813",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.324425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Validate risk exits\n",
    "validation_results = validate_risk_exits(trades)\n",
    "\n",
    "# Show exit type distribution\n",
    "exit_counts = trades['exit_type'].value_counts()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Exit type pie chart\n",
    "ax1.pie(exit_counts.values, labels=exit_counts.index, autopct='%1.1f%%')\n",
    "ax1.set_title('Exit Type Distribution')\n",
    "\n",
    "# Returns by exit type\n",
    "exit_returns = trades.groupby('exit_type')['net_return_pct'].agg(['mean', 'count'])\n",
    "x = range(len(exit_returns))\n",
    "ax2.bar(x, exit_returns['mean'])\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(exit_returns.index, rotation=45)\n",
    "ax2.set_ylabel('Average Return %')\n",
    "ax2.set_title('Average Return by Exit Type')\n",
    "ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Add count labels\n",
    "for i, (idx, row) in enumerate(exit_returns.iterrows()):\n",
    "    ax2.text(i, row['mean'] + 0.01, f\"n={row['count']}\", ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show validation warnings if any\n",
    "if validation_results['warnings']:\n",
    "    print(\"\\n⚠️ Risk Exit Validation Warnings:\")\n",
    "    for warning in validation_results['warnings']:\n",
    "        print(f\"  - {warning}\")\n",
    "else:\n",
    "    print(\"\\n✅ All risk exits appear to be functioning correctly\")\n",
    "\n",
    "# Show detailed stats by direction and exit type\n",
    "print(\"\\n=== Returns by Direction and Exit Type ===\")\n",
    "for direction in ['LONG', 'SHORT']:\n",
    "    dir_trades = trades[trades['direction'] == direction]\n",
    "    if len(dir_trades) > 0:\n",
    "        print(f\"\\n{direction} Positions:\")\n",
    "        exit_stats = dir_trades.groupby('exit_type')['net_return_pct'].agg(['mean', 'count'])\n",
    "        print(exit_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1063d",
   "metadata": {
    "papermill": {
     "duration": 0.001784,
     "end_time": "2025-06-29T04:53:00.328994",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.327210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6. Return Distribution Analysis\n",
    "Analyze the distribution of returns and identify outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24032a5",
   "metadata": {
    "papermill": {
     "duration": 0.001554,
     "end_time": "2025-06-29T04:53:00.332007",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.330453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Return distribution analysis\n",
    "returns = trades['net_return_pct'].values\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Return distribution histogram\n",
    "ax = axes[0, 0]\n",
    "n_bins = min(50, len(returns) // 10)\n",
    "ax.hist(returns, bins=n_bins, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "ax.axvline(x=returns.mean(), color='green', linestyle='-', alpha=0.7, label=f'Mean: {returns.mean():.3f}%')\n",
    "ax.set_xlabel('Return %')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Return Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# 2. Cumulative returns\n",
    "ax = axes[0, 1]\n",
    "cumulative_returns = (1 + returns/100).cumprod() - 1\n",
    "ax.plot(cumulative_returns * 100)\n",
    "ax.set_xlabel('Trade Number')\n",
    "ax.set_ylabel('Cumulative Return %')\n",
    "ax.set_title('Cumulative Returns')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Returns by direction\n",
    "ax = axes[1, 0]\n",
    "for direction in ['LONG', 'SHORT']:\n",
    "    dir_returns = trades[trades['direction'] == direction]['net_return_pct']\n",
    "    if len(dir_returns) > 0:\n",
    "        ax.hist(dir_returns, bins=30, alpha=0.5, label=f'{direction} (n={len(dir_returns)})', edgecolor='black')\n",
    "ax.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "ax.set_xlabel('Return %')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Returns by Direction')\n",
    "ax.legend()\n",
    "\n",
    "# 4. Q-Q plot for normality check\n",
    "ax = axes[1, 1]\n",
    "from scipy import stats\n",
    "stats.probplot(returns, dist=\"norm\", plot=ax)\n",
    "ax.set_title('Q-Q Plot (Normality Test)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\n=== Return Distribution Statistics ===\")\n",
    "print(f\"Mean: {returns.mean():.4f}%\")\n",
    "print(f\"Median: {np.median(returns):.4f}%\")\n",
    "print(f\"Std Dev: {returns.std():.4f}%\")\n",
    "print(f\"Skewness: {stats.skew(returns):.4f}\")\n",
    "print(f\"Kurtosis: {stats.kurtosis(returns):.4f}\")\n",
    "print(f\"Sharpe Ratio: {returns.mean() / returns.std() * np.sqrt(252):.4f}\")  # Annualized\n",
    "\n",
    "# Identify outliers\n",
    "q1, q3 = np.percentile(returns, [25, 75])\n",
    "iqr = q3 - q1\n",
    "outlier_threshold = 1.5 * iqr\n",
    "outliers = trades[(returns < q1 - outlier_threshold) | (returns > q3 + outlier_threshold)]\n",
    "\n",
    "if len(outliers) > 0:\n",
    "    print(f\"\\n⚠️ Found {len(outliers)} outlier trades ({len(outliers)/len(trades)*100:.1f}%):\")\n",
    "    print(outliers[['entry_time', 'exit_time', 'direction', 'net_return_pct', 'exit_type']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de74c2c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T04:53:00.335337Z",
     "iopub.status.busy": "2025-06-29T04:53:00.335239Z",
     "iopub.status.idle": "2025-06-29T04:53:00.338024Z",
     "shell.execute_reply": "2025-06-29T04:53:00.337802Z"
    },
    "papermill": {
     "duration": 0.005119,
     "end_time": "2025-06-29T04:53:00.338613",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.333494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze effectiveness of risk management\n",
    "if 'position_close' in traces and 'realized_pnl' in traces['position_close'].columns:\n",
    "    pos_close = traces['position_close']\n",
    "    \n",
    "    print(\"=== Risk Management Effectiveness ===\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_trades = len(pos_close)\n",
    "    profitable_trades = (pos_close['realized_pnl'] > 0).sum() if 'realized_pnl' in pos_close.columns else 0\n",
    "    \n",
    "    if total_trades > 0:\n",
    "        win_rate = profitable_trades / total_trades * 100\n",
    "        avg_win = pos_close[pos_close['realized_pnl'] > 0]['realized_pnl'].mean() if profitable_trades > 0 else 0\n",
    "        avg_loss = pos_close[pos_close['realized_pnl'] < 0]['realized_pnl'].mean() if (total_trades - profitable_trades) > 0 else 0\n",
    "        \n",
    "        print(f\"Total trades: {total_trades}\")\n",
    "        print(f\"Win rate: {win_rate:.1f}%\")\n",
    "        print(f\"Average win: ${avg_win:.2f}\")\n",
    "        print(f\"Average loss: ${avg_loss:.2f}\")\n",
    "        \n",
    "        if avg_loss != 0:\n",
    "            profit_factor = abs(avg_win / avg_loss)\n",
    "            print(f\"Profit factor: {profit_factor:.2f}\")\n",
    "        \n",
    "        # Analyze by exit type\n",
    "        if 'exit_type' in pos_close.columns:\n",
    "            print(\"\\nWin rate by exit type:\")\n",
    "            for exit_type, group in pos_close.groupby('exit_type'):\n",
    "                wins = (group['realized_pnl'] > 0).sum()\n",
    "                total = len(group)\n",
    "                win_pct = wins / total * 100 if total > 0 else 0\n",
    "                print(f\"  {exit_type}: {win_pct:.1f}% ({wins}/{total})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0553f5",
   "metadata": {
    "papermill": {
     "duration": 0.001456,
     "end_time": "2025-06-29T04:53:00.341540",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.340084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Summary statistics\n",
    "print(\"=== Execution Summary ===\")\n",
    "print(f\"Total orders: {len(data['orders'])}\")\n",
    "print(f\"Total fills: {len(data['fills'])}\")\n",
    "print(f\"Total trades: {len(trades)}\")\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"Total Return: {trades['net_return_pct'].sum():.2f}%\")\n",
    "print(f\"Win Rate: {(trades['net_return_pct'] > 0).mean() * 100:.1f}%\")\n",
    "print(f\"Average Return per Trade: {trades['net_return_pct'].mean():.4f}%\")\n",
    "print(f\"Best Trade: {trades['net_return_pct'].max():.4f}%\")\n",
    "print(f\"Worst Trade: {trades['net_return_pct'].min():.4f}%\")\n",
    "print(f\"\\nRisk Metrics:\")\n",
    "print(f\"Return Std Dev: {trades['net_return_pct'].std():.4f}%\")\n",
    "print(f\"Downside Deviation: {trades[trades['net_return_pct'] < 0]['net_return_pct'].std():.4f}%\")\n",
    "print(f\"Max Drawdown: {(cumulative_returns.cummax() - cumulative_returns).max() * 100:.2f}%\")\n",
    "\n",
    "# Direction breakdown\n",
    "print(f\"\\nBy Direction:\")\n",
    "for direction in ['LONG', 'SHORT']:\n",
    "    dir_trades = trades[trades['direction'] == direction]\n",
    "    if len(dir_trades) > 0:\n",
    "        print(f\"\\n{direction} ({len(dir_trades)} trades):\")\n",
    "        print(f\"  Total Return: {dir_trades['net_return_pct'].sum():.2f}%\")\n",
    "        print(f\"  Win Rate: {(dir_trades['net_return_pct'] > 0).mean() * 100:.1f}%\")\n",
    "        print(f\"  Avg Return: {dir_trades['net_return_pct'].mean():.4f}%\")\n",
    "\n",
    "# Execution cost impact\n",
    "total_exec_cost = len(trades) * execution_cost_bps / 100\n",
    "print(f\"\\nExecution Cost Impact:\")\n",
    "print(f\"Total Execution Cost: {total_exec_cost:.2f}%\")\n",
    "print(f\"Avg Cost per Trade: {execution_cost_bps / 100:.3f}%\")\n",
    "\n",
    "# Export results if needed\n",
    "output_file = f\"trade_analysis_{strategy_hash[:8]}.csv\"\n",
    "trades.to_csv(output_file, index=False)\n",
    "print(f\"\\nTrade details exported to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7d358bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T04:53:00.344976Z",
     "iopub.status.busy": "2025-06-29T04:53:00.344877Z",
     "iopub.status.idle": "2025-06-29T04:53:00.347338Z",
     "shell.execute_reply": "2025-06-29T04:53:00.347135Z"
    },
    "papermill": {
     "duration": 0.004871,
     "end_time": "2025-06-29T04:53:00.347914",
     "exception": false,
     "start_time": "2025-06-29T04:53:00.343043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY ===\n",
      "\n",
      "Data Quality:\n",
      "\n",
      "Key Findings:\n",
      "\n",
      "=== RECOMMENDATIONS ===\n",
      "1. Check for immediate re-entry after risk exits\n",
      "2. Analyze signal persistence after stop-loss exits\n",
      "3. Consider implementing a 'cooldown' period after risk exits\n",
      "4. Review risk parameters if too many stop-loss exits\n"
     ]
    }
   ],
   "source": [
    "print(\"=== SUMMARY ===\")\n",
    "print(f\"\\nData Quality:\")\n",
    "for key, df in traces.items():\n",
    "    print(f\"  {key}: {len(df)} records\")\n",
    "\n",
    "print(f\"\\nKey Findings:\")\n",
    "if 'orders' in traces and 'fills' in traces:\n",
    "    print(f\"  - Order fill rate: {len(traces['fills'])/len(traces['orders'])*100:.1f}%\")\n",
    "\n",
    "if 'position_close' in traces and 'exit_type' in traces['position_close'].columns:\n",
    "    risk_exits = traces['position_close']['exit_type'].isin(['stop_loss', 'take_profit', 'trailing_stop']).sum()\n",
    "    print(f\"  - Risk management exits: {risk_exits} ({risk_exits/len(traces['position_close'])*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATIONS ===\")\n",
    "print(\"1. Check for immediate re-entry after risk exits\")\n",
    "print(\"2. Analyze signal persistence after stop-loss exits\")\n",
    "print(\"3. Consider implementing a 'cooldown' period after risk exits\")\n",
    "print(\"4. Review risk parameters if too many stop-loss exits\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1.764706,
   "end_time": "2025-06-29T04:53:00.565539",
   "environment_variables": {},
   "exception": null,
   "input_path": "/Users/daws/ADMF-PC/src/analytics/templates/trade_analysis.ipynb",
   "output_path": "config/bollinger/results/20250628_215246/analysis_20250628_215258.ipynb",
   "parameters": {
    "calculate_all_performance": true,
    "config_name": "bollinger",
    "correlation_threshold": 0.7,
    "ensemble_size": 5,
    "min_strategies_to_analyze": 20,
    "performance_limit": 100,
    "run_dir": "/Users/daws/ADMF-PC/config/bollinger/results/20250628_215246",
    "sharpe_threshold": 1.0,
    "symbols": [
     "SPY"
    ],
    "timeframe": "5m",
    "top_n_strategies": 10
   },
   "start_time": "2025-06-29T04:52:58.800833",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}