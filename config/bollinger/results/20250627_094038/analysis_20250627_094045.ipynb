{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f68719c5",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [6]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b60f1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:40:46.276599Z",
     "iopub.status.busy": "2025-06-27T16:40:46.276264Z",
     "iopub.status.idle": "2025-06-27T16:40:46.281881Z",
     "shell.execute_reply": "2025-06-27T16:40:46.281414Z"
    },
    "papermill": {
     "duration": 0.014226,
     "end_time": "2025-06-27T16:40:46.283201",
     "exception": false,
     "start_time": "2025-06-27T16:40:46.268975",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "run_dir = \"/Users/daws/ADMF-PC/config/bollinger/results/20250627_094038\"\n",
    "config_name = \"bollinger\"\n",
    "symbols = [\"SPY\"]\n",
    "timeframe = \"5m\"\n",
    "min_strategies_to_analyze = 20\n",
    "sharpe_threshold = 1.0\n",
    "correlation_threshold = 0.7\n",
    "top_n_strategies = 10\n",
    "ensemble_size = 5\n",
    "calculate_all_performance = True\n",
    "performance_limit = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2d1d02",
   "metadata": {
    "papermill": {
     "duration": 0.002481,
     "end_time": "2025-06-27T16:40:46.288976",
     "exception": false,
     "start_time": "2025-06-27T16:40:46.286495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trade & Risk Analysis Notebook\n",
    "\n",
    "This notebook analyzes trading performance through orders, fills, and position events,\n",
    "with special focus on risk management exits (stop loss, take profit, trailing stop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90e4e5d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:40:46.294402Z",
     "iopub.status.busy": "2025-06-27T16:40:46.294227Z",
     "iopub.status.idle": "2025-06-27T16:40:46.771624Z",
     "shell.execute_reply": "2025-06-27T16:40:46.771380Z"
    },
    "papermill": {
     "duration": 0.481315,
     "end_time": "2025-06-27T16:40:46.772463",
     "exception": false,
     "start_time": "2025-06-27T16:40:46.291148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813265c",
   "metadata": {
    "papermill": {
     "duration": 0.001158,
     "end_time": "2025-06-27T16:40:46.775026",
     "exception": false,
     "start_time": "2025-06-27T16:40:46.773868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Load Trace Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2da809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:40:46.777737Z",
     "iopub.status.busy": "2025-06-27T16:40:46.777596Z",
     "iopub.status.idle": "2025-06-27T16:40:46.780974Z",
     "shell.execute_reply": "2025-06-27T16:40:46.780743Z"
    },
    "papermill": {
     "duration": 0.005437,
     "end_time": "2025-06-27T16:40:46.781551",
     "exception": false,
     "start_time": "2025-06-27T16:40:46.776114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trace files: []\n"
     ]
    }
   ],
   "source": [
    "# Set the results directory\n",
    "results_dir = Path('.')  # Assumes notebook is run from results directory\n",
    "traces_dir = results_dir / 'traces'\n",
    "\n",
    "# Load all trace files\n",
    "def load_trace_files(traces_dir):\n",
    "    \"\"\"Load all trace files and return as dict of DataFrames.\"\"\"\n",
    "    traces = {}\n",
    "    \n",
    "    # Strategy signals\n",
    "    signals_path = list(traces_dir.rglob('signals/*/*.parquet'))\n",
    "    if signals_path:\n",
    "        traces['signals'] = pd.read_parquet(signals_path[0])\n",
    "    \n",
    "    # Portfolio orders\n",
    "    orders_path = traces_dir / 'portfolio' / 'orders' / 'portfolio_orders.parquet'\n",
    "    if orders_path.exists():\n",
    "        traces['orders'] = pd.read_parquet(orders_path)\n",
    "    \n",
    "    # Execution fills\n",
    "    fills_path = traces_dir / 'execution' / 'fills' / 'execution_fills.parquet'\n",
    "    if fills_path.exists():\n",
    "        traces['fills'] = pd.read_parquet(fills_path)\n",
    "    \n",
    "    # Position events\n",
    "    pos_open_path = traces_dir / 'portfolio' / 'positions_open' / 'position_open.parquet'\n",
    "    if pos_open_path.exists():\n",
    "        traces['position_open'] = pd.read_parquet(pos_open_path)\n",
    "    \n",
    "    pos_close_path = traces_dir / 'portfolio' / 'positions_close' / 'position_close.parquet'\n",
    "    if pos_close_path.exists():\n",
    "        traces['position_close'] = pd.read_parquet(pos_close_path)\n",
    "    \n",
    "    return traces\n",
    "\n",
    "traces = load_trace_files(traces_dir)\n",
    "print(f\"Loaded trace files: {list(traces.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bfd56c",
   "metadata": {
    "papermill": {
     "duration": 0.001375,
     "end_time": "2025-06-27T16:40:46.784169",
     "exception": false,
     "start_time": "2025-06-27T16:40:46.782794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Parse Metadata and Build Trade Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1fc5c94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:40:46.787090Z",
     "iopub.status.busy": "2025-06-27T16:40:46.786988Z",
     "iopub.status.idle": "2025-06-27T16:40:46.789475Z",
     "shell.execute_reply": "2025-06-27T16:40:46.789244Z"
    },
    "papermill": {
     "duration": 0.004653,
     "end_time": "2025-06-27T16:40:46.790068",
     "exception": false,
     "start_time": "2025-06-27T16:40:46.785415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_metadata(df, col='metadata'):\n",
    "    \"\"\"Parse JSON metadata column into separate columns.\"\"\"\n",
    "    if col not in df.columns or len(df) == 0:\n",
    "        return df\n",
    "    \n",
    "    # Parse JSON metadata\n",
    "    metadata_list = []\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            metadata = json.loads(row[col]) if row[col] else {}\n",
    "            metadata_list.append(metadata)\n",
    "        except:\n",
    "            metadata_list.append({})\n",
    "    \n",
    "    # Create DataFrame from metadata\n",
    "    metadata_df = pd.DataFrame(metadata_list)\n",
    "    \n",
    "    # Combine with original, avoiding duplicate columns\n",
    "    for col in metadata_df.columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = metadata_df[col]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Parse metadata for all traces\n",
    "for key in ['orders', 'fills', 'position_open', 'position_close']:\n",
    "    if key in traces:\n",
    "        traces[key] = parse_metadata(traces[key])\n",
    "        print(f\"Parsed {key}: {len(traces[key])} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e4bdf6",
   "metadata": {
    "papermill": {
     "duration": 0.001171,
     "end_time": "2025-06-27T16:40:46.792496",
     "exception": false,
     "start_time": "2025-06-27T16:40:46.791325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Reconstruct Complete Trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b657d023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:40:46.795654Z",
     "iopub.status.busy": "2025-06-27T16:40:46.795559Z",
     "iopub.status.idle": "2025-06-27T16:40:46.799825Z",
     "shell.execute_reply": "2025-06-27T16:40:46.799621Z"
    },
    "papermill": {
     "duration": 0.006335,
     "end_time": "2025-06-27T16:40:46.800404",
     "exception": false,
     "start_time": "2025-06-27T16:40:46.794069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed 0 trades\n"
     ]
    }
   ],
   "source": [
    "def reconstruct_trades(traces):\n",
    "    \"\"\"Reconstruct complete trades from orders, fills, and position events.\"\"\"\n",
    "    trades = []\n",
    "    \n",
    "    # Match orders with fills\n",
    "    if 'orders' in traces and 'fills' in traces:\n",
    "        orders_df = traces['orders'].copy()\n",
    "        fills_df = traces['fills'].copy()\n",
    "        \n",
    "        # Add order index for matching\n",
    "        orders_df['order_idx'] = range(len(orders_df))\n",
    "        fills_df['fill_idx'] = range(len(fills_df))\n",
    "        \n",
    "        # Simple matching by bar index (assumes 1:1 order:fill)\n",
    "        for i, (_, order) in enumerate(orders_df.iterrows()):\n",
    "            if i < len(fills_df):\n",
    "                fill = fills_df.iloc[i]\n",
    "                \n",
    "                trade = {\n",
    "                    'order_idx': order['idx'],\n",
    "                    'fill_idx': fill['idx'],\n",
    "                    'symbol': order.get('symbol', 'UNKNOWN'),\n",
    "                    'side': order.get('side', 'UNKNOWN'),\n",
    "                    'quantity': order.get('quantity', 0),\n",
    "                    'order_price': order.get('price', 0),\n",
    "                    'fill_price': fill.get('price', 0),\n",
    "                    'order_time': order['ts'],\n",
    "                    'fill_time': fill['ts'],\n",
    "                    'strategy_id': order.get('strategy_id', 'unknown')\n",
    "                }\n",
    "                trades.append(trade)\n",
    "    \n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    \n",
    "    # Add position events if available\n",
    "    if 'position_open' in traces and 'position_close' in traces:\n",
    "        # Match trades with position events\n",
    "        # This is simplified - in reality would need more sophisticated matching\n",
    "        pos_open = traces['position_open']\n",
    "        pos_close = traces['position_close']\n",
    "        \n",
    "        if len(pos_open) > 0 and len(pos_close) > 0:\n",
    "            # Add exit information to trades\n",
    "            for i, close_event in pos_close.iterrows():\n",
    "                exit_type = close_event.get('exit_type', 'unknown')\n",
    "                exit_reason = close_event.get('exit_reason', 'unknown')\n",
    "                if i < len(trades_df):\n",
    "                    trades_df.loc[trades_df.index[i], 'exit_type'] = exit_type\n",
    "                    trades_df.loc[trades_df.index[i], 'exit_reason'] = exit_reason\n",
    "    \n",
    "    return trades_df\n",
    "\n",
    "trades_df = reconstruct_trades(traces)\n",
    "print(f\"Reconstructed {len(trades_df)} trades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c28a45",
   "metadata": {
    "papermill": {
     "duration": 0.001257,
     "end_time": "2025-06-27T16:40:46.802943",
     "exception": false,
     "start_time": "2025-06-27T16:40:46.801686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Analyze Risk Management Exits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b936010",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c8a17d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T16:40:46.805832Z",
     "iopub.status.busy": "2025-06-27T16:40:46.805725Z",
     "iopub.status.idle": "2025-06-27T16:40:46.808071Z",
     "shell.execute_reply": "2025-06-27T16:40:46.807730Z"
    },
    "papermill": {
     "duration": 0.004396,
     "end_time": "2025-06-27T16:40:46.808594",
     "exception": true,
     "start_time": "2025-06-27T16:40:46.804198",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 11) (3970604835.py, line 11)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 11)\n"
     ]
    }
   ],
   "source": [
    "# Analyze position close events for risk exits\n",
    "if 'position_close' in traces:\n",
    "    pos_close = traces['position_close']\n",
    "    \n",
    "    print(\"=== Risk Management Exit Analysis ===\")\n",
    "    print(f\"Total positions closed: {len(pos_close)}\")\n",
    "    \n",
    "    # Count exit types\n",
    "    if 'exit_type' in pos_close.columns:\n",
    "        exit_counts = pos_close['exit_type'].value_counts()\n",
    "        print(\"\n",
    "Exit types:\")\n",
    "        for exit_type, count in exit_counts.items():\n",
    "            print(f\"  {exit_type}: {count} ({count/len(pos_close)*100:.1f}%)\")\n",
    "    \n",
    "    # Analyze exit reasons\n",
    "    if 'exit_reason' in pos_close.columns:\n",
    "        print(\"\n",
    "Exit reasons:\")\n",
    "        for i, row in pos_close.iterrows():\n",
    "            print(f\"  Trade {i+1}: {row.get('exit_type', 'unknown')} - {row.get('exit_reason', 'unknown')}\")\n",
    "            if hasattr(row, 'realized_pnl'):\n",
    "                print(f\"    PnL: ${row['realized_pnl']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ecd049",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5. Signal vs Position Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feed448",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze signal persistence after risk exits\n",
    "if 'signals' in traces and 'position_close' in traces:\n",
    "    signals_df = traces['signals']\n",
    "    pos_close = traces['position_close']\n",
    "    \n",
    "    print(\"=== Signal Persistence After Risk Exits ===\")\n",
    "    \n",
    "    # For each position close due to risk\n",
    "    risk_closes = pos_close[pos_close.get('exit_type', '').isin(['stop_loss', 'trailing_stop'])] if 'exit_type' in pos_close.columns else pd.DataFrame()\n",
    "    \n",
    "    if len(risk_closes) > 0:\n",
    "        for _, close_event in risk_closes.iterrows():\n",
    "            close_bar = close_event['idx']\n",
    "            \n",
    "            # Check signal value at close and next few bars\n",
    "            next_signals = signals_df[signals_df['idx'].between(close_bar, close_bar + 10)]\n",
    "            \n",
    "            if len(next_signals) > 0:\n",
    "                print(f\"\n",
    "Risk exit at bar {close_bar}:\")\n",
    "                print(f\"  Exit type: {close_event.get('exit_type', 'unknown')}\")\n",
    "                print(f\"  Signal values after exit:\")\n",
    "                for _, sig in next_signals.iterrows():\n",
    "                    print(f\"    Bar {sig['idx']}: signal = {sig['val']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887f884",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6. Performance Metrics by Exit Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498c5a9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate performance metrics grouped by exit type\n",
    "if 'position_close' in traces and 'realized_pnl' in traces['position_close'].columns:\n",
    "    pos_close = traces['position_close']\n",
    "    \n",
    "    # Group by exit type\n",
    "    if 'exit_type' in pos_close.columns:\n",
    "        metrics_by_exit = pos_close.groupby('exit_type').agg({\n",
    "            'realized_pnl': ['count', 'sum', 'mean', 'std'],\n",
    "            'idx': ['min', 'max']  # First and last bar\n",
    "        }).round(2)\n",
    "        \n",
    "        print(\"=== Performance by Exit Type ===\")\n",
    "        print(metrics_by_exit)\n",
    "        \n",
    "        # Visualize\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Count by exit type\n",
    "        exit_counts = pos_close['exit_type'].value_counts()\n",
    "        exit_counts.plot(kind='bar', ax=ax1, title='Number of Exits by Type')\n",
    "        ax1.set_xlabel('Exit Type')\n",
    "        ax1.set_ylabel('Count')\n",
    "        \n",
    "        # PnL by exit type\n",
    "        pos_close.boxplot(column='realized_pnl', by='exit_type', ax=ax2)\n",
    "        ax2.set_title('PnL Distribution by Exit Type')\n",
    "        ax2.set_xlabel('Exit Type')\n",
    "        ax2.set_ylabel('Realized PnL ($)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5068eee0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7. Trade Duration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a21489",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze trade durations\n",
    "if 'position_open' in traces and 'position_close' in traces:\n",
    "    pos_open = traces['position_open']\n",
    "    pos_close = traces['position_close']\n",
    "    \n",
    "    if len(pos_open) > 0 and len(pos_close) > 0:\n",
    "        # Calculate trade durations (simplified - assumes matching order)\n",
    "        durations = []\n",
    "        for i in range(min(len(pos_open), len(pos_close))):\n",
    "            open_bar = pos_open.iloc[i]['idx']\n",
    "            close_bar = pos_close.iloc[i]['idx']\n",
    "            duration = close_bar - open_bar\n",
    "            exit_type = pos_close.iloc[i].get('exit_type', 'unknown')\n",
    "            \n",
    "            durations.append({\n",
    "                'duration_bars': duration,\n",
    "                'exit_type': exit_type,\n",
    "                'pnl': pos_close.iloc[i].get('realized_pnl', 0)\n",
    "            })\n",
    "        \n",
    "        duration_df = pd.DataFrame(durations)\n",
    "        \n",
    "        print(\"=== Trade Duration Analysis ===\")\n",
    "        print(f\"Average duration: {duration_df['duration_bars'].mean():.1f} bars\")\n",
    "        print(f\"Median duration: {duration_df['duration_bars'].median():.1f} bars\")\n",
    "        \n",
    "        # Duration by exit type\n",
    "        if 'exit_type' in duration_df.columns:\n",
    "            print(\"\n",
    "Average duration by exit type:\")\n",
    "            for exit_type, group in duration_df.groupby('exit_type'):\n",
    "                print(f\"  {exit_type}: {group['duration_bars'].mean():.1f} bars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1fd93c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 8. Order Flow Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2c356",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze order patterns\n",
    "if 'orders' in traces:\n",
    "    orders_df = traces['orders']\n",
    "    \n",
    "    print(\"=== Order Flow Analysis ===\")\n",
    "    print(f\"Total orders: {len(orders_df)}\")\n",
    "    \n",
    "    # Order frequency\n",
    "    if len(orders_df) > 1:\n",
    "        order_gaps = orders_df['idx'].diff().dropna()\n",
    "        print(f\"\n",
    "Average bars between orders: {order_gaps.mean():.1f}\")\n",
    "        print(f\"Median bars between orders: {order_gaps.median():.1f}\")\n",
    "        \n",
    "        # Check for immediate re-entry after exit\n",
    "        immediate_reentries = (order_gaps <= 1).sum()\n",
    "        print(f\"\n",
    "Immediate re-entries (â‰¤1 bar): {immediate_reentries}\")\n",
    "        \n",
    "        # Visualize order frequency\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(order_gaps, bins=50, edgecolor='black', alpha=0.7)\n",
    "        plt.xlabel('Bars Between Orders')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Distribution of Time Between Orders')\n",
    "        plt.axvline(order_gaps.mean(), color='red', linestyle='--', label=f'Mean: {order_gaps.mean():.1f}')\n",
    "        plt.axvline(order_gaps.median(), color='green', linestyle='--', label=f'Median: {order_gaps.median():.1f}')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e868a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 9. Risk Management Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707a5d8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze effectiveness of risk management\n",
    "if 'position_close' in traces and 'realized_pnl' in traces['position_close'].columns:\n",
    "    pos_close = traces['position_close']\n",
    "    \n",
    "    print(\"=== Risk Management Effectiveness ===\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_trades = len(pos_close)\n",
    "    profitable_trades = (pos_close['realized_pnl'] > 0).sum() if 'realized_pnl' in pos_close.columns else 0\n",
    "    \n",
    "    if total_trades > 0:\n",
    "        win_rate = profitable_trades / total_trades * 100\n",
    "        avg_win = pos_close[pos_close['realized_pnl'] > 0]['realized_pnl'].mean() if profitable_trades > 0 else 0\n",
    "        avg_loss = pos_close[pos_close['realized_pnl'] < 0]['realized_pnl'].mean() if (total_trades - profitable_trades) > 0 else 0\n",
    "        \n",
    "        print(f\"Total trades: {total_trades}\")\n",
    "        print(f\"Win rate: {win_rate:.1f}%\")\n",
    "        print(f\"Average win: ${avg_win:.2f}\")\n",
    "        print(f\"Average loss: ${avg_loss:.2f}\")\n",
    "        \n",
    "        if avg_loss != 0:\n",
    "            profit_factor = abs(avg_win / avg_loss)\n",
    "            print(f\"Profit factor: {profit_factor:.2f}\")\n",
    "        \n",
    "        # Analyze by exit type\n",
    "        if 'exit_type' in pos_close.columns:\n",
    "            print(\"\n",
    "Win rate by exit type:\")\n",
    "            for exit_type, group in pos_close.groupby('exit_type'):\n",
    "                wins = (group['realized_pnl'] > 0).sum()\n",
    "                total = len(group)\n",
    "                win_pct = wins / total * 100 if total > 0 else 0\n",
    "                print(f\"  {exit_type}: {win_pct:.1f}% ({wins}/{total})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353c301",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 10. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6392633",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"=== SUMMARY ===\")\n",
    "print(f\"\n",
    "Data Quality:\")\n",
    "for key, df in traces.items():\n",
    "    print(f\"  {key}: {len(df)} records\")\n",
    "\n",
    "print(f\"\n",
    "Key Findings:\")\n",
    "if 'orders' in traces and 'fills' in traces:\n",
    "    print(f\"  - Order fill rate: {len(traces['fills'])/len(traces['orders'])*100:.1f}%\")\n",
    "\n",
    "if 'position_close' in traces and 'exit_type' in traces['position_close'].columns:\n",
    "    risk_exits = traces['position_close']['exit_type'].isin(['stop_loss', 'take_profit', 'trailing_stop']).sum()\n",
    "    print(f\"  - Risk management exits: {risk_exits} ({risk_exits/len(traces['position_close'])*100:.1f}%)\")\n",
    "\n",
    "print(\"\n",
    "=== RECOMMENDATIONS ===\")\n",
    "print(\"1. Check for immediate re-entry after risk exits\")\n",
    "print(\"2. Analyze signal persistence after stop-loss exits\")\n",
    "print(\"3. Consider implementing a 'cooldown' period after risk exits\")\n",
    "print(\"4. Review risk parameters if too many stop-loss exits\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1.464563,
   "end_time": "2025-06-27T16:40:47.026616",
   "environment_variables": {},
   "exception": true,
   "input_path": "/Users/daws/ADMF-PC/src/analytics/templates/trade_analysis.ipynb",
   "output_path": "config/bollinger/results/20250627_094038/analysis_20250627_094045.ipynb",
   "parameters": {
    "calculate_all_performance": true,
    "config_name": "bollinger",
    "correlation_threshold": 0.7,
    "ensemble_size": 5,
    "min_strategies_to_analyze": 20,
    "performance_limit": 100,
    "run_dir": "/Users/daws/ADMF-PC/config/bollinger/results/20250627_094038",
    "sharpe_threshold": 1.0,
    "symbols": [
     "SPY"
    ],
    "timeframe": "5m",
    "top_n_strategies": 10
   },
   "start_time": "2025-06-27T16:40:45.562053",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}