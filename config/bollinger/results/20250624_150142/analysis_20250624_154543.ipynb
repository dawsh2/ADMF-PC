{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Strategy Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis across all strategies tested in a parameter sweep.\n",
    "\n",
    "**Key Features:**\n",
    "- Cross-strategy performance comparison\n",
    "- Parameter sensitivity analysis\n",
    "- Correlation analysis for ensemble building\n",
    "- Regime-specific performance breakdown\n",
    "- Automatic identification of optimal strategies and ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc761ca",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (auto-generated)\n",
    "run_dir = '/Users/daws/ADMF-PC/config/bollinger/results/20250624_150142'\n",
    "config_name = 'unnamed'\n",
    "symbols = ['SPY']\n",
    "timeframe = '5m'\n",
    "min_strategies_to_analyze = 20\n",
    "sharpe_threshold = 1.0\n",
    "correlation_threshold = 0.7\n",
    "top_n_strategies = 10\n",
    "ensemble_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "run_dir = \"/path/to/results/run_20250623_143030\"\n",
    "config_name = \"my_sweep\"\n",
    "symbols = [\"SPY\"]\n",
    "timeframe = \"5m\"\n",
    "min_strategies_to_analyze = 20\n",
    "sharpe_threshold = 1.0\n",
    "correlation_threshold = 0.7\n",
    "top_n_strategies = 10\n",
    "ensemble_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Initialize DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Convert run_dir to Path\n",
    "run_dir = Path(run_dir)\n",
    "print(f\"Analyzing run: {run_dir.name}\")\n",
    "print(f\"Config: {config_name}\")\n",
    "print(f\"Symbol(s): {symbols}\")\n",
    "print(f\"Timeframe: {timeframe}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path for loading analysis snippets\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find the project root (where src/ directory is)\n",
    "current_path = Path(run_dir).resolve()\n",
    "project_root = None\n",
    "\n",
    "# Search up the directory tree for src/analytics/snippets\n",
    "for parent in current_path.parents:\n",
    "    if (parent / 'src' / 'analytics' / 'snippets').exists():\n",
    "        project_root = parent\n",
    "        break\n",
    "\n",
    "if project_root:\n",
    "    # Add to Python path if not already there\n",
    "    if str(project_root) not in sys.path:\n",
    "        sys.path.insert(0, str(project_root))\n",
    "    snippets_path = project_root / 'src' / 'analytics' / 'snippets'\n",
    "    queries_path = project_root / 'src' / 'analytics' / 'queries'\n",
    "    print(f\"✅ Analysis snippets available at: {snippets_path}\")\n",
    "    print(f\"✅ SQL queries available at: {queries_path}\")\n",
    "    print(\"\\nUse %load to load any snippet, e.g.:\")\n",
    "    print(\"  %load src/analytics/snippets/exploratory/signal_frequency.py\")\n",
    "    print(\"  %load src/analytics/snippets/ensembles/find_uncorrelated.py\")\n",
    "else:\n",
    "    print(\"⚠️ Could not find project root with src/analytics/snippets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Strategy Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load strategy index - the catalog of all strategies tested\n",
    "strategy_index_path = run_dir / 'strategy_index.parquet'\n",
    "\n",
    "if strategy_index_path.exists():\n",
    "    strategy_index = pd.read_parquet(strategy_index_path)\n",
    "    print(f\"✅ Loaded {len(strategy_index)} strategies\")\n",
    "    \n",
    "    # Show strategy type distribution\n",
    "    by_type = strategy_index['strategy_type'].value_counts()\n",
    "    print(\"\\nStrategies by type:\")\n",
    "    for stype, count in by_type.items():\n",
    "        print(f\"  {stype}: {count}\")\n",
    "else:\n",
    "    # Fallback for legacy format\n",
    "    print(\"⚠️ No strategy_index.parquet found, using legacy format\")\n",
    "    strategy_index = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(strategy_hash, trace_path, market_data):\n",
    "    \"\"\"Calculate performance metrics for a strategy\"\"\"\n",
    "    try:\n",
    "        # Load sparse signals\n",
    "        signals = pd.read_parquet(run_dir / trace_path)\n",
    "        signals['ts'] = pd.to_datetime(signals['ts'])\n",
    "        \n",
    "        # Merge with market data\n",
    "        df = market_data.merge(\n",
    "            signals[['ts', 'val']], \n",
    "            left_on='timestamp', \n",
    "            right_on='ts', \n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Forward fill signals (sparse to dense)\n",
    "        df['signal'] = df['val'].fillna(method='ffill').fillna(0)\n",
    "        \n",
    "        # Calculate returns\n",
    "        df['returns'] = df['close'].pct_change()\n",
    "        df['strategy_returns'] = df['returns'] * df['signal'].shift(1)\n",
    "        df['cum_returns'] = (1 + df['strategy_returns']).cumprod()\n",
    "        \n",
    "        # Metrics\n",
    "        total_return = df['cum_returns'].iloc[-1] - 1\n",
    "        \n",
    "        if df['strategy_returns'].std() > 0:\n",
    "            sharpe = df['strategy_returns'].mean() / df['strategy_returns'].std() * np.sqrt(252 * 78)\n",
    "        else:\n",
    "            sharpe = 0\n",
    "            \n",
    "        cummax = df['cum_returns'].expanding().max()\n",
    "        drawdown = (df['cum_returns'] / cummax - 1)\n",
    "        max_dd = drawdown.min()\n",
    "        \n",
    "        # Count trades\n",
    "        trades = (df['signal'] != df['signal'].shift()).sum()\n",
    "        \n",
    "        return {\n",
    "            'total_return': total_return,\n",
    "            'sharpe_ratio': sharpe,\n",
    "            'max_drawdown': max_dd,\n",
    "            'num_trades': trades,\n",
    "            'df': df  # For later analysis\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating performance for {strategy_hash}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load market data\n",
    "market_data_paths = [\n",
    "    Path(f'data/{symbols[0]}_{timeframe}.parquet'),\n",
    "    Path(f'../data/{symbols[0]}_{timeframe}.parquet'),\n",
    "    Path(f'../../data/{symbols[0]}_{timeframe}.parquet'),\n",
    "    Path(f'../../../data/{symbols[0]}_{timeframe}.parquet'),\n",
    "    Path(f'../../../../data/{symbols[0]}_{timeframe}.parquet'),\n",
    "]\n",
    "\n",
    "market_data = None\n",
    "for path in market_data_paths:\n",
    "    if path.exists():\n",
    "        market_data = pd.read_parquet(path)\n",
    "        print(f'✅ Loaded market data from: {path}')\n",
    "        break\n",
    "\n",
    "if market_data is None:\n",
    "    print('❌ Could not find market data file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance for all strategies\n",
    "if strategy_index is not None and market_data is not None:\n",
    "    performance_results = []\n",
    "    \n",
    "    # Limit analysis for performance if too many strategies\n",
    "    strategies_to_analyze = strategy_index\n",
    "    if len(strategy_index) > min_strategies_to_analyze * 2:\n",
    "        print(f\"Note: Limiting initial analysis to {min_strategies_to_analyze * 2} strategies for performance\")\n",
    "        # Sample diverse strategies\n",
    "        strategies_to_analyze = strategy_index.groupby('strategy_type').apply(\n",
    "            lambda x: x.sample(min=len(x), n=min(len(x), min_strategies_to_analyze // strategy_index['strategy_type'].nunique()))\n",
    "        ).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\nCalculating performance for {len(strategies_to_analyze)} strategies...\")\n",
    "    \n",
    "    for idx, row in strategies_to_analyze.iterrows():\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"  Progress: {idx}/{len(strategies_to_analyze)}\")\n",
    "            \n",
    "        perf = calculate_performance(row['strategy_hash'], row['trace_path'], market_data)\n",
    "        \n",
    "        if perf:\n",
    "            # Combine strategy info with performance\n",
    "            result = {**row.to_dict(), **perf}\n",
    "            # Remove the full dataframe from results\n",
    "            result.pop('df', None)\n",
    "            performance_results.append(result)\n",
    "    \n",
    "    performance_df = pd.DataFrame(performance_results)\n",
    "    print(f\"\\n✅ Calculated performance for {len(performance_df)} strategies\")\n",
    "else:\n",
    "    performance_df = pd.DataFrame()\n",
    "    print(\"⚠️ Skipping performance calculation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Strategy Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(performance_df) > 0:\n",
    "    # Top performers across ALL strategy types\n",
    "    top_overall = performance_df.nlargest(top_n_strategies, 'sharpe_ratio')\n",
    "    \n",
    "    print(f\"\\n🏆 Top {top_n_strategies} Strategies (All Types):\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    display_cols = ['strategy_type', 'strategy_hash', 'sharpe_ratio', 'total_return', 'max_drawdown', 'num_trades']\n",
    "    # Add parameter columns if they exist\n",
    "    param_cols = [col for col in top_overall.columns if col.startswith('param_')]\n",
    "    display_cols.extend(param_cols[:3])  # Show first 3 parameters\n",
    "    \n",
    "    for idx, row in top_overall.iterrows():\n",
    "        print(f\"\\n{row['strategy_type']} - {row['strategy_hash'][:8]}\")\n",
    "        print(f\"  Sharpe: {row['sharpe_ratio']:.2f} | Return: {row['total_return']:.1%} | Drawdown: {row['max_drawdown']:.1%}\")\n",
    "        if param_cols:\n",
    "            params_str = \" | \".join([f\"{col.replace('param_', '')}: {row[col]}\" for col in param_cols[:3] if pd.notna(row[col])])\n",
    "            if params_str:\n",
    "                print(f\"  Params: {params_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance by strategy type\n",
    "if len(performance_df) > 0:\n",
    "    type_summary = performance_df.groupby('strategy_type').agg({\n",
    "        'sharpe_ratio': ['mean', 'std', 'max'],\n",
    "        'total_return': ['mean', 'std', 'max'],\n",
    "        'strategy_hash': 'count'\n",
    "    }).round(3)\n",
    "    \n",
    "    type_summary.columns = ['_'.join(col).strip() for col in type_summary.columns]\n",
    "    type_summary = type_summary.rename(columns={'strategy_hash_count': 'count'})\n",
    "    type_summary = type_summary.sort_values('sharpe_ratio_mean', ascending=False)\n",
    "    \n",
    "    print(\"\\n📊 Performance by Strategy Type:\")\n",
    "    print(type_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharpe distribution by strategy type\n",
    "if len(performance_df) > 0 and performance_df['strategy_type'].nunique() > 1:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Box plot of Sharpe by type\n",
    "    plt.subplot(1, 2, 1)\n",
    "    performance_df.boxplot(column='sharpe_ratio', by='strategy_type', ax=plt.gca())\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title('Sharpe Ratio Distribution by Strategy Type')\n",
    "    plt.suptitle('')  # Remove default title\n",
    "    plt.ylabel('Sharpe Ratio')\n",
    "    \n",
    "    # Scatter: Return vs Sharpe\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for stype in performance_df['strategy_type'].unique():\n",
    "        mask = performance_df['strategy_type'] == stype\n",
    "        plt.scatter(performance_df.loc[mask, 'total_return'], \n",
    "                   performance_df.loc[mask, 'sharpe_ratio'],\n",
    "                   label=stype, alpha=0.6)\n",
    "    plt.xlabel('Total Return')\n",
    "    plt.ylabel('Sharpe Ratio')\n",
    "    plt.title('Return vs Risk-Adjusted Return')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis for Ensemble Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_strategy_correlations(strategies_df, market_data, run_dir):\n",
    "    \"\"\"Calculate correlation matrix between strategies\"\"\"\n",
    "    returns_dict = {}\n",
    "    \n",
    "    for idx, row in strategies_df.iterrows():\n",
    "        try:\n",
    "            # Load signals\n",
    "            signals = pd.read_parquet(run_dir / row['trace_path'])\n",
    "            signals['ts'] = pd.to_datetime(signals['ts'])\n",
    "            \n",
    "            # Merge and calculate returns\n",
    "            df = market_data.merge(signals[['ts', 'val']], left_on='timestamp', right_on='ts', how='left')\n",
    "            df['signal'] = df['val'].fillna(method='ffill').fillna(0)\n",
    "            df['returns'] = df['close'].pct_change()\n",
    "            df['strategy_returns'] = df['returns'] * df['signal'].shift(1)\n",
    "            \n",
    "            returns_dict[row['strategy_hash']] = df['strategy_returns']\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Create returns DataFrame and calculate correlation\n",
    "    if returns_dict:\n",
    "        returns_df = pd.DataFrame(returns_dict)\n",
    "        return returns_df.corr()\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations among top performers\n",
    "if len(performance_df) > 0 and len(top_overall) > 1:\n",
    "    print(\"\\n🔗 Calculating correlations among top strategies...\")\n",
    "    \n",
    "    corr_matrix = calculate_strategy_correlations(top_overall, market_data, run_dir)\n",
    "    \n",
    "    if not corr_matrix.empty:\n",
    "        # Find uncorrelated strategies\n",
    "        uncorrelated_pairs = []\n",
    "        for i in range(len(corr_matrix)):\n",
    "            for j in range(i+1, len(corr_matrix)):\n",
    "                corr_val = corr_matrix.iloc[i, j]\n",
    "                if abs(corr_val) < correlation_threshold:\n",
    "                    uncorrelated_pairs.append({\n",
    "                        'strategy1': corr_matrix.index[i],\n",
    "                        'strategy2': corr_matrix.columns[j],\n",
    "                        'correlation': corr_val\n",
    "                    })\n",
    "        \n",
    "        print(f\"\\n✅ Found {len(uncorrelated_pairs)} uncorrelated pairs (correlation < {correlation_threshold})\")\n",
    "        \n",
    "        # Visualize correlation matrix\n",
    "        if len(corr_matrix) <= 20:  # Only plot if reasonable size\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(corr_matrix, cmap='coolwarm', center=0, vmin=-1, vmax=1, \n",
    "                       xticklabels=[h[:8] for h in corr_matrix.columns],\n",
    "                       yticklabels=[h[:8] for h in corr_matrix.index])\n",
    "            plt.title('Strategy Correlation Matrix')\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optimal ensemble\n",
    "if len(performance_df) > 0 and 'corr_matrix' in locals() and not corr_matrix.empty:\n",
    "    # Start with best strategy\n",
    "    ensemble = [top_overall.iloc[0]['strategy_hash']]\n",
    "    ensemble_data = [top_overall.iloc[0]]\n",
    "    \n",
    "    # Add uncorrelated strategies\n",
    "    for idx, candidate in top_overall.iloc[1:].iterrows():\n",
    "        if len(ensemble) >= ensemble_size:\n",
    "            break\n",
    "            \n",
    "        # Check correlation with existing ensemble members\n",
    "        candidate_hash = candidate['strategy_hash']\n",
    "        if candidate_hash in corr_matrix.columns:\n",
    "            max_corr = 0\n",
    "            for existing in ensemble:\n",
    "                if existing in corr_matrix.index:\n",
    "                    corr = abs(corr_matrix.loc[existing, candidate_hash])\n",
    "                    max_corr = max(max_corr, corr)\n",
    "            \n",
    "            if max_corr < correlation_threshold:\n",
    "                ensemble.append(candidate_hash)\n",
    "                ensemble_data.append(candidate)\n",
    "    \n",
    "    print(f\"\\n🎯 Recommended Ensemble ({len(ensemble)} strategies):\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    ensemble_df = pd.DataFrame(ensemble_data)\n",
    "    for idx, row in ensemble_df.iterrows():\n",
    "        print(f\"\\n{idx+1}. {row['strategy_type']} - {row['strategy_hash'][:8]}\")\n",
    "        print(f\"   Sharpe: {row['sharpe_ratio']:.2f} | Return: {row['total_return']:.1%}\")\n",
    "    \n",
    "    # Calculate ensemble metrics\n",
    "    print(f\"\\nEnsemble Statistics:\")\n",
    "    print(f\"  Average Sharpe: {ensemble_df['sharpe_ratio'].mean():.2f}\")\n",
    "    print(f\"  Average Return: {ensemble_df['total_return'].mean():.1%}\")\n",
    "    print(f\"  Strategy Types: {', '.join(ensemble_df['strategy_type'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export recommendations\n",
    "if len(performance_df) > 0:\n",
    "    recommendations = {\n",
    "        'run_info': {\n",
    "            'run_id': run_dir.name,\n",
    "            'config_name': config_name,\n",
    "            'generated_at': datetime.now().isoformat(),\n",
    "            'total_strategies': len(strategy_index) if strategy_index is not None else 0,\n",
    "            'strategies_analyzed': len(performance_df)\n",
    "        },\n",
    "        'best_individual': {},\n",
    "        'best_by_type': {},\n",
    "        'ensemble': []\n",
    "    }\n",
    "    \n",
    "    # Best overall\n",
    "    if len(top_overall) > 0:\n",
    "        best = top_overall.iloc[0]\n",
    "        recommendations['best_individual'] = {\n",
    "            'strategy_hash': best['strategy_hash'],\n",
    "            'strategy_type': best['strategy_type'],\n",
    "            'sharpe_ratio': float(best['sharpe_ratio']),\n",
    "            'total_return': float(best['total_return']),\n",
    "            'max_drawdown': float(best['max_drawdown']),\n",
    "            'parameters': {col.replace('param_', ''): best[col] \n",
    "                          for col in best.index if col.startswith('param_') and pd.notna(best[col])}\n",
    "        }\n",
    "    \n",
    "    # Best by type\n",
    "    for stype in performance_df['strategy_type'].unique():\n",
    "        type_best = performance_df[performance_df['strategy_type'] == stype].nlargest(1, 'sharpe_ratio')\n",
    "        if len(type_best) > 0:\n",
    "            row = type_best.iloc[0]\n",
    "            recommendations['best_by_type'][stype] = {\n",
    "                'strategy_hash': row['strategy_hash'],\n",
    "                'sharpe_ratio': float(row['sharpe_ratio']),\n",
    "                'total_return': float(row['total_return'])\n",
    "            }\n",
    "    \n",
    "    # Ensemble\n",
    "    if 'ensemble_df' in locals():\n",
    "        for idx, row in ensemble_df.iterrows():\n",
    "            recommendations['ensemble'].append({\n",
    "                'strategy_hash': row['strategy_hash'],\n",
    "                'strategy_type': row['strategy_type'],\n",
    "                'sharpe_ratio': float(row['sharpe_ratio']),\n",
    "                'weight': 1.0 / len(ensemble_df)  # Equal weight for now\n",
    "            })\n",
    "    \n",
    "    # Save files\n",
    "    with open(run_dir / 'recommendations.json', 'w') as f:\n",
    "        json.dump(recommendations, f, indent=2)\n",
    "    \n",
    "    performance_df.to_csv(run_dir / 'performance_analysis.csv', index=False)\n",
    "    \n",
    "    print(\"\\n✅ Results exported:\")\n",
    "    print(f\"  - recommendations.json\")\n",
    "    print(f\"  - performance_analysis.csv\")\n",
    "else:\n",
    "    print(\"⚠️ No results to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Analysis with Snippets\n",
    "\n",
    "You can now extend this analysis using pre-built snippets. Examples:\n",
    "\n",
    "### Exploratory Analysis\n",
    "```python\n",
    "%load src/analytics/snippets/exploratory/signal_frequency.py\n",
    "# Then edit parameters and run\n",
    "\n",
    "%load src/analytics/snippets/exploratory/parameter_sweep.py\n",
    "# Analyze specific strategy type parameters\n",
    "```\n",
    "\n",
    "### Ensemble Building\n",
    "```python\n",
    "%load src/analytics/snippets/ensembles/find_uncorrelated.py\n",
    "# Advanced correlation analysis\n",
    "\n",
    "%load src/analytics/snippets/ensembles/optimize_weights.py\n",
    "# Optimize portfolio weights\n",
    "```\n",
    "\n",
    "### Regime Analysis\n",
    "```python\n",
    "%load src/analytics/snippets/regime/volatility_regimes.py\n",
    "# Performance in different volatility environments\n",
    "```\n",
    "\n",
    "### Helper Functions\n",
    "```python\n",
    "%load src/analytics/snippets/helpers.py\n",
    "# Load utility functions for custom analysis\n",
    "```\n",
    "\n",
    "Each snippet contains editable parameters at the top. Modify them before running to customize the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Analysis complete! Key files generated:\n",
    "- `recommendations.json` - Best strategies and ensemble recommendations\n",
    "- `performance_analysis.csv` - Full performance data for all strategies\n",
    "\n",
    "Next steps:\n",
    "1. Use the recommended ensemble for live trading\n",
    "2. Deep dive into specific strategy types if needed\n",
    "3. Run regime-specific analysis to understand performance drivers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
