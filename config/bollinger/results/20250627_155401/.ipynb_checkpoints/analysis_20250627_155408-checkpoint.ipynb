{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa13d67f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T22:54:09.368073Z",
     "iopub.status.busy": "2025-06-27T22:54:09.367710Z",
     "iopub.status.idle": "2025-06-27T22:54:09.373689Z",
     "shell.execute_reply": "2025-06-27T22:54:09.373262Z"
    },
    "papermill": {
     "duration": 0.015894,
     "end_time": "2025-06-27T22:54:09.375068",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.359174",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "run_dir = \"/Users/daws/ADMF-PC/config/bollinger/results/20250627_155401\"\n",
    "config_name = \"bollinger\"\n",
    "symbols = [\"SPY\"]\n",
    "timeframe = \"5m\"\n",
    "min_strategies_to_analyze = 20\n",
    "sharpe_threshold = 1.0\n",
    "correlation_threshold = 0.7\n",
    "top_n_strategies = 10\n",
    "ensemble_size = 5\n",
    "calculate_all_performance = True\n",
    "performance_limit = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e823907f",
   "metadata": {
    "papermill": {
     "duration": 0.002563,
     "end_time": "2025-06-27T22:54:09.381512",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.378949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trade & Risk Analysis Notebook\n",
    "\n",
    "Analyzes trading performance through orders, fills, and position events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a31ea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T22:54:09.387518Z",
     "iopub.status.busy": "2025-06-27T22:54:09.387198Z",
     "iopub.status.idle": "2025-06-27T22:54:09.837404Z",
     "shell.execute_reply": "2025-06-27T22:54:09.837162Z"
    },
    "papermill": {
     "duration": 0.454081,
     "end_time": "2025-06-27T22:54:09.838215",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.384134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349db3fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T22:54:09.841292Z",
     "iopub.status.busy": "2025-06-27T22:54:09.841077Z",
     "iopub.status.idle": "2025-06-27T22:54:09.842760Z",
     "shell.execute_reply": "2025-06-27T22:54:09.842564Z"
    },
    "papermill": {
     "duration": 0.003666,
     "end_time": "2025-06-27T22:54:09.843353",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.839687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters (for papermill)\n",
    "run_dir = '.'\n",
    "config_name = 'test'\n",
    "symbols = ['SPY']\n",
    "timeframe = '5m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ff77d",
   "metadata": {
    "papermill": {
     "duration": 0.000968,
     "end_time": "2025-06-27T22:54:09.845348",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.844380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Load Trace Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c021a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T22:54:09.847663Z",
     "iopub.status.busy": "2025-06-27T22:54:09.847574Z",
     "iopub.status.idle": "2025-06-27T22:54:09.850526Z",
     "shell.execute_reply": "2025-06-27T22:54:09.850313Z"
    },
    "papermill": {
     "duration": 0.004818,
     "end_time": "2025-06-27T22:54:09.851108",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.846290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the results directory\n",
    "results_dir = Path('.')\n",
    "traces_dir = results_dir / 'traces'\n",
    "\n",
    "# Load trace files\n",
    "traces = {}\n",
    "\n",
    "# Strategy signals\n",
    "signals_path = list(traces_dir.rglob('signals/*/*.parquet'))\n",
    "if signals_path:\n",
    "    traces['signals'] = pd.read_parquet(signals_path[0])\n",
    "    print(f\"Loaded signals: {len(traces['signals'])} records\")\n",
    "\n",
    "# Portfolio orders\n",
    "orders_path = traces_dir / 'portfolio' / 'orders' / 'portfolio_orders.parquet'\n",
    "if orders_path.exists():\n",
    "    traces['orders'] = pd.read_parquet(orders_path)\n",
    "    print(f\"Loaded orders: {len(traces['orders'])} records\")\n",
    "\n",
    "# Execution fills\n",
    "fills_path = traces_dir / 'execution' / 'fills' / 'execution_fills.parquet'\n",
    "if fills_path.exists():\n",
    "    traces['fills'] = pd.read_parquet(fills_path)\n",
    "    print(f\"Loaded fills: {len(traces['fills'])} records\")\n",
    "\n",
    "# Position events - NOTE: File names are plural\n",
    "pos_open_path = traces_dir / 'portfolio' / 'positions_open' / 'positions_open.parquet'\n",
    "if pos_open_path.exists():\n",
    "    traces['position_open'] = pd.read_parquet(pos_open_path)\n",
    "    print(f\"Loaded position opens: {len(traces['position_open'])} records\")\n",
    "\n",
    "pos_close_path = traces_dir / 'portfolio' / 'positions_close' / 'positions_close.parquet'\n",
    "if pos_close_path.exists():\n",
    "    traces['position_close'] = pd.read_parquet(pos_close_path)\n",
    "    print(f\"Loaded position closes: {len(traces['position_close'])} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d953b44",
   "metadata": {
    "papermill": {
     "duration": 0.001211,
     "end_time": "2025-06-27T22:54:09.853467",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.852256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Parse Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a75e68b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T22:54:09.856143Z",
     "iopub.status.busy": "2025-06-27T22:54:09.855977Z",
     "iopub.status.idle": "2025-06-27T22:54:09.858281Z",
     "shell.execute_reply": "2025-06-27T22:54:09.858067Z"
    },
    "papermill": {
     "duration": 0.004113,
     "end_time": "2025-06-27T22:54:09.858831",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.854718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse JSON metadata for all trace types\n",
    "for trace_type, df in traces.items():\n",
    "    if 'metadata' in df.columns and len(df) > 0:\n",
    "        try:\n",
    "            # Parse metadata\n",
    "            metadata_parsed = df['metadata'].apply(lambda x: json.loads(x) if x else {})\n",
    "            metadata_df = pd.DataFrame(list(metadata_parsed))\n",
    "            \n",
    "            # Add parsed columns to original dataframe\n",
    "            for col in metadata_df.columns:\n",
    "                if col not in df.columns:\n",
    "                    df[col] = metadata_df[col]\n",
    "            \n",
    "            traces[trace_type] = df  # Update with parsed data\n",
    "            print(f\"Parsed {trace_type} metadata: {list(metadata_df.columns)[:10]}...\")  # Show first 10 cols\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {trace_type} metadata: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561b1c6e",
   "metadata": {
    "papermill": {
     "duration": 0.001018,
     "end_time": "2025-06-27T22:54:09.860924",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.859906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Reconstruct Trades from Position Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5ee53e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T22:54:09.863364Z",
     "iopub.status.busy": "2025-06-27T22:54:09.863216Z",
     "iopub.status.idle": "2025-06-27T22:54:09.867321Z",
     "shell.execute_reply": "2025-06-27T22:54:09.867117Z"
    },
    "papermill": {
     "duration": 0.006019,
     "end_time": "2025-06-27T22:54:09.867901",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.861882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing position open/close events for trade reconstruction\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct trades from position events\n",
    "trades_df = None\n",
    "\n",
    "if 'position_open' in traces and 'position_close' in traces:\n",
    "    opens = traces['position_open']\n",
    "    closes = traces['position_close']\n",
    "    \n",
    "    # If we have position_id, use it for matching\n",
    "    if 'position_id' in opens.columns and 'position_id' in closes.columns:\n",
    "        # Match by position_id\n",
    "        trades_df = pd.merge(\n",
    "            opens[['position_id', 'idx', 'entry_price', 'quantity', 'strategy_id']].rename(\n",
    "                columns={'idx': 'entry_bar'}\n",
    "            ),\n",
    "            closes[['position_id', 'idx', 'exit_price', 'realized_pnl', 'exit_type', 'exit_reason']].rename(\n",
    "                columns={'idx': 'exit_bar'}\n",
    "            ),\n",
    "            on='position_id',\n",
    "            how='inner'\n",
    "        )\n",
    "    else:\n",
    "        # Simple approach: assume sequential trades\n",
    "        min_len = min(len(opens), len(closes))\n",
    "        if min_len > 0:\n",
    "            trades_df = pd.DataFrame({\n",
    "                'entry_bar': opens['idx'].iloc[:min_len].values,\n",
    "                'exit_bar': closes['idx'].iloc[:min_len].values,\n",
    "                'entry_price': opens['entry_price'].iloc[:min_len].values if 'entry_price' in opens.columns else opens['px'].iloc[:min_len].values,\n",
    "                'exit_price': closes['exit_price'].iloc[:min_len].values if 'exit_price' in closes.columns else closes['px'].iloc[:min_len].values,\n",
    "                'quantity': opens['quantity'].iloc[:min_len].values if 'quantity' in opens.columns else 100,\n",
    "                'realized_pnl': closes['realized_pnl'].iloc[:min_len].values if 'realized_pnl' in closes.columns else 0,\n",
    "                'exit_type': closes['exit_type'].iloc[:min_len].values if 'exit_type' in closes.columns else 'unknown',\n",
    "                'strategy_id': opens['strategy_id'].iloc[:min_len].values if 'strategy_id' in opens.columns else 'unknown'\n",
    "            })\n",
    "    \n",
    "    if trades_df is not None and len(trades_df) > 0:\n",
    "        # Calculate additional metrics\n",
    "        trades_df['bars_held'] = trades_df['exit_bar'] - trades_df['entry_bar']\n",
    "        \n",
    "        # Correctly calculate returns based on position direction (long vs short)\n",
    "        # For long positions: profit when exit > entry\n",
    "        # For short positions: profit when exit < entry\n",
    "        if 'quantity' in trades_df.columns:\n",
    "            # Use quantity sign to determine direction\n",
    "            trades_df['return_pct'] = trades_df.apply(\n",
    "                lambda row: ((row['exit_price'] - row['entry_price']) / row['entry_price'] * 100) if row['quantity'] > 0 \n",
    "                           else ((row['entry_price'] - row['exit_price']) / row['entry_price'] * 100),\n",
    "                axis=1\n",
    "            )\n",
    "        else:\n",
    "            # Fallback: assume all long positions (legacy compatibility)\n",
    "            trades_df['return_pct'] = (trades_df['exit_price'] - trades_df['entry_price']) / trades_df['entry_price'] * 100\n",
    "            \n",
    "        trades_df['return_per_bar'] = trades_df['return_pct'] / trades_df['bars_held'].clip(lower=1)\n",
    "        \n",
    "        print(f\"Reconstructed {len(trades_df)} trades\")\n",
    "        print(\"\\nTrade Summary:\")\n",
    "        print(trades_df[['entry_bar', 'exit_bar', 'bars_held', 'return_pct', 'exit_type']].describe())\n",
    "    else:\n",
    "        print(\"Could not reconstruct trades - missing position events or position_id\")\n",
    "else:\n",
    "    print(\"Missing position open/close events for trade reconstruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db227a30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T22:54:09.870856Z",
     "iopub.status.busy": "2025-06-27T22:54:09.870742Z",
     "iopub.status.idle": "2025-06-27T22:54:09.875538Z",
     "shell.execute_reply": "2025-06-27T22:54:09.875263Z"
    },
    "papermill": {
     "duration": 0.007148,
     "end_time": "2025-06-27T22:54:09.876123",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.868975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No trades available for performance analysis\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "if trades_df is not None and len(trades_df) > 0:\n",
    "    print(\"=== PERFORMANCE METRICS ===\")\n",
    "    \n",
    "    # Basic metrics\n",
    "    total_trades = len(trades_df)\n",
    "    winning_trades = (trades_df['return_pct'] > 0).sum()\n",
    "    losing_trades = (trades_df['return_pct'] < 0).sum()\n",
    "    win_rate = winning_trades / total_trades if total_trades > 0 else 0\n",
    "    \n",
    "    print(f\"\\nTotal trades: {total_trades}\")\n",
    "    print(f\"Winning trades: {winning_trades}\")\n",
    "    print(f\"Losing trades: {losing_trades}\")\n",
    "    print(f\"Win rate: {win_rate:.1%}\")\n",
    "    \n",
    "    # Return metrics\n",
    "    avg_return = trades_df['return_pct'].mean()\n",
    "    total_return = trades_df['return_pct'].sum()\n",
    "    \n",
    "    if winning_trades > 0:\n",
    "        avg_win = trades_df[trades_df['return_pct'] > 0]['return_pct'].mean()\n",
    "    else:\n",
    "        avg_win = 0\n",
    "        \n",
    "    if losing_trades > 0:\n",
    "        avg_loss = trades_df[trades_df['return_pct'] < 0]['return_pct'].mean()\n",
    "    else:\n",
    "        avg_loss = 0\n",
    "    \n",
    "    profit_factor = abs(avg_win * winning_trades) / abs(avg_loss * losing_trades) if losing_trades > 0 and avg_loss != 0 else np.inf\n",
    "    \n",
    "    print(f\"\\nAverage return per trade: {avg_return:.2f}%\")\n",
    "    print(f\"Total return: {total_return:.2f}%\")\n",
    "    print(f\"Average winning trade: {avg_win:.2f}%\")\n",
    "    print(f\"Average losing trade: {avg_loss:.2f}%\")\n",
    "    print(f\"Profit factor: {profit_factor:.2f}\")\n",
    "    \n",
    "    # Risk metrics\n",
    "    returns_std = trades_df['return_pct'].std()\n",
    "    sharpe_ratio = avg_return / returns_std * np.sqrt(252) if returns_std > 0 else 0  # Annualized\n",
    "    \n",
    "    max_dd = 0\n",
    "    peak = 0\n",
    "    cumulative_returns = (1 + trades_df['return_pct'] / 100).cumprod()\n",
    "    for value in cumulative_returns:\n",
    "        if value > peak:\n",
    "            peak = value\n",
    "        dd = (peak - value) / peak\n",
    "        if dd > max_dd:\n",
    "            max_dd = dd\n",
    "    \n",
    "    print(f\"\\nSharpe ratio (annualized): {sharpe_ratio:.2f}\")\n",
    "    print(f\"Maximum drawdown: {max_dd:.1%}\")\n",
    "    \n",
    "    # Time metrics\n",
    "    avg_bars_held = trades_df['bars_held'].mean()\n",
    "    print(f\"\\nAverage bars held: {avg_bars_held:.1f}\")\n",
    "    \n",
    "    # Exit type analysis\n",
    "    if 'exit_type' in trades_df.columns:\n",
    "        print(\"\\nExit type breakdown:\")\n",
    "        exit_counts = trades_df['exit_type'].value_counts()\n",
    "        for exit_type, count in exit_counts.items():\n",
    "            pct = count / total_trades * 100\n",
    "            avg_ret = trades_df[trades_df['exit_type'] == exit_type]['return_pct'].mean()\n",
    "            print(f\"  {exit_type}: {count} trades ({pct:.1f}%), avg return: {avg_ret:.2f}%\")\n",
    "    \n",
    "    # Plot return distribution\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(trades_df['return_pct'], bins=30, alpha=0.7, edgecolor='black')\n",
    "    plt.axvline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    plt.axvline(avg_return, color='green', linestyle='--', label=f'Mean: {avg_return:.2f}%')\n",
    "    plt.xlabel('Return (%)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Return Distribution')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    cumulative_returns.plot()\n",
    "    plt.xlabel('Trade Number')\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.title('Equity Curve')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No trades available for performance analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aa72ca",
   "metadata": {
    "papermill": {
     "duration": 0.001299,
     "end_time": "2025-06-27T22:54:09.878786",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.877487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb55433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T22:54:09.881264Z",
     "iopub.status.busy": "2025-06-27T22:54:09.881169Z",
     "iopub.status.idle": "2025-06-27T22:54:09.883446Z",
     "shell.execute_reply": "2025-06-27T22:54:09.883217Z"
    },
    "papermill": {
     "duration": 0.004209,
     "end_time": "2025-06-27T22:54:09.884035",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.879826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'position_close' in traces:\n",
    "    pos_close = traces['position_close']\n",
    "    print(\"=== Risk Management Exit Analysis ===\")\n",
    "    print(f\"Total positions closed: {len(pos_close)}\")\n",
    "    \n",
    "    if 'exit_type' in pos_close.columns:\n",
    "        exit_counts = pos_close['exit_type'].value_counts()\n",
    "        print(\"\\nExit types:\")\n",
    "        for exit_type, count in exit_counts.items():\n",
    "            pct = count/len(pos_close)*100\n",
    "            print(f\"  {exit_type}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    if 'exit_reason' in pos_close.columns:\n",
    "        print(\"\\nSample exit reasons:\")\n",
    "        for i, row in pos_close.head(5).iterrows():\n",
    "            exit_type = row.get('exit_type', 'unknown')\n",
    "            exit_reason = row.get('exit_reason', 'unknown')\n",
    "            print(f\"  {exit_type}: {exit_reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5792dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T22:54:09.886758Z",
     "iopub.status.busy": "2025-06-27T22:54:09.886669Z",
     "iopub.status.idle": "2025-06-27T22:54:09.889045Z",
     "shell.execute_reply": "2025-06-27T22:54:09.888843Z"
    },
    "papermill": {
     "duration": 0.004508,
     "end_time": "2025-06-27T22:54:09.889617",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.885109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if signals persist after risk exits\n",
    "if 'signals' in traces and 'position_close' in traces:\n",
    "    signals_df = traces['signals']\n",
    "    pos_close = traces['position_close']\n",
    "    \n",
    "    print(\"=== Signal Persistence After Risk Exits ===\")\n",
    "    \n",
    "    # Find risk exits\n",
    "    if 'exit_type' in pos_close.columns:\n",
    "        risk_exits = pos_close[pos_close['exit_type'].isin(['stop_loss', 'trailing_stop'])]\n",
    "        \n",
    "        if len(risk_exits) > 0:\n",
    "            print(f\"Found {len(risk_exits)} risk exits\")\n",
    "            \n",
    "            # Check first few risk exits\n",
    "            for idx, exit_row in risk_exits.head(3).iterrows():\n",
    "                exit_bar = exit_row['idx']\n",
    "                \n",
    "                # Get signals around exit\n",
    "                next_signals = signals_df[\n",
    "                    (signals_df['idx'] >= exit_bar) & \n",
    "                    (signals_df['idx'] <= exit_bar + 5)\n",
    "                ]\n",
    "                \n",
    "                if len(next_signals) > 0:\n",
    "                    print(f\"\\nExit at bar {exit_bar} ({exit_row['exit_type']}):\")\n",
    "                    for _, sig in next_signals.iterrows():\n",
    "                        print(f\"  Bar {sig['idx']}: signal = {sig['val']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343c04d",
   "metadata": {
    "papermill": {
     "duration": 0.003197,
     "end_time": "2025-06-27T22:54:09.893985",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.890788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Risk Management Exit Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee50b0",
   "metadata": {
    "papermill": {
     "duration": 0.001125,
     "end_time": "2025-06-27T22:54:09.896414",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.895289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058af300",
   "metadata": {
    "papermill": {
     "duration": 0.001056,
     "end_time": "2025-06-27T22:54:09.898514",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.897458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Order Flow Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "601b8ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T22:54:09.901132Z",
     "iopub.status.busy": "2025-06-27T22:54:09.900956Z",
     "iopub.status.idle": "2025-06-27T22:54:09.903621Z",
     "shell.execute_reply": "2025-06-27T22:54:09.903425Z"
    },
    "papermill": {
     "duration": 0.004648,
     "end_time": "2025-06-27T22:54:09.904240",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.899592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'orders' in traces:\n",
    "    orders_df = traces['orders']\n",
    "    print(\"=== Order Flow Analysis ===\")\n",
    "    print(f\"Total orders: {len(orders_df)}\")\n",
    "    \n",
    "    if len(orders_df) > 1:\n",
    "        # Calculate time between orders\n",
    "        order_gaps = orders_df['idx'].diff().dropna()\n",
    "        \n",
    "        print(f\"\\nTime between orders:\")\n",
    "        print(f\"  Mean: {order_gaps.mean():.1f} bars\")\n",
    "        print(f\"  Median: {order_gaps.median():.1f} bars\")\n",
    "        print(f\"  Min: {order_gaps.min():.0f} bars\")\n",
    "        \n",
    "        # Check for immediate re-entries\n",
    "        immediate = (order_gaps <= 1).sum()\n",
    "        print(f\"\\nImmediate re-entries (≤1 bar): {immediate}\")\n",
    "        \n",
    "        # Plot distribution\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(order_gaps, bins=50, alpha=0.7, edgecolor='black')\n",
    "        plt.axvline(order_gaps.mean(), color='red', linestyle='--', label=f'Mean: {order_gaps.mean():.1f}')\n",
    "        plt.axvline(order_gaps.median(), color='green', linestyle='--', label=f'Median: {order_gaps.median():.1f}')\n",
    "        plt.xlabel('Bars Between Orders')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Time Between Orders Distribution')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe449df8",
   "metadata": {
    "papermill": {
     "duration": 0.001223,
     "end_time": "2025-06-27T22:54:09.906607",
     "exception": false,
     "start_time": "2025-06-27T22:54:09.905384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Trade Performance Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1.688588,
   "end_time": "2025-06-27T22:54:10.123740",
   "environment_variables": {},
   "exception": null,
   "input_path": "/Users/daws/ADMF-PC/src/analytics/templates/trade_analysis_simple.ipynb",
   "output_path": "config/bollinger/results/20250627_155401/analysis_20250627_155408.ipynb",
   "parameters": {
    "calculate_all_performance": true,
    "config_name": "bollinger",
    "correlation_threshold": 0.7,
    "ensemble_size": 5,
    "min_strategies_to_analyze": 20,
    "performance_limit": 100,
    "run_dir": "/Users/daws/ADMF-PC/config/bollinger/results/20250627_155401",
    "sharpe_threshold": 1.0,
    "symbols": [
     "SPY"
    ],
    "timeframe": "5m",
    "top_n_strategies": 10
   },
   "start_time": "2025-06-27T22:54:08.435152",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}