{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86bacc69",
   "metadata": {
    "papermill": {
     "duration": 0.008906,
     "end_time": "2025-06-25T04:42:55.199368",
     "exception": false,
     "start_time": "2025-06-25T04:42:55.190462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Universal Strategy Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis across all strategies tested in a parameter sweep.\n",
    "\n",
    "**Key Features:**\n",
    "- Cross-strategy performance comparison\n",
    "- Parameter sensitivity analysis\n",
    "- Correlation analysis for ensemble building\n",
    "- Regime-specific performance breakdown\n",
    "- Automatic identification of optimal strategies and ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f36741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:55.210191Z",
     "iopub.status.busy": "2025-06-25T04:42:55.209978Z",
     "iopub.status.idle": "2025-06-25T04:42:55.215139Z",
     "shell.execute_reply": "2025-06-25T04:42:55.214709Z"
    },
    "papermill": {
     "duration": 0.010903,
     "end_time": "2025-06-25T04:42:55.216243",
     "exception": false,
     "start_time": "2025-06-25T04:42:55.205340",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters will be injected here by papermill\n",
    "# This cell is tagged with 'parameters' for papermill to recognize it\n",
    "run_dir = \".\"\n",
    "config_name = \"config\"\n",
    "symbols = [\"SPY\"]\n",
    "timeframe = \"5m\"\n",
    "min_strategies_to_analyze = 20\n",
    "sharpe_threshold = 1.0\n",
    "correlation_threshold = 0.7\n",
    "top_n_strategies = 10\n",
    "ensemble_size = 5\n",
    "calculate_all_performance = True  # Set to False to limit analysis for large sweeps\n",
    "performance_limit = 100  # If calculate_all_performance is False, limit to this many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f71988",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:55.222337Z",
     "iopub.status.busy": "2025-06-25T04:42:55.222185Z",
     "iopub.status.idle": "2025-06-25T04:42:55.224752Z",
     "shell.execute_reply": "2025-06-25T04:42:55.224431Z"
    },
    "papermill": {
     "duration": 0.00639,
     "end_time": "2025-06-25T04:42:55.225603",
     "exception": false,
     "start_time": "2025-06-25T04:42:55.219213",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "run_dir = \"/Users/daws/ADMF-PC/config/bollinger/results/20250624_214106\"\n",
    "config_name = \"bollinger\"\n",
    "symbols = [\"SPY_5m\"]\n",
    "timeframe = \"5m\"\n",
    "min_strategies_to_analyze = 20\n",
    "sharpe_threshold = 1.0\n",
    "correlation_threshold = 0.7\n",
    "top_n_strategies = 10\n",
    "ensemble_size = 5\n",
    "calculate_all_performance = True\n",
    "performance_limit = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc250f",
   "metadata": {
    "papermill": {
     "duration": 0.002387,
     "end_time": "2025-06-25T04:42:55.230513",
     "exception": false,
     "start_time": "2025-06-25T04:42:55.228126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc20b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:55.235148Z",
     "iopub.status.busy": "2025-06-25T04:42:55.235024Z",
     "iopub.status.idle": "2025-06-25T04:42:55.959019Z",
     "shell.execute_reply": "2025-06-25T04:42:55.958788Z"
    },
    "papermill": {
     "duration": 0.727106,
     "end_time": "2025-06-25T04:42:55.959680",
     "exception": false,
     "start_time": "2025-06-25T04:42:55.232574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing run: 20250624_214106\n",
      "Full path: /Users/daws/ADMF-PC/config/bollinger/results/20250624_214106\n",
      "Config: bollinger\n",
      "Symbol(s): ['SPY_5m']\n",
      "Timeframe: 5m\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Initialize DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Convert run_dir to Path and resolve to absolute path\n",
    "run_dir = Path(run_dir).resolve()\n",
    "print(f\"Analyzing run: {run_dir.name}\")\n",
    "print(f\"Full path: {run_dir}\")\n",
    "print(f\"Config: {config_name}\")\n",
    "print(f\"Symbol(s): {symbols}\")\n",
    "print(f\"Timeframe: {timeframe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b53b0148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:55.963605Z",
     "iopub.status.busy": "2025-06-25T04:42:55.963460Z",
     "iopub.status.idle": "2025-06-25T04:42:55.967310Z",
     "shell.execute_reply": "2025-06-25T04:42:55.967106Z"
    },
    "papermill": {
     "duration": 0.006358,
     "end_time": "2025-06-25T04:42:55.967963",
     "exception": false,
     "start_time": "2025-06-25T04:42:55.961605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found project root: /Users/daws/ADMF-PC\n",
      "âœ… Analysis snippets available at: /Users/daws/ADMF-PC/src/analytics/snippets\n",
      "âœ… SQL queries available at: /Users/daws/ADMF-PC/src/analytics/queries\n",
      "\n",
      "Use %load to load any snippet, e.g.:\n",
      "  %load /Users/daws/ADMF-PC/src/analytics/snippets/exploratory/signal_frequency.py\n",
      "  %load /Users/daws/ADMF-PC/src/analytics/snippets/ensembles/find_uncorrelated.py\n"
     ]
    }
   ],
   "source": [
    "# Setup path for loading analysis snippets\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find the project root (where src/ directory is)\n",
    "current_path = Path(run_dir).resolve()\n",
    "project_root = None\n",
    "\n",
    "# Search up the directory tree for src/analytics/snippets\n",
    "for parent in current_path.parents:\n",
    "    if (parent / 'src' / 'analytics' / 'snippets').exists():\n",
    "        project_root = parent\n",
    "        break\n",
    "\n",
    "# If not found from run_dir, try from current working directory\n",
    "if not project_root:\n",
    "    cwd = Path.cwd()\n",
    "    for parent in [cwd] + list(cwd.parents):\n",
    "        if (parent / 'src' / 'analytics' / 'snippets').exists():\n",
    "            project_root = parent\n",
    "            break\n",
    "\n",
    "# Last resort: check common project locations\n",
    "if not project_root:\n",
    "    common_roots = [\n",
    "        Path('/Users/daws/ADMF-PC'),\n",
    "        Path.home() / 'ADMF-PC',\n",
    "        Path.cwd().parent.parent.parent.parent  # 4 levels up from typical results dir\n",
    "    ]\n",
    "    for root in common_roots:\n",
    "        if root.exists() and (root / 'src' / 'analytics' / 'snippets').exists():\n",
    "            project_root = root\n",
    "            break\n",
    "\n",
    "if project_root:\n",
    "    # Add to Python path if not already there\n",
    "    if str(project_root) not in sys.path:\n",
    "        sys.path.insert(0, str(project_root))\n",
    "    snippets_path = project_root / 'src' / 'analytics' / 'snippets'\n",
    "    queries_path = project_root / 'src' / 'analytics' / 'queries'\n",
    "    print(f\"âœ… Found project root: {project_root}\")\n",
    "    print(f\"âœ… Analysis snippets available at: {snippets_path}\")\n",
    "    print(f\"âœ… SQL queries available at: {queries_path}\")\n",
    "    print(\"\\nUse %load to load any snippet, e.g.:\")\n",
    "    print(\"  %load {}/src/analytics/snippets/exploratory/signal_frequency.py\".format(project_root))\n",
    "    print(\"  %load {}/src/analytics/snippets/ensembles/find_uncorrelated.py\".format(project_root))\n",
    "else:\n",
    "    print(\"âš ï¸ Could not find project root with src/analytics/snippets\")\n",
    "    print(f\"  Searched from: {current_path}\")\n",
    "    print(f\"  Current working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e97f0",
   "metadata": {
    "papermill": {
     "duration": 0.001451,
     "end_time": "2025-06-25T04:42:55.971187",
     "exception": false,
     "start_time": "2025-06-25T04:42:55.969736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Strategy Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31274f34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:55.974521Z",
     "iopub.status.busy": "2025-06-25T04:42:55.974425Z",
     "iopub.status.idle": "2025-06-25T04:42:55.976657Z",
     "shell.execute_reply": "2025-06-25T04:42:55.976451Z"
    },
    "papermill": {
     "duration": 0.004617,
     "end_time": "2025-06-25T04:42:55.977259",
     "exception": false,
     "start_time": "2025-06-25T04:42:55.972642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ No strategy_index.parquet found at /Users/daws/ADMF-PC/config/bollinger/results/20250624_214106/strategy_index.parquet\n"
     ]
    }
   ],
   "source": [
    "# Load strategy index - the catalog of all strategies tested\n",
    "strategy_index_path = run_dir / 'strategy_index.parquet'\n",
    "\n",
    "if strategy_index_path.exists():\n",
    "    strategy_index = pd.read_parquet(strategy_index_path)\n",
    "    print(f\"âœ… Loaded {len(strategy_index)} strategies from {strategy_index_path}\")\n",
    "    \n",
    "    # Show strategy type distribution\n",
    "    by_type = strategy_index['strategy_type'].value_counts()\n",
    "    print(\"\\nStrategies by type:\")\n",
    "    for stype, count in by_type.items():\n",
    "        print(f\"  {stype}: {count}\")\n",
    "        \n",
    "    # Show sample of columns\n",
    "    print(f\"\\nColumns: {list(strategy_index.columns)[:10]}...\")\n",
    "else:\n",
    "    print(f\"âŒ No strategy_index.parquet found at {strategy_index_path}\")\n",
    "    strategy_index = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed3a8fd",
   "metadata": {
    "papermill": {
     "duration": 0.001483,
     "end_time": "2025-06-25T04:42:55.980356",
     "exception": false,
     "start_time": "2025-06-25T04:42:55.978873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Performance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93aa16be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:55.983911Z",
     "iopub.status.busy": "2025-06-25T04:42:55.983815Z",
     "iopub.status.idle": "2025-06-25T04:42:55.986778Z",
     "shell.execute_reply": "2025-06-25T04:42:55.986570Z"
    },
    "papermill": {
     "duration": 0.00532,
     "end_time": "2025-06-25T04:42:55.987353",
     "exception": false,
     "start_time": "2025-06-25T04:42:55.982033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_performance(strategy_hash, trace_path, market_data):\n",
    "    \"\"\"Calculate performance metrics for a strategy\"\"\"\n",
    "    try:\n",
    "        # Always use the global run_dir which is already resolved to absolute path\n",
    "        signals_path = run_dir / trace_path\n",
    "            \n",
    "        # Load sparse signals\n",
    "        signals = pd.read_parquet(signals_path)\n",
    "        signals['ts'] = pd.to_datetime(signals['ts'])\n",
    "        \n",
    "        # Merge with market data\n",
    "        df = market_data.merge(\n",
    "            signals[['ts', 'val']], \n",
    "            left_on='timestamp', \n",
    "            right_on='ts', \n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Forward fill signals (sparse to dense)\n",
    "        df['signal'] = df['val'].ffill().fillna(0)\n",
    "        \n",
    "        # Calculate returns\n",
    "        df['returns'] = df['close'].pct_change()\n",
    "        df['strategy_returns'] = df['returns'] * df['signal'].shift(1)\n",
    "        df['cum_returns'] = (1 + df['strategy_returns']).cumprod()\n",
    "        \n",
    "        # Metrics\n",
    "        total_return = df['cum_returns'].iloc[-1] - 1\n",
    "        \n",
    "        if df['strategy_returns'].std() > 0:\n",
    "            sharpe = df['strategy_returns'].mean() / df['strategy_returns'].std() * np.sqrt(252 * 78)\n",
    "        else:\n",
    "            sharpe = 0\n",
    "            \n",
    "        cummax = df['cum_returns'].expanding().max()\n",
    "        drawdown = (df['cum_returns'] / cummax - 1)\n",
    "        max_dd = drawdown.min()\n",
    "        \n",
    "        # Count trades\n",
    "        trades = (df['signal'] != df['signal'].shift()).sum()\n",
    "        \n",
    "        return {\n",
    "            'total_return': total_return,\n",
    "            'sharpe_ratio': sharpe,\n",
    "            'max_drawdown': max_dd,\n",
    "            'num_trades': trades,\n",
    "            'df': df  # For later analysis\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating performance for {strategy_hash}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8477e0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:55.991034Z",
     "iopub.status.busy": "2025-06-25T04:42:55.990921Z",
     "iopub.status.idle": "2025-06-25T04:42:56.048559Z",
     "shell.execute_reply": "2025-06-25T04:42:56.048340Z"
    },
    "papermill": {
     "duration": 0.060118,
     "end_time": "2025-06-25T04:42:56.049186",
     "exception": false,
     "start_time": "2025-06-25T04:42:55.989068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded market data from: data/SPY_5m.parquet\n",
      "   Shape: (20769, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load market data\n",
    "# First, try to create a symlink to data directory for easier access\n",
    "try:\n",
    "    data_symlink = Path('data')\n",
    "    if not data_symlink.exists():\n",
    "        # Try to find the project root and create symlink\n",
    "        project_root = None\n",
    "        # Extract actual symbol from data configuration\n",
    "        # Handle case where config has 'data: SPY_5m' instead of just symbol\n",
    "        if symbols and len(symbols) > 0:\n",
    "            symbol = symbols[0]\n",
    "            # If symbol contains underscore and timeframe, extract just the symbol part\n",
    "            if '_' in symbol and symbol.endswith(f'_{timeframe}'):\n",
    "                symbol = symbol.replace(f'_{timeframe}', '')\n",
    "        else:\n",
    "            symbol = 'SPY'  # Default fallback\n",
    "            \n",
    "        for parent in [Path.cwd()] + list(Path.cwd().parents):\n",
    "            if (parent / 'data' / f'{symbol}_{timeframe}.parquet').exists():\n",
    "                project_root = parent\n",
    "                break\n",
    "        \n",
    "        if project_root:\n",
    "            data_symlink.symlink_to(project_root / 'data')\n",
    "            print(f\"âœ… Created symlink to data directory: {project_root / 'data'}\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: Could not create data symlink: {e}\")\n",
    "\n",
    "# Extract actual symbol from data configuration\n",
    "# Handle case where config has 'data: SPY_5m' instead of just symbol\n",
    "if symbols and len(symbols) > 0:\n",
    "    symbol = symbols[0]\n",
    "    # If symbol contains underscore and timeframe, extract just the symbol part\n",
    "    if '_' in symbol and symbol.endswith(f'_{timeframe}'):\n",
    "        symbol = symbol.replace(f'_{timeframe}', '')\n",
    "else:\n",
    "    symbol = 'SPY'  # Default fallback\n",
    "\n",
    "# Try multiple paths to find market data\n",
    "market_data_paths = [\n",
    "    Path(f'data/{symbol}_{timeframe}.parquet'),\n",
    "    Path(f'../data/{symbol}_{timeframe}.parquet'),\n",
    "    Path(f'../../data/{symbol}_{timeframe}.parquet'),\n",
    "    Path(f'../../../data/{symbol}_{timeframe}.parquet'),\n",
    "    Path(f'../../../../data/{symbol}_{timeframe}.parquet'),\n",
    "    # Also try absolute path as fallback\n",
    "    Path(f'/Users/daws/ADMF-PC/data/{symbol}_{timeframe}.parquet'),\n",
    "]\n",
    "\n",
    "market_data = None\n",
    "for path in market_data_paths:\n",
    "    if path.exists():\n",
    "        market_data = pd.read_parquet(path)\n",
    "        print(f'âœ… Loaded market data from: {path}')\n",
    "        print(f'   Shape: {market_data.shape}')\n",
    "        break\n",
    "\n",
    "if market_data is None:\n",
    "    print('âŒ Could not find market data file')\n",
    "    print(f'   Searched for: {symbol}_{timeframe}.parquet')\n",
    "    print(f'   In directories:')\n",
    "    for path in market_data_paths:\n",
    "        print(f'     - {path.resolve() if path.exists() else path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad7cd261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:56.053213Z",
     "iopub.status.busy": "2025-06-25T04:42:56.053032Z",
     "iopub.status.idle": "2025-06-25T04:42:56.057514Z",
     "shell.execute_reply": "2025-06-25T04:42:56.057319Z"
    },
    "papermill": {
     "duration": 0.007015,
     "end_time": "2025-06-25T04:42:56.058085",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.051070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping performance calculation\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance for all strategies\n",
    "if strategy_index is not None and market_data is not None:\n",
    "    performance_results = []\n",
    "    \n",
    "    # Determine strategies to analyze based on parameters\n",
    "    strategies_to_analyze = strategy_index\n",
    "    \n",
    "    if not calculate_all_performance and len(strategy_index) > performance_limit:\n",
    "        print(f\"Note: Large parameter sweep detected ({len(strategy_index)} strategies)\")\n",
    "        print(f\"Limiting analysis to {performance_limit} strategies (set calculate_all_performance=True to analyze all)\")\n",
    "        \n",
    "        # Sample diverse strategies across all types\n",
    "        strategies_to_analyze = strategy_index.groupby('strategy_type').apply(\n",
    "            lambda x: x.sample(n=min(len(x), performance_limit // strategy_index['strategy_type'].nunique()), \n",
    "                             random_state=42)\n",
    "        ).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\nCalculating performance for {len(strategies_to_analyze)} strategies...\")\n",
    "    print(f\"Using run directory: {run_dir}\")\n",
    "    \n",
    "    # Check if we already have cached performance metrics\n",
    "    cached_performance_path = run_dir / 'performance_metrics.parquet'\n",
    "    if cached_performance_path.exists() and calculate_all_performance:\n",
    "        print(f\"ðŸ“‚ Found cached performance metrics, loading...\")\n",
    "        performance_df = pd.read_parquet(cached_performance_path)\n",
    "        print(f\"âœ… Loaded performance for {len(performance_df)} strategies from cache\")\n",
    "    else:\n",
    "        # Calculate performance\n",
    "        for idx, row in strategies_to_analyze.iterrows():\n",
    "            if idx % 10 == 0:\n",
    "                print(f\"  Progress: {idx}/{len(strategies_to_analyze)} ({idx/len(strategies_to_analyze)*100:.1f}%)\")\n",
    "                \n",
    "            perf = calculate_performance(row['strategy_hash'], row['trace_path'], market_data)\n",
    "            \n",
    "            if perf:\n",
    "                # Combine strategy info with performance\n",
    "                result = {**row.to_dict(), **perf}\n",
    "                # Remove the full dataframe from results\n",
    "                result.pop('df', None)\n",
    "                performance_results.append(result)\n",
    "        \n",
    "        print(f\"  Progress: {len(strategies_to_analyze)}/{len(strategies_to_analyze)} (100.0%)\")\n",
    "        \n",
    "        performance_df = pd.DataFrame(performance_results)\n",
    "        print(f\"\\nâœ… Calculated performance for {len(performance_df)} strategies\")\n",
    "        \n",
    "        # Save performance results for future use (only if we calculated all)\n",
    "        if calculate_all_performance and len(performance_df) == len(strategy_index):\n",
    "            performance_df.to_parquet(cached_performance_path)\n",
    "            print(f\"ðŸ’¾ Saved performance metrics to: {cached_performance_path}\")\n",
    "else:\n",
    "    performance_df = pd.DataFrame()\n",
    "    print(\"âš ï¸ Skipping performance calculation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada2960c",
   "metadata": {
    "papermill": {
     "duration": 0.001528,
     "end_time": "2025-06-25T04:42:56.061345",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.059817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cross-Strategy Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f2d57ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:56.065059Z",
     "iopub.status.busy": "2025-06-25T04:42:56.064937Z",
     "iopub.status.idle": "2025-06-25T04:42:56.068103Z",
     "shell.execute_reply": "2025-06-25T04:42:56.067888Z"
    },
    "papermill": {
     "duration": 0.00558,
     "end_time": "2025-06-25T04:42:56.068687",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.063107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(performance_df) > 0:\n",
    "    # Top performers across ALL strategy types\n",
    "    top_overall = performance_df.nlargest(top_n_strategies, 'sharpe_ratio')\n",
    "    \n",
    "    print(f\"\\nðŸ† Top {top_n_strategies} Strategies (All Types):\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Look for parameter columns (both with and without param_ prefix for compatibility)\n",
    "    all_param_cols = []\n",
    "    # Check for param_ prefixed columns\n",
    "    param_prefixed_cols = [col for col in top_overall.columns if col.startswith('param_')]\n",
    "    # Check for direct parameter columns (per trace-updates.md)\n",
    "    direct_param_cols = ['period', 'std_dev', 'fast_period', 'slow_period', 'multiplier', 'exit_threshold']\n",
    "    available_param_cols = [col for col in direct_param_cols if col in top_overall.columns]\n",
    "    \n",
    "    # Use whichever we find\n",
    "    if available_param_cols:\n",
    "        all_param_cols = available_param_cols\n",
    "    elif param_prefixed_cols:\n",
    "        all_param_cols = param_prefixed_cols\n",
    "    \n",
    "    for idx, row in top_overall.iterrows():\n",
    "        # Determine identifier to show\n",
    "        strategy_identifier = row.get('strategy_id', 'unknown')\n",
    "        if 'strategy_hash' in row and pd.notna(row['strategy_hash']):\n",
    "            # Check if all strategies have the same hash\n",
    "            if performance_df['strategy_hash'].nunique() > 1:\n",
    "                # Use hash if they're unique\n",
    "                strategy_identifier = row['strategy_hash'][:8]\n",
    "        \n",
    "        print(f\"\\n{row['strategy_type']} - {strategy_identifier}\")\n",
    "        print(f\"  Sharpe: {row['sharpe_ratio']:.2f} | Return: {row['total_return']:.1%} | Drawdown: {row['max_drawdown']:.1%}\")\n",
    "        \n",
    "        # Show parameters\n",
    "        if all_param_cols:\n",
    "            # Filter out null parameters\n",
    "            valid_params = []\n",
    "            for col in all_param_cols[:5]:  # Show up to 5 parameters\n",
    "                if col in row and pd.notna(row[col]):\n",
    "                    param_name = col.replace('param_', '') if col.startswith('param_') else col\n",
    "                    valid_params.append(f\"{param_name}: {row[col]}\")\n",
    "            \n",
    "            if valid_params:\n",
    "                print(f\"  Params: {' | '.join(valid_params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9514917e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:56.072586Z",
     "iopub.status.busy": "2025-06-25T04:42:56.072492Z",
     "iopub.status.idle": "2025-06-25T04:42:56.074462Z",
     "shell.execute_reply": "2025-06-25T04:42:56.074282Z"
    },
    "papermill": {
     "duration": 0.004564,
     "end_time": "2025-06-25T04:42:56.075064",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.070500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Performance by strategy type\n",
    "if len(performance_df) > 0:\n",
    "    type_summary = performance_df.groupby('strategy_type').agg({\n",
    "        'sharpe_ratio': ['mean', 'std', 'max'],\n",
    "        'total_return': ['mean', 'std', 'max'],\n",
    "        'strategy_hash': 'count'\n",
    "    }).round(3)\n",
    "    \n",
    "    type_summary.columns = ['_'.join(col).strip() for col in type_summary.columns]\n",
    "    type_summary = type_summary.rename(columns={'strategy_hash_count': 'count'})\n",
    "    type_summary = type_summary.sort_values('sharpe_ratio_mean', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸ“Š Performance by Strategy Type:\")\n",
    "    print(type_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc4431f",
   "metadata": {
    "papermill": {
     "duration": 0.001603,
     "end_time": "2025-06-25T04:42:56.078660",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.077057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5657d371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:56.082519Z",
     "iopub.status.busy": "2025-06-25T04:42:56.082407Z",
     "iopub.status.idle": "2025-06-25T04:42:56.089723Z",
     "shell.execute_reply": "2025-06-25T04:42:56.089522Z"
    },
    "papermill": {
     "duration": 0.00992,
     "end_time": "2025-06-25T04:42:56.090300",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.080380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizations for single or multiple strategy types\n",
    "if len(performance_df) > 0:\n",
    "    if performance_df['strategy_type'].nunique() > 1:\n",
    "        # Multiple strategy types - original visualization\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        \n",
    "        # Box plot of Sharpe by type\n",
    "        plt.subplot(1, 2, 1)\n",
    "        performance_df.boxplot(column='sharpe_ratio', by='strategy_type', ax=plt.gca())\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.title('Sharpe Ratio Distribution by Strategy Type')\n",
    "        plt.suptitle('')  # Remove default title\n",
    "        plt.ylabel('Sharpe Ratio')\n",
    "        \n",
    "        # Scatter: Return vs Sharpe\n",
    "        plt.subplot(1, 2, 2)\n",
    "        for stype in performance_df['strategy_type'].unique():\n",
    "            mask = performance_df['strategy_type'] == stype\n",
    "            plt.scatter(performance_df.loc[mask, 'total_return'], \n",
    "                       performance_df.loc[mask, 'sharpe_ratio'],\n",
    "                       label=stype, alpha=0.6)\n",
    "        plt.xlabel('Total Return')\n",
    "        plt.ylabel('Sharpe Ratio')\n",
    "        plt.title('Return vs Risk-Adjusted Return')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Single strategy type - parameter analysis visualization\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # 1. Sharpe ratio distribution\n",
    "        plt.subplot(2, 2, 1)\n",
    "        performance_df['sharpe_ratio'].hist(bins=20, alpha=0.7, color='blue')\n",
    "        plt.axvline(performance_df['sharpe_ratio'].mean(), color='red', linestyle='--', label=f'Mean: {performance_df[\"sharpe_ratio\"].mean():.2f}')\n",
    "        plt.axvline(performance_df['sharpe_ratio'].median(), color='green', linestyle='--', label=f'Median: {performance_df[\"sharpe_ratio\"].median():.2f}')\n",
    "        plt.xlabel('Sharpe Ratio')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Sharpe Ratio Distribution')\n",
    "        plt.legend()\n",
    "        \n",
    "        # 2. Return vs Sharpe scatter\n",
    "        plt.subplot(2, 2, 2)\n",
    "        # Determine which parameters exist (check both naming conventions)\n",
    "        param_cols = [col for col in performance_df.columns if col.startswith('param_')]\n",
    "        direct_param_cols = ['period', 'std_dev', 'fast_period', 'slow_period', 'multiplier', 'exit_threshold']\n",
    "        available_param_cols = [col for col in direct_param_cols if col in performance_df.columns]\n",
    "        \n",
    "        # Use direct parameter names if available, otherwise fall back to param_ prefix\n",
    "        if available_param_cols:\n",
    "            param_cols = available_param_cols\n",
    "        \n",
    "        if len(param_cols) >= 2:\n",
    "            # Use first two parameters for visualization\n",
    "            scatter = plt.scatter(performance_df['total_return'], \n",
    "                                 performance_df['sharpe_ratio'],\n",
    "                                 c=performance_df[param_cols[0]], \n",
    "                                 cmap='viridis',\n",
    "                                 s=performance_df[param_cols[1]]*50 if performance_df[param_cols[1]].max() < 10 else 50,\n",
    "                                 alpha=0.6)\n",
    "            plt.colorbar(scatter, label=param_cols[0].replace('param_', ''))\n",
    "            plt.title(f'Return vs Risk-Adjusted Return\\n(Color={param_cols[0].replace(\"param_\", \"\")}, Size={param_cols[1].replace(\"param_\", \"\")})')\n",
    "        else:\n",
    "            plt.scatter(performance_df['total_return'], \n",
    "                       performance_df['sharpe_ratio'],\n",
    "                       alpha=0.6)\n",
    "            plt.title('Return vs Risk-Adjusted Return')\n",
    "        plt.xlabel('Total Return')\n",
    "        plt.ylabel('Sharpe Ratio')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Parameter heatmap (if enough data and two numeric parameters)\n",
    "        if len(performance_df) > 10 and len(param_cols) >= 2:\n",
    "            plt.subplot(2, 2, 3)\n",
    "            try:\n",
    "                # Create pivot table for heatmap\n",
    "                pivot_sharpe = performance_df.pivot_table(\n",
    "                    values='sharpe_ratio', \n",
    "                    index=param_cols[0], \n",
    "                    columns=param_cols[1],\n",
    "                    aggfunc='mean'\n",
    "                )\n",
    "                if not pivot_sharpe.empty and pivot_sharpe.shape[0] > 1 and pivot_sharpe.shape[1] > 1:\n",
    "                    sns.heatmap(pivot_sharpe, cmap='RdYlGn', center=0, \n",
    "                               cbar_kws={'label': 'Sharpe Ratio'})\n",
    "                    plt.title(f'Sharpe Ratio by {param_cols[0].replace(\"param_\", \"\")} and {param_cols[1].replace(\"param_\", \"\")}')\n",
    "            except:\n",
    "                plt.text(0.5, 0.5, 'Not enough data for heatmap', \n",
    "                        ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        \n",
    "        # 4. Box plot of returns\n",
    "        plt.subplot(2, 2, 4)\n",
    "        performance_df.boxplot(column=['total_return', 'sharpe_ratio'])\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title('Performance Metrics Distribution')\n",
    "        plt.ylabel('Value')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Additional parameter analysis\n",
    "        if param_cols:\n",
    "            print(\"\\nðŸ“ˆ Parameter Analysis:\")\n",
    "            for param in param_cols[:3]:  # Analyze first 3 parameters\n",
    "                if param in performance_df.columns and performance_df[param].notna().any():\n",
    "                    corr = performance_df[param].corr(performance_df['sharpe_ratio'])\n",
    "                    param_display = param.replace('param_', '')\n",
    "                    print(f\"Correlation between {param_display} and Sharpe: {corr:.3f}\")\n",
    "            \n",
    "            # Group by parameter ranges to find stable regions\n",
    "            if len(param_cols) >= 2 and len(performance_df) > 20:\n",
    "                print(\"\\nðŸŽ¯ Performance by Parameter Ranges:\")\n",
    "                try:\n",
    "                    # Find numeric parameter columns\n",
    "                    numeric_params = []\n",
    "                    for col in param_cols:\n",
    "                        if pd.api.types.is_numeric_dtype(performance_df[col]) and performance_df[col].notna().sum() > 0:\n",
    "                            numeric_params.append(col)\n",
    "                    \n",
    "                    if len(numeric_params) >= 2:\n",
    "                        # Create bins for numeric parameters\n",
    "                        param1_groups = pd.cut(performance_df[numeric_params[0]], bins=5)\n",
    "                        param2_groups = pd.cut(performance_df[numeric_params[1]], bins=5)\n",
    "                        \n",
    "                        param_summary = performance_df.groupby([param1_groups, param2_groups])['sharpe_ratio'].agg(['mean', 'std', 'count'])\n",
    "                        param_summary = param_summary[param_summary['count'] > 0].sort_values('mean', ascending=False)\n",
    "                        \n",
    "                        # Display with clean parameter names\n",
    "                        param1_name = numeric_params[0].replace('param_', '')\n",
    "                        param2_name = numeric_params[1].replace('param_', '')\n",
    "                        print(f\"\\nTop performing {param1_name} x {param2_name} ranges:\")\n",
    "                        print(param_summary.head(10))\n",
    "                    else:\n",
    "                        print(\"Not enough numeric parameters for range analysis\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not create parameter range analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d5d50",
   "metadata": {
    "papermill": {
     "duration": 0.00159,
     "end_time": "2025-06-25T04:42:56.093973",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.092383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Correlation Analysis for Ensemble Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "349b8439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:56.097688Z",
     "iopub.status.busy": "2025-06-25T04:42:56.097599Z",
     "iopub.status.idle": "2025-06-25T04:42:56.100028Z",
     "shell.execute_reply": "2025-06-25T04:42:56.099809Z"
    },
    "papermill": {
     "duration": 0.004977,
     "end_time": "2025-06-25T04:42:56.100603",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.095626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_strategy_correlations(strategies_df, market_data, run_dir):\n",
    "    \"\"\"Calculate correlation matrix between strategies\"\"\"\n",
    "    returns_dict = {}\n",
    "    \n",
    "    for idx, row in strategies_df.iterrows():\n",
    "        try:\n",
    "            # Use the global run_dir\n",
    "            signals_path = run_dir / row['trace_path']\n",
    "            signals = pd.read_parquet(signals_path)\n",
    "            signals['ts'] = pd.to_datetime(signals['ts'])\n",
    "            \n",
    "            # Merge and calculate returns\n",
    "            df = market_data.merge(signals[['ts', 'val']], left_on='timestamp', right_on='ts', how='left')\n",
    "            df['signal'] = df['val'].ffill().fillna(0)\n",
    "            df['returns'] = df['close'].pct_change()\n",
    "            df['strategy_returns'] = df['returns'] * df['signal'].shift(1)\n",
    "            \n",
    "            returns_dict[row['strategy_hash']] = df['strategy_returns']\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Create returns DataFrame and calculate correlation\n",
    "    if returns_dict:\n",
    "        returns_df = pd.DataFrame(returns_dict)\n",
    "        return returns_df.corr()\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d67e3692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:56.104285Z",
     "iopub.status.busy": "2025-06-25T04:42:56.104176Z",
     "iopub.status.idle": "2025-06-25T04:42:56.108748Z",
     "shell.execute_reply": "2025-06-25T04:42:56.108526Z"
    },
    "papermill": {
     "duration": 0.007077,
     "end_time": "2025-06-25T04:42:56.109319",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.102242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimized correlation calculation with progress tracking\n",
    "if len(performance_df) > 0 and len(top_overall) > 1:\n",
    "    print(\"\\nðŸ”— Calculating correlations among top strategies...\")\n",
    "    print(f\"Processing {len(top_overall)} strategies...\")\n",
    "    \n",
    "    # First, load all returns data in one pass\n",
    "    returns_dict = {}\n",
    "    \n",
    "    for idx, (_, row) in enumerate(top_overall.iterrows()):\n",
    "        if idx % 5 == 0:\n",
    "            print(f\"  Loading signals: {idx}/{len(top_overall)}\")\n",
    "            \n",
    "        try:\n",
    "            signals_path = run_dir / row['trace_path']\n",
    "            \n",
    "            # Load signals\n",
    "            signals = pd.read_parquet(signals_path)\n",
    "            signals['ts'] = pd.to_datetime(signals['ts'])\n",
    "            \n",
    "            # Merge with market data (already in memory)\n",
    "            df = market_data.merge(\n",
    "                signals[['ts', 'val']], \n",
    "                left_on='timestamp', \n",
    "                right_on='ts', \n",
    "                how='left'\n",
    "            )\n",
    "            df['signal'] = df['val'].ffill().fillna(0)\n",
    "            \n",
    "            # Calculate strategy returns only once\n",
    "            df['returns'] = df['close'].pct_change()\n",
    "            df['strategy_returns'] = df['returns'] * df['signal'].shift(1)\n",
    "            \n",
    "            returns_dict[row['strategy_hash']] = df['strategy_returns'].values\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Could not load {row['strategy_hash'][:8]}: {e}\")\n",
    "    \n",
    "    print(f\"âœ… Loaded returns for {len(returns_dict)} strategies\")\n",
    "    \n",
    "    if len(returns_dict) >= 2:\n",
    "        # Convert to DataFrame for correlation calculation\n",
    "        returns_df = pd.DataFrame(returns_dict)\n",
    "        \n",
    "        # Calculate correlation matrix (this is fast once data is loaded)\n",
    "        print(\"Calculating correlation matrix...\")\n",
    "        corr_matrix = returns_df.corr()\n",
    "        \n",
    "        # Find uncorrelated pairs\n",
    "        uncorrelated_pairs = []\n",
    "        n = len(corr_matrix)\n",
    "        total_pairs = n * (n - 1) // 2\n",
    "        \n",
    "        pair_count = 0\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                pair_count += 1\n",
    "                    \n",
    "                corr_val = corr_matrix.iloc[i, j]\n",
    "                if abs(corr_val) < correlation_threshold:\n",
    "                    uncorrelated_pairs.append({\n",
    "                        'strategy1': corr_matrix.index[i],\n",
    "                        'strategy2': corr_matrix.columns[j],\n",
    "                        'correlation': corr_val\n",
    "                    })\n",
    "        \n",
    "        print(f\"âœ… Found {len(uncorrelated_pairs)} uncorrelated pairs (correlation < {correlation_threshold})\")\n",
    "        \n",
    "        # Visualize correlation matrix\n",
    "        if len(corr_matrix) <= 20:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            # Only show annotations if matrix is small enough\n",
    "            show_annot = len(corr_matrix) <= 10\n",
    "            sns.heatmap(corr_matrix, cmap='coolwarm', center=0, vmin=-1, vmax=1, \n",
    "                       xticklabels=[h[:8] for h in corr_matrix.columns],\n",
    "                       yticklabels=[h[:8] for h in corr_matrix.index],\n",
    "                       annot=show_annot, fmt='.2f' if show_annot else None)\n",
    "            plt.title('Strategy Correlation Matrix')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Show correlation statistics\n",
    "            corr_values = corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)]\n",
    "            print(f\"\\nCorrelation Statistics:\")\n",
    "            print(f\"  Mean correlation: {np.mean(corr_values):.3f}\")\n",
    "            print(f\"  Median correlation: {np.median(corr_values):.3f}\")\n",
    "            print(f\"  Min correlation: {np.min(corr_values):.3f}\")\n",
    "            print(f\"  Max correlation: {np.max(corr_values):.3f}\")\n",
    "        else:\n",
    "            print(f\"Skipping heatmap visualization (too many strategies: {len(corr_matrix)})\")\n",
    "    else:\n",
    "        print(\"âŒ Not enough strategies loaded for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc0b11",
   "metadata": {
    "papermill": {
     "duration": 0.001571,
     "end_time": "2025-06-25T04:42:56.112545",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.110974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensemble Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d41cfbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:56.116321Z",
     "iopub.status.busy": "2025-06-25T04:42:56.116232Z",
     "iopub.status.idle": "2025-06-25T04:42:56.119118Z",
     "shell.execute_reply": "2025-06-25T04:42:56.118923Z"
    },
    "papermill": {
     "duration": 0.005374,
     "end_time": "2025-06-25T04:42:56.119693",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.114319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build optimal ensemble\n",
    "if len(performance_df) > 0 and 'corr_matrix' in locals() and not corr_matrix.empty:\n",
    "    # Start with best strategy\n",
    "    ensemble = [top_overall.iloc[0]['strategy_hash']]\n",
    "    ensemble_data = [top_overall.iloc[0]]\n",
    "    \n",
    "    # Add uncorrelated strategies\n",
    "    for idx, candidate in top_overall.iloc[1:].iterrows():\n",
    "        if len(ensemble) >= ensemble_size:\n",
    "            break\n",
    "            \n",
    "        # Check correlation with existing ensemble members\n",
    "        candidate_hash = candidate['strategy_hash']\n",
    "        if candidate_hash in corr_matrix.columns:\n",
    "            max_corr = 0\n",
    "            for existing in ensemble:\n",
    "                if existing in corr_matrix.index:\n",
    "                    corr = abs(corr_matrix.loc[existing, candidate_hash])\n",
    "                    max_corr = max(max_corr, corr)\n",
    "            \n",
    "            if max_corr < correlation_threshold:\n",
    "                ensemble.append(candidate_hash)\n",
    "                ensemble_data.append(candidate)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Recommended Ensemble ({len(ensemble)} strategies):\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    ensemble_df = pd.DataFrame(ensemble_data)\n",
    "    for idx, row in ensemble_df.iterrows():\n",
    "        print(f\"\\n{idx+1}. {row['strategy_type']} - {row['strategy_hash'][:8]}\")\n",
    "        print(f\"   Sharpe: {row['sharpe_ratio']:.2f} | Return: {row['total_return']:.1%}\")\n",
    "    \n",
    "    # Calculate ensemble metrics\n",
    "    print(f\"\\nEnsemble Statistics:\")\n",
    "    print(f\"  Average Sharpe: {ensemble_df['sharpe_ratio'].mean():.2f}\")\n",
    "    print(f\"  Average Return: {ensemble_df['total_return'].mean():.1%}\")\n",
    "    print(f\"  Strategy Types: {', '.join(ensemble_df['strategy_type'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c553646e",
   "metadata": {
    "papermill": {
     "duration": 0.001641,
     "end_time": "2025-06-25T04:42:56.123225",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.121584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2cb08be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:42:56.127005Z",
     "iopub.status.busy": "2025-06-25T04:42:56.126913Z",
     "iopub.status.idle": "2025-06-25T04:42:56.130415Z",
     "shell.execute_reply": "2025-06-25T04:42:56.130211Z"
    },
    "papermill": {
     "duration": 0.006,
     "end_time": "2025-06-25T04:42:56.131034",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.125034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ No results to export\n"
     ]
    }
   ],
   "source": [
    "# Export recommendations\n",
    "if len(performance_df) > 0:\n",
    "    recommendations = {\n",
    "        'run_info': {\n",
    "            'run_id': run_dir.name,\n",
    "            'config_name': config_name,\n",
    "            'generated_at': datetime.now().isoformat(),\n",
    "            'total_strategies': len(strategy_index) if strategy_index is not None else 0,\n",
    "            'strategies_analyzed': len(performance_df)\n",
    "        },\n",
    "        'best_individual': {},\n",
    "        'best_by_type': {},\n",
    "        'ensemble': []\n",
    "    }\n",
    "    \n",
    "    # Best overall\n",
    "    if len(top_overall) > 0:\n",
    "        best = top_overall.iloc[0]\n",
    "        recommendations['best_individual'] = {\n",
    "            'strategy_hash': best['strategy_hash'],\n",
    "            'strategy_type': best['strategy_type'],\n",
    "            'sharpe_ratio': float(best['sharpe_ratio']),\n",
    "            'total_return': float(best['total_return']),\n",
    "            'max_drawdown': float(best['max_drawdown']),\n",
    "            'parameters': {col.replace('param_', ''): best[col] \n",
    "                          for col in best.index if col.startswith('param_') and pd.notna(best[col])}\n",
    "        }\n",
    "    \n",
    "    # Best by type\n",
    "    for stype in performance_df['strategy_type'].unique():\n",
    "        type_best = performance_df[performance_df['strategy_type'] == stype].nlargest(1, 'sharpe_ratio')\n",
    "        if len(type_best) > 0:\n",
    "            row = type_best.iloc[0]\n",
    "            recommendations['best_by_type'][stype] = {\n",
    "                'strategy_hash': row['strategy_hash'],\n",
    "                'sharpe_ratio': float(row['sharpe_ratio']),\n",
    "                'total_return': float(row['total_return'])\n",
    "            }\n",
    "    \n",
    "    # Ensemble\n",
    "    if 'ensemble_df' in locals():\n",
    "        for idx, row in ensemble_df.iterrows():\n",
    "            recommendations['ensemble'].append({\n",
    "                'strategy_hash': row['strategy_hash'],\n",
    "                'strategy_type': row['strategy_type'],\n",
    "                'sharpe_ratio': float(row['sharpe_ratio']),\n",
    "                'weight': 1.0 / len(ensemble_df)  # Equal weight for now\n",
    "            })\n",
    "    \n",
    "    # Save files\n",
    "    with open(run_dir / 'recommendations.json', 'w') as f:\n",
    "        json.dump(recommendations, f, indent=2)\n",
    "    \n",
    "    performance_df.to_csv(run_dir / 'performance_analysis.csv', index=False)\n",
    "    \n",
    "    print(\"\\nâœ… Results exported:\")\n",
    "    print(f\"  - recommendations.json\")\n",
    "    print(f\"  - performance_analysis.csv\")\n",
    "else:\n",
    "    print(\"âš ï¸ No results to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f14dfd",
   "metadata": {
    "papermill": {
     "duration": 0.001601,
     "end_time": "2025-06-25T04:42:56.134479",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.132878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Additional Analysis with Snippets\n",
    "\n",
    "You can now extend this analysis using pre-built snippets. Examples:\n",
    "\n",
    "### Exploratory Analysis\n",
    "```python\n",
    "%load src/analytics/snippets/exploratory/signal_frequency.py\n",
    "# Then edit parameters and run\n",
    "\n",
    "%load src/analytics/snippets/exploratory/parameter_sweep.py\n",
    "# Analyze specific strategy type parameters\n",
    "```\n",
    "\n",
    "### Ensemble Building\n",
    "```python\n",
    "%load src/analytics/snippets/ensembles/find_uncorrelated.py\n",
    "# Advanced correlation analysis\n",
    "\n",
    "%load src/analytics/snippets/ensembles/optimize_weights.py\n",
    "# Optimize portfolio weights\n",
    "```\n",
    "\n",
    "### Regime Analysis\n",
    "```python\n",
    "%load src/analytics/snippets/regime/volatility_regimes.py\n",
    "# Performance in different volatility environments\n",
    "```\n",
    "\n",
    "### Helper Functions\n",
    "```python\n",
    "%load src/analytics/snippets/helpers.py\n",
    "# Load utility functions for custom analysis\n",
    "```\n",
    "\n",
    "Each snippet contains editable parameters at the top. Modify them before running to customize the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c38266",
   "metadata": {
    "papermill": {
     "duration": 0.001612,
     "end_time": "2025-06-25T04:42:56.137934",
     "exception": false,
     "start_time": "2025-06-25T04:42:56.136322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "Analysis complete! Key files generated:\n",
    "- `recommendations.json` - Best strategies and ensemble recommendations\n",
    "- `performance_analysis.csv` - Full performance data for all strategies\n",
    "\n",
    "Next steps:\n",
    "1. Use the recommended ensemble for live trading\n",
    "2. Deep dive into specific strategy types if needed\n",
    "3. Run regime-specific analysis to understand performance drivers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.113233,
   "end_time": "2025-06-25T04:42:56.355904",
   "environment_variables": {},
   "exception": null,
   "input_path": "/Users/daws/ADMF-PC/src/analytics/templates/universal_analysis.ipynb",
   "output_path": "/Users/daws/ADMF-PC/config/bollinger/results/20250624_214106/analysis_20250624_214254.ipynb",
   "parameters": {
    "calculate_all_performance": true,
    "config_name": "bollinger",
    "correlation_threshold": 0.7,
    "ensemble_size": 5,
    "min_strategies_to_analyze": 20,
    "performance_limit": 100,
    "run_dir": "/Users/daws/ADMF-PC/config/bollinger/results/20250624_214106",
    "sharpe_threshold": 1.0,
    "symbols": [
     "SPY_5m"
    ],
    "timeframe": "5m",
    "top_n_strategies": 10
   },
   "start_time": "2025-06-25T04:42:54.242671",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}