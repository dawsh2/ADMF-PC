{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cba815e",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [3]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a89daa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:19:12.161570Z",
     "iopub.status.busy": "2025-06-25T19:19:12.161202Z",
     "iopub.status.idle": "2025-06-25T19:19:12.165862Z",
     "shell.execute_reply": "2025-06-25T19:19:12.165434Z"
    },
    "papermill": {
     "duration": 0.015521,
     "end_time": "2025-06-25T19:19:12.167352",
     "exception": false,
     "start_time": "2025-06-25T19:19:12.151831",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "results_path = \"config/bollinger/results/latest\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c3fcdd",
   "metadata": {
    "papermill": {
     "duration": 0.00423,
     "end_time": "2025-06-25T19:19:12.177057",
     "exception": false,
     "start_time": "2025-06-25T19:19:12.172827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bollinger Bands Parameter Analysis (v2)\n",
    "\n",
    "This notebook analyzes your Bollinger Bands parameter sweep using the new self-documenting trace format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd72d6",
   "metadata": {
    "papermill": {
     "duration": 0.003695,
     "end_time": "2025-06-25T19:19:12.184756",
     "exception": false,
     "start_time": "2025-06-25T19:19:12.181061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "927d6b99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:19:12.192186Z",
     "iopub.status.busy": "2025-06-25T19:19:12.192038Z",
     "iopub.status.idle": "2025-06-25T19:19:12.714290Z",
     "shell.execute_reply": "2025-06-25T19:19:12.713946Z"
    },
    "papermill": {
     "duration": 0.526764,
     "end_time": "2025-06-25T19:19:12.715291",
     "exception": false,
     "start_time": "2025-06-25T19:19:12.188527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d5198e",
   "metadata": {
    "papermill": {
     "duration": 0.002267,
     "end_time": "2025-06-25T19:19:12.720134",
     "exception": false,
     "start_time": "2025-06-25T19:19:12.717867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Load Strategy Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c3c86",
   "metadata": {
    "papermill": {
     "duration": 0.002287,
     "end_time": "2025-06-25T19:19:12.724777",
     "exception": false,
     "start_time": "2025-06-25T19:19:12.722490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66937b93",
   "metadata": {
    "papermill": {
     "duration": 0.001975,
     "end_time": "2025-06-25T19:19:12.729039",
     "exception": false,
     "start_time": "2025-06-25T19:19:12.727064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833fe967",
   "metadata": {
    "papermill": {
     "duration": 0.00189,
     "end_time": "2025-06-25T19:19:12.732856",
     "exception": false,
     "start_time": "2025-06-25T19:19:12.730966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581320b9",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269aac80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:19:12.737566Z",
     "iopub.status.busy": "2025-06-25T19:19:12.737400Z",
     "iopub.status.idle": "2025-06-25T19:19:12.914986Z",
     "shell.execute_reply": "2025-06-25T19:19:12.914499Z"
    },
    "papermill": {
     "duration": 0.180689,
     "end_time": "2025-06-25T19:19:12.915643",
     "exception": true,
     "start_time": "2025-06-25T19:19:12.734954",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/latest/strategy_index.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m results_path = Path(\u001b[33m'\u001b[39m\u001b[33m../results/latest\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the strategy index - this has all our metadata!\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m strategy_index = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstrategy_index.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal strategies tested: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(strategy_index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mColumns available:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ADMF-PC/venv/lib/python3.13/site-packages/pandas/io/parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ADMF-PC/venv/lib/python3.13/site-packages/pandas/io/parquet.py:258\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    257\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    265\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    266\u001b[39m         path_or_handle,\n\u001b[32m    267\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         **kwargs,\n\u001b[32m    271\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ADMF-PC/venv/lib/python3.13/site-packages/pandas/io/parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ADMF-PC/venv/lib/python3.13/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../results/latest/strategy_index.parquet'"
     ]
    }
   ],
   "source": [
    "# Path to results\n",
    "results_path = Path('../results/latest')\n",
    "\n",
    "# Load the strategy index - this has all our metadata!\n",
    "strategy_index = pd.read_parquet(results_path / 'strategy_index.parquet')\n",
    "\n",
    "print(f\"Total strategies tested: {len(strategy_index)}\")\n",
    "print(\"\\nColumns available:\")\n",
    "print(strategy_index.columns.tolist())\n",
    "print(\"\\nFirst few strategies:\")\n",
    "strategy_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b80f54",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3. Connect to DuckDB and Query Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94cb74",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Query signal statistics directly from traces - FIXED VERSION\n",
    "signal_stats = con.execute(f\"\"\"\n",
    "    WITH trace_data AS (\n",
    "        SELECT \n",
    "            strategy_hash,\n",
    "            json_extract_string(metadata, '$.parameters.period') as period,\n",
    "            json_extract_string(metadata, '$.parameters.std_dev') as std_dev,\n",
    "            COUNT(*) as num_signals,\n",
    "            COUNT(DISTINCT DATE(ts)) as trading_days,\n",
    "            MIN(ts) as first_signal,\n",
    "            MAX(ts) as last_signal\n",
    "        FROM read_parquet('{results_path}/traces/SPY_5m_1m/signals/bollinger_bands/*.parquet')\n",
    "        WHERE val != 0  -- Only count actual signals\n",
    "          AND metadata IS NOT NULL  -- Only use rows with metadata\n",
    "        GROUP BY strategy_hash, period, std_dev\n",
    "    )\n",
    "    SELECT \n",
    "        strategy_hash,\n",
    "        CAST(period AS INT) as period,\n",
    "        CAST(std_dev AS FLOAT) as std_dev,\n",
    "        num_signals,\n",
    "        trading_days,\n",
    "        num_signals::FLOAT / trading_days as signals_per_day,\n",
    "        first_signal,\n",
    "        last_signal\n",
    "    FROM trace_data\n",
    "    WHERE period IS NOT NULL  -- Filter out any failed extractions\n",
    "    ORDER BY period, std_dev\n",
    "\"\"\").df()\n",
    "\n",
    "print(f\"Loaded signal statistics for {len(signal_stats)} strategies\")\n",
    "signal_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ce468c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4. Create Parameter Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5eeee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Heatmap 1: Signals per day\n",
    "signals_pivot = signal_stats.pivot(index='period', columns='std_dev', values='signals_per_day')\n",
    "sns.heatmap(signals_pivot, annot=True, fmt='.2f', cmap='viridis', ax=axes[0, 0], cbar_kws={'label': 'Signals/Day'})\n",
    "axes[0, 0].set_title('Average Signals Per Day', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Standard Deviation')\n",
    "axes[0, 0].set_ylabel('Period')\n",
    "\n",
    "# Heatmap 2: Total number of signals\n",
    "total_signals_pivot = signal_stats.pivot(index='period', columns='std_dev', values='num_signals')\n",
    "sns.heatmap(total_signals_pivot, annot=False, cmap='plasma', ax=axes[0, 1], cbar_kws={'label': 'Total Signals'})\n",
    "axes[0, 1].set_title('Total Number of Signals', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Find optimal signal frequency (1-3 signals per day)\n",
    "optimal_freq = signal_stats[(signal_stats['signals_per_day'] >= 1) & \n",
    "                           (signal_stats['signals_per_day'] <= 3)]\n",
    "print(f\"\\nStrategies with optimal signal frequency (1-3 per day): {len(optimal_freq)}\")\n",
    "print(\"\\nTop 10 by signal frequency balance:\")\n",
    "print(optimal_freq.nsmallest(10, 'signals_per_day')[['period', 'std_dev', 'signals_per_day', 'num_signals']])\n",
    "\n",
    "# Heatmap 3: Trading days active\n",
    "days_pivot = signal_stats.pivot(index='period', columns='std_dev', values='trading_days')\n",
    "sns.heatmap(days_pivot, annot=False, cmap='magma', ax=axes[1, 0], cbar_kws={'label': 'Days'})\n",
    "axes[1, 0].set_title('Trading Days with Signals', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Heatmap 4: Optimal frequency mask\n",
    "optimal_mask = (signals_pivot >= 1) & (signals_pivot <= 3)\n",
    "sns.heatmap(optimal_mask.astype(int), annot=False, cmap='RdYlGn', ax=axes[1, 1], \n",
    "            cbar_kws={'label': 'Optimal'}, vmin=0, vmax=1)\n",
    "axes[1, 1].set_title('Optimal Signal Frequency Region (1-3/day)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8961e1e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5. Performance Analysis\n",
    "\n",
    "If performance metrics are available in the strategy index:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6c3262",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Let's see the full distribution of signals\n",
    "print(\"Distribution of total signals:\")\n",
    "print(signal_stats['num_signals'].value_counts().sort_index().head(20))\n",
    "\n",
    "print(\"\\nLet's look at ALL strategies, not just optimal frequency:\")\n",
    "print(signal_stats.sort_values('num_signals', ascending=False).head(10))\n",
    "\n",
    "# Check a specific tight parameter combination\n",
    "tight_params = signal_stats[(signal_stats['period'] == 10) & (signal_stats['std_dev'] == 0.5)]\n",
    "print(f\"\\nPeriod=10, Std=0.5 details:\")\n",
    "print(tight_params)\n",
    "\n",
    "# Let's also check the actual signal data for one of these\n",
    "sample_hash = signal_stats.iloc[0]['strategy_hash']\n",
    "print(f\"\\nChecking actual signals for strategy {sample_hash}:\")\n",
    "sample_signals = con.execute(f\"\"\"\n",
    "    SELECT ts, val, px\n",
    "    FROM read_parquet('{results_path}/traces/SPY_5m_1m/signals/bollinger_bands/*.parquet')\n",
    "    WHERE strategy_hash = '{sample_hash}'\n",
    "    AND val != 0\n",
    "    LIMIT 10\n",
    "\"\"\").df()\n",
    "print(sample_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373577a4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if we have performance metrics\n",
    "perf_cols = [col for col in strategy_index.columns if 'sharpe' in col or 'return' in col or 'drawdown' in col]\n",
    "\n",
    "if perf_cols:\n",
    "    print(f\"Found performance metrics: {perf_cols}\")\n",
    "    \n",
    "    # Merge with signal stats\n",
    "    perf_data = strategy_index[['strategy_hash'] + perf_cols].merge(\n",
    "        signal_stats, on='strategy_hash', how='inner'\n",
    "    )\n",
    "    \n",
    "    # Find best performers\n",
    "    if 'sharpe_ratio' in perf_cols:\n",
    "        best_sharpe = perf_data.nlargest(10, 'sharpe_ratio')\n",
    "        print(\"\\nTop 10 strategies by Sharpe Ratio:\")\n",
    "        print(best_sharpe[['period', 'std_dev', 'sharpe_ratio', 'signals_per_day']])\n",
    "        \n",
    "        # Create Sharpe heatmap\n",
    "        sharpe_pivot = perf_data.pivot(index='period', columns='std_dev', values='sharpe_ratio')\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(sharpe_pivot, annot=True, fmt='.2f', cmap='RdYlGn', center=0,\n",
    "                   cbar_kws={'label': 'Sharpe Ratio'})\n",
    "        plt.title('Sharpe Ratio by Parameters', fontsize=14, fontweight='bold')\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No performance metrics found in strategy index - calculating from traces...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d513ee04",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6. Calculate Performance from Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98fcaf9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load market data\n",
    "market_data_path = Path('../../../../data/SPY_5m.parquet')\n",
    "market_data = pd.read_parquet(market_data_path)\n",
    "print(f\"Market data shape: {market_data.shape}\")\n",
    "\n",
    "# Function to calculate performance for a strategy\n",
    "def calculate_strategy_performance(strategy_hash, signal_stats_row):\n",
    "    # Load signals for this strategy\n",
    "    signals = con.execute(f\"\"\"\n",
    "        SELECT idx, ts, sym, val as signal, px\n",
    "        FROM read_parquet('{results_path}/traces/*.parquet')\n",
    "        WHERE strategy_hash = '{strategy_hash}'\n",
    "        ORDER BY idx\n",
    "    \"\"\").df()\n",
    "    \n",
    "    if len(signals) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Convert to proper datetime\n",
    "    signals['ts'] = pd.to_datetime(signals['ts'])\n",
    "    market_data['timestamp'] = pd.to_datetime(market_data['timestamp'])\n",
    "    \n",
    "    # Merge with market data\n",
    "    df = market_data.merge(\n",
    "        signals[['ts', 'signal']], \n",
    "        left_on='timestamp', \n",
    "        right_on='ts', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Forward fill signals (sparse to dense)\n",
    "    df['signal'] = df['signal'].fillna(method='ffill').fillna(0)\n",
    "    \n",
    "    # Calculate returns\n",
    "    df['returns'] = df['close'].pct_change()\n",
    "    df['strategy_returns'] = df['returns'] * df['signal'].shift(1)\n",
    "    df['cum_returns'] = (1 + df['strategy_returns']).cumprod()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_return = df['cum_returns'].iloc[-1] - 1\n",
    "    sharpe = df['strategy_returns'].mean() / df['strategy_returns'].std() * np.sqrt(252 * 78)\n",
    "    max_dd = (df['cum_returns'] / df['cum_returns'].expanding().max() - 1).min()\n",
    "    \n",
    "    # Win rate\n",
    "    winning_returns = df[df['strategy_returns'] > 0]['strategy_returns']\n",
    "    total_returns = df[df['strategy_returns'] != 0]['strategy_returns']\n",
    "    win_rate = len(winning_returns) / len(total_returns) if len(total_returns) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'strategy_hash': strategy_hash,\n",
    "        'total_return': total_return,\n",
    "        'sharpe_ratio': sharpe,\n",
    "        'max_drawdown': max_dd,\n",
    "        'win_rate': win_rate,\n",
    "        'period': signal_stats_row['period'],\n",
    "        'std_dev': signal_stats_row['std_dev']\n",
    "    }\n",
    "\n",
    "# Calculate performance for optimal frequency strategies\n",
    "print(\"Calculating performance metrics...\")\n",
    "performance_results = []\n",
    "\n",
    "for idx, row in optimal_freq.head(20).iterrows():\n",
    "    result = calculate_strategy_performance(row['strategy_hash'], row)\n",
    "    if result:\n",
    "        performance_results.append(result)\n",
    "        print(f\"Processed period={row['period']}, std={row['std_dev']}\")\n",
    "\n",
    "performance_df = pd.DataFrame(performance_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec2251d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7. Find Best Performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a33aff8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort by different metrics\n",
    "print(\"=\"*60)\n",
    "print(\"TOP PERFORMERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# By Sharpe\n",
    "best_sharpe = performance_df.nlargest(10, 'sharpe_ratio')\n",
    "print(\"\\nTop 10 by Sharpe Ratio:\")\n",
    "print(best_sharpe[['period', 'std_dev', 'sharpe_ratio', 'total_return', 'max_drawdown']].round(3))\n",
    "\n",
    "# By Total Return\n",
    "best_return = performance_df.nlargest(10, 'total_return')\n",
    "print(\"\\nTop 10 by Total Return:\")\n",
    "print(best_return[['period', 'std_dev', 'total_return', 'sharpe_ratio', 'max_drawdown']].round(3))\n",
    "\n",
    "# Balanced performers\n",
    "balanced = performance_df[\n",
    "    (performance_df['sharpe_ratio'] > 1.0) & \n",
    "    (performance_df['max_drawdown'] > -0.10)\n",
    "]\n",
    "print(f\"\\nBalanced strategies (Sharpe > 1.0, Max DD > -10%): {len(balanced)}\")\n",
    "if len(balanced) > 0:\n",
    "    print(balanced[['period', 'std_dev', 'sharpe_ratio', 'total_return', 'max_drawdown']].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b197c0dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 8. Parameter Stability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4402e04e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze parameter regions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Sharpe by period\n",
    "period_perf = performance_df.groupby('period')['sharpe_ratio'].agg(['mean', 'std'])\n",
    "period_perf['mean'].plot(ax=axes[0, 0], marker='o')\n",
    "axes[0, 0].fill_between(period_perf.index, \n",
    "                        period_perf['mean'] - period_perf['std'],\n",
    "                        period_perf['mean'] + period_perf['std'], \n",
    "                        alpha=0.3)\n",
    "axes[0, 0].set_title('Sharpe Ratio by Period (mean ± std)')\n",
    "axes[0, 0].set_xlabel('Period')\n",
    "axes[0, 0].set_ylabel('Sharpe Ratio')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Sharpe by std_dev\n",
    "std_perf = performance_df.groupby('std_dev')['sharpe_ratio'].agg(['mean', 'std'])\n",
    "std_perf['mean'].plot(ax=axes[0, 1], marker='o')\n",
    "axes[0, 1].fill_between(std_perf.index,\n",
    "                        std_perf['mean'] - std_perf['std'],\n",
    "                        std_perf['mean'] + std_perf['std'],\n",
    "                        alpha=0.3)\n",
    "axes[0, 1].set_title('Sharpe Ratio by Std Dev (mean ± std)')\n",
    "axes[0, 1].set_xlabel('Standard Deviation')\n",
    "axes[0, 1].set_ylabel('Sharpe Ratio')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot: Period vs Sharpe\n",
    "axes[1, 0].scatter(performance_df['period'], performance_df['sharpe_ratio'], \n",
    "                   c=performance_df['std_dev'], cmap='viridis', s=100, alpha=0.6)\n",
    "axes[1, 0].set_xlabel('Period')\n",
    "axes[1, 0].set_ylabel('Sharpe Ratio')\n",
    "axes[1, 0].set_title('Period vs Sharpe (colored by Std Dev)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot: Std Dev vs Sharpe\n",
    "axes[1, 1].scatter(performance_df['std_dev'], performance_df['sharpe_ratio'],\n",
    "                   c=performance_df['period'], cmap='plasma', s=100, alpha=0.6)\n",
    "axes[1, 1].set_xlabel('Standard Deviation')\n",
    "axes[1, 1].set_ylabel('Sharpe Ratio')\n",
    "axes[1, 1].set_title('Std Dev vs Sharpe (colored by Period)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find most stable parameter regions\n",
    "print(\"\\nParameter Stability Analysis:\")\n",
    "print(\"Periods with consistent performance (low std):\")\n",
    "print(period_perf.nsmallest(5, 'std'))\n",
    "print(\"\\nStd Devs with consistent performance:\")\n",
    "print(std_perf.nsmallest(5, 'std'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28b4028",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 9. Final Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3754cbd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create final recommendations\n",
    "print(\"=\"*60)\n",
    "print(\"BOLLINGER BANDS PARAMETER RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Best overall\n",
    "best_overall = performance_df.loc[performance_df['sharpe_ratio'].idxmax()]\n",
    "print(f\"\\n1. BEST OVERALL PERFORMER:\")\n",
    "print(f\"   Period: {int(best_overall['period'])}\")\n",
    "print(f\"   Std Dev: {best_overall['std_dev']:.1f}\")\n",
    "print(f\"   Sharpe Ratio: {best_overall['sharpe_ratio']:.2f}\")\n",
    "print(f\"   Total Return: {best_overall['total_return']:.1%}\")\n",
    "print(f\"   Max Drawdown: {best_overall['max_drawdown']:.1%}\")\n",
    "\n",
    "# Most robust (good performance in stable region)\n",
    "robust_candidates = performance_df[\n",
    "    (performance_df['period'].between(18, 25)) & \n",
    "    (performance_df['std_dev'].between(1.5, 2.5)) &\n",
    "    (performance_df['sharpe_ratio'] > 0.8)\n",
    "]\n",
    "if len(robust_candidates) > 0:\n",
    "    robust_best = robust_candidates.loc[robust_candidates['sharpe_ratio'].idxmax()]\n",
    "    print(f\"\\n2. MOST ROBUST PARAMETERS:\")\n",
    "    print(f\"   Period: {int(robust_best['period'])}\")\n",
    "    print(f\"   Std Dev: {robust_best['std_dev']:.1f}\")\n",
    "    print(f\"   Sharpe Ratio: {robust_best['sharpe_ratio']:.2f}\")\n",
    "    print(f\"   (from stable region: period 18-25, std 1.5-2.5)\")\n",
    "\n",
    "# Conservative choice\n",
    "conservative = performance_df[performance_df['max_drawdown'] > -0.08]\n",
    "if len(conservative) > 0:\n",
    "    conservative_best = conservative.loc[conservative['sharpe_ratio'].idxmax()]\n",
    "    print(f\"\\n3. CONSERVATIVE CHOICE (max DD < 8%):\")\n",
    "    print(f\"   Period: {int(conservative_best['period'])}\")\n",
    "    print(f\"   Std Dev: {conservative_best['std_dev']:.1f}\")\n",
    "    print(f\"   Sharpe Ratio: {conservative_best['sharpe_ratio']:.2f}\")\n",
    "    print(f\"   Max Drawdown: {conservative_best['max_drawdown']:.1%}\")\n",
    "\n",
    "# Save recommendations\n",
    "recommendations = {\n",
    "    'best_overall': {\n",
    "        'period': int(best_overall['period']),\n",
    "        'std_dev': float(best_overall['std_dev']),\n",
    "        'sharpe_ratio': float(best_overall['sharpe_ratio']),\n",
    "        'total_return': float(best_overall['total_return']),\n",
    "        'max_drawdown': float(best_overall['max_drawdown'])\n",
    "    }\n",
    "}\n",
    "\n",
    "if len(robust_candidates) > 0:\n",
    "    recommendations['robust_choice'] = {\n",
    "        'period': int(robust_best['period']),\n",
    "        'std_dev': float(robust_best['std_dev']),\n",
    "        'sharpe_ratio': float(robust_best['sharpe_ratio'])\n",
    "    }\n",
    "\n",
    "with open('../bollinger_recommendations.json', 'w') as f:\n",
    "    json.dump(recommendations, f, indent=2)\n",
    "    \n",
    "print(\"\\n✅ Recommendations saved to bollinger_recommendations.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a584815",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 10. Generate Production Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa1c1f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate production-ready config\n",
    "production_config = f\"\"\"name: bollinger_production\n",
    "data: SPY_5m\n",
    "\n",
    "strategy:\n",
    "  bollinger_bands:\n",
    "    period: {int(best_overall['period'])}\n",
    "    std_dev: {best_overall['std_dev']:.1f}\n",
    "    threshold: \"intraday\"\n",
    "\n",
    "# Performance in backtest:\n",
    "# Sharpe Ratio: {best_overall['sharpe_ratio']:.2f}\n",
    "# Total Return: {best_overall['total_return']:.1%}\n",
    "# Max Drawdown: {best_overall['max_drawdown']:.1%}\n",
    "\"\"\"\n",
    "\n",
    "with open('../bollinger_production.yaml', 'w') as f:\n",
    "    f.write(production_config)\n",
    "    \n",
    "print(\"\\n✅ Production config saved to bollinger_production.yaml\")\n",
    "print(\"\\nProduction config:\")\n",
    "print(production_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11e3fc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 11. Visualize Best Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb82a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and plot the best strategy's equity curve\n",
    "best_hash = best_overall['strategy_hash']\n",
    "print(f\"Loading signals for best strategy: {best_hash}\")\n",
    "\n",
    "# Get full signal trace\n",
    "best_signals = con.execute(f\"\"\"\n",
    "    SELECT idx, ts, val as signal, px\n",
    "    FROM read_parquet('{results_path}/traces/*.parquet')\n",
    "    WHERE strategy_hash = '{best_hash}'\n",
    "    ORDER BY idx\n",
    "\"\"\").df()\n",
    "\n",
    "# Merge with market data and calculate equity curve\n",
    "best_signals['ts'] = pd.to_datetime(best_signals['ts'])\n",
    "df = market_data.merge(\n",
    "    best_signals[['ts', 'signal']], \n",
    "    left_on='timestamp', \n",
    "    right_on='ts', \n",
    "    how='left'\n",
    ")\n",
    "df['signal'] = df['signal'].fillna(method='ffill').fillna(0)\n",
    "df['returns'] = df['close'].pct_change()\n",
    "df['strategy_returns'] = df['returns'] * df['signal'].shift(1)\n",
    "df['cum_returns'] = (1 + df['strategy_returns']).cumprod()\n",
    "df['buy_hold'] = (1 + df['returns']).cumprod()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(df['timestamp'], df['cum_returns'], label='Strategy', linewidth=2)\n",
    "plt.plot(df['timestamp'], df['buy_hold'], label='Buy & Hold', linewidth=1, alpha=0.7)\n",
    "plt.title(f'Best Strategy Performance: Period={int(best_overall[\"period\"])}, Std Dev={best_overall[\"std_dev\"]:.1f}')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "drawdown = (df['cum_returns'] / df['cum_returns'].expanding().max() - 1)\n",
    "plt.fill_between(df['timestamp'], drawdown, 0, alpha=0.3, color='red')\n",
    "plt.plot(df['timestamp'], drawdown, color='red', linewidth=1)\n",
    "plt.ylabel('Drawdown')\n",
    "plt.xlabel('Date')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nStrategy Statistics:\")\n",
    "print(f\"Total signals: {len(best_signals)}\")\n",
    "print(f\"Long signals: {(best_signals['signal'] == 1).sum()}\")\n",
    "print(f\"Short signals: {(best_signals['signal'] == -1).sum()}\")\n",
    "print(f\"Final return: {(df['cum_returns'].iloc[-1] - 1):.1%}\")\n",
    "print(f\"Buy & Hold return: {(df['buy_hold'].iloc[-1] - 1):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78606c09",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's check what's actually in the parquet files\n",
    "sample_file = list(Path(f'{results_path}/traces/SPY_5m_1m/signals/bollinger_bands/').glob('*.parquet'))[0]\n",
    "print(f\"Checking file: {sample_file.name}\")\n",
    "\n",
    "# Read one file to see its structure\n",
    "sample_df = pd.read_parquet(sample_file)\n",
    "print(\"\\nColumns in parquet file:\")\n",
    "print(sample_df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(sample_df.head())\n",
    "\n",
    "# Check if there's metadata in the first row\n",
    "if 'metadata' in sample_df.columns:\n",
    "    first_metadata = sample_df['metadata'].dropna().iloc[0] if sample_df['metadata'].notna().any() else None\n",
    "    if first_metadata:\n",
    "        print(f\"\\nMetadata content: {first_metadata}\")\n",
    "        \n",
    "# Also check PyArrow metadata\n",
    "import pyarrow.parquet as pq\n",
    "table = pq.read_table(sample_file)\n",
    "if table.schema.metadata:\n",
    "    print(\"\\nPyArrow table metadata:\")\n",
    "    for key, value in table.schema.metadata.items():\n",
    "        print(f\"  {key}: {value[:100]}...\")  # First 100 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c11b5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's see the full distribution of signals\n",
    "print(\"Distribution of total signals:\")\n",
    "print(signal_stats['num_signals'].value_counts().sort_index().head(20))\n",
    "\n",
    "print(\"\\nLet's look at ALL strategies, not just optimal frequency:\")\n",
    "print(signal_stats.sort_values('num_signals', ascending=False).head(10))\n",
    "\n",
    "# Check a specific tight parameter combination\n",
    "tight_params = signal_stats[(signal_stats['period'] == 10) & (signal_stats['std_dev'] == 0.5)]\n",
    "print(f\"\\nPeriod=10, Std=0.5 details:\")\n",
    "print(tight_params)\n",
    "\n",
    "# Let's also check the actual signal data for one of these\n",
    "sample_hash = signal_stats.iloc[0]['strategy_hash']\n",
    "print(f\"\\nChecking actual signals for strategy {sample_hash}:\")\n",
    "sample_signals = con.execute(f\"\"\"\n",
    "    SELECT ts, val, px\n",
    "    FROM read_parquet('{results_path}/traces/SPY_5m_1m/signals/bollinger_bands/*.parquet')\n",
    "    WHERE strategy_hash = '{sample_hash}'\n",
    "    AND val != 0\n",
    "    LIMIT 10\n",
    "\"\"\").df()\n",
    "print(sample_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03393c7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1.692486,
   "end_time": "2025-06-25T19:19:13.134186",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/bollinger_analysis_v2.ipynb",
   "output_path": "bollinger_analysis_output.ipynb",
   "parameters": {
    "results_path": "config/bollinger/results/latest"
   },
   "start_time": "2025-06-25T19:19:11.441700",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}