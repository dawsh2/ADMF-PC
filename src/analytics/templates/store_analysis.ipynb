{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store-Based Strategy Analysis\n",
    "\n",
    "This notebook demonstrates run-invariant analysis by querying the global strategy store directly.\n",
    "No run IDs or run directories required - just query by strategy type and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["parameters"]
   },
   "outputs": [],
   "source": [
    "# Parameters - these can be set by papermill or manually\n",
    "strategy_type = 'bollinger_bands'  # Query specific strategy type\n",
    "symbol = 'SPY'  # Optional: filter by symbol\n",
    "timeframe = '5m'  # Optional: filter by timeframe\n",
    "min_strategies = 5  # Minimum strategies needed for analysis\n",
    "performance_limit = 100  # Max strategies to calculate detailed performance for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import analytics modules\n",
    "from src.analytics.modules.core import (\n",
    "    load_global_traces,\n",
    "    load_strategy_index,\n",
    "    load_market_data,\n",
    "    calculate_returns\n",
    ")\n",
    "\n",
    "from src.analytics.modules.signal_analysis import (\n",
    "    count_signals,\n",
    "    calculate_signal_persistence,\n",
    "    analyze_signal_patterns\n",
    ")\n",
    "\n",
    "from src.analytics.modules.performance import (\n",
    "    calculate_strategy_performance,\n",
    "    calculate_ensemble_sharpe\n",
    ")\n",
    "\n",
    "from src.analytics.modules.visualization import (\n",
    "    plot_signal_heatmap,\n",
    "    plot_performance_distribution,\n",
    "    plot_parameter_sensitivity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Query Strategy Store\n",
    "\n",
    "Load strategies directly from the global store by type and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the strategy index to see what's available\n",
    "strategy_index = load_strategy_index()\n",
    "\n",
    "print(f\"Total strategies in store: {len(strategy_index)}\")\n",
    "print(f\"\\nStrategy types available:\")\n",
    "print(strategy_index['strategy_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter strategies based on our criteria\n",
    "filtered_strategies = strategy_index.copy()\n",
    "\n",
    "# Apply filters\n",
    "if strategy_type and strategy_type != 'all':\n",
    "    filtered_strategies = filtered_strategies[filtered_strategies['strategy_type'] == strategy_type]\n",
    "    print(f\"Filtered to {strategy_type}: {len(filtered_strategies)} strategies\")\n",
    "\n",
    "if symbol:\n",
    "    filtered_strategies = filtered_strategies[filtered_strategies['symbol'] == symbol]\n",
    "    print(f\"Filtered to {symbol}: {len(filtered_strategies)} strategies\")\n",
    "\n",
    "if timeframe:\n",
    "    filtered_strategies = filtered_strategies[filtered_strategies['timeframe'] == timeframe]\n",
    "    print(f\"Filtered to {timeframe}: {len(filtered_strategies)} strategies\")\n",
    "\n",
    "print(f\"\\nTotal matching strategies: {len(filtered_strategies)}\")\n",
    "\n",
    "if len(filtered_strategies) == 0:\n",
    "    print(\"\\nNo strategies match the criteria!\")\n",
    "    print(\"\\nAvailable combinations:\")\n",
    "    print(strategy_index.groupby(['strategy_type', 'symbol', 'timeframe']).size().to_frame('count'))\n",
    "elif len(filtered_strategies) < min_strategies:\n",
    "    print(f\"\\nWarning: Only {len(filtered_strategies)} strategies found (minimum {min_strategies} required)\")\n",
    "    print(\"Consider broadening your search criteria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show parameter distributions for filtered strategies\n",
    "if len(filtered_strategies) > 0:\n",
    "    print(\"\\nParameter columns found:\")\n",
    "    param_cols = [col for col in filtered_strategies.columns \n",
    "                  if col not in ['strategy_hash', 'strategy_type', 'component_type', \n",
    "                                'symbol', 'timeframe', 'constraints', 'trace_path', \n",
    "                                'first_seen', 'full_config']]\n",
    "    \n",
    "    for col in param_cols:\n",
    "        if pd.api.types.is_numeric_dtype(filtered_strategies[col]):\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(filtered_strategies[col].describe())\n",
    "        else:\n",
    "            print(f\"\\n{col}: {filtered_strategies[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Signal Data\n",
    "\n",
    "Load the actual signal traces for our filtered strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load signals for all matching strategies\n",
    "if len(filtered_strategies) > 0:\n",
    "    print(\"Loading signal data...\")\n",
    "    \n",
    "    all_signals = []\n",
    "    for idx, strategy in filtered_strategies.iterrows():\n",
    "        try:\n",
    "            signals = load_global_traces(strategy_hash=strategy['strategy_hash'])\n",
    "            if not signals.empty:\n",
    "                # Add strategy metadata to signals\n",
    "                signals['strategy_hash'] = strategy['strategy_hash']\n",
    "                signals['strategy_type'] = strategy['strategy_type']\n",
    "                \n",
    "                # Add parameters as columns\n",
    "                for col in param_cols:\n",
    "                    if col in strategy:\n",
    "                        signals[col] = strategy[col]\n",
    "                \n",
    "                all_signals.append(signals)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {strategy['strategy_hash']}: {e}\")\n",
    "    \n",
    "    if all_signals:\n",
    "        combined_signals = pd.concat(all_signals, ignore_index=True)\n",
    "        print(f\"\\nLoaded {len(combined_signals):,} signal records from {len(all_signals)} strategies\")\n",
    "        \n",
    "        # Convert timestamp to datetime\n",
    "        combined_signals['timestamp'] = pd.to_datetime(combined_signals['timestamp'])\n",
    "        \n",
    "        # Show date range\n",
    "        print(f\"Date range: {combined_signals['timestamp'].min()} to {combined_signals['timestamp'].max()}\")\n",
    "    else:\n",
    "        print(\"No signal data could be loaded!\")\n",
    "        combined_signals = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Signal Analysis\n",
    "\n",
    "Analyze the signals without needing market data or execution results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count signals by strategy\n",
    "if not combined_signals.empty:\n",
    "    signal_counts = combined_signals.groupby('strategy_hash').agg({\n",
    "        'signal': 'count',\n",
    "        'direction': lambda x: (x != 'flat').sum()\n",
    "    }).rename(columns={'signal': 'total_bars', 'direction': 'active_signals'})\n",
    "    \n",
    "    signal_counts['signal_rate'] = signal_counts['active_signals'] / signal_counts['total_bars']\n",
    "    \n",
    "    # Add strategy info\n",
    "    signal_counts = signal_counts.merge(\n",
    "        filtered_strategies[['strategy_hash'] + param_cols],\n",
    "        left_index=True,\n",
    "        right_on='strategy_hash'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nSignal Statistics by Strategy:\")\n",
    "    print(signal_counts.sort_values('signal_rate', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze signal patterns\n",
    "if not combined_signals.empty:\n",
    "    # Group by strategy and analyze patterns\n",
    "    pattern_results = []\n",
    "    \n",
    "    for strategy_hash in combined_signals['strategy_hash'].unique():\n",
    "        strategy_signals = combined_signals[combined_signals['strategy_hash'] == strategy_hash]\n",
    "        \n",
    "        # Calculate signal persistence\n",
    "        persistence = calculate_signal_persistence(strategy_signals)\n",
    "        \n",
    "        # Get pattern statistics\n",
    "        patterns = analyze_signal_patterns(strategy_signals)\n",
    "        \n",
    "        pattern_results.append({\n",
    "            'strategy_hash': strategy_hash,\n",
    "            'avg_signal_duration': persistence['avg_duration'],\n",
    "            'max_signal_duration': persistence['max_duration'],\n",
    "            'num_signal_changes': patterns['num_changes'],\n",
    "            'long_ratio': patterns['long_ratio'],\n",
    "            'short_ratio': patterns['short_ratio']\n",
    "        })\n",
    "    \n",
    "    pattern_df = pd.DataFrame(pattern_results)\n",
    "    \n",
    "    # Add strategy metadata\n",
    "    pattern_df = pattern_df.merge(\n",
    "        filtered_strategies[['strategy_hash'] + param_cols],\n",
    "        on='strategy_hash'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nSignal Pattern Analysis:\")\n",
    "    print(pattern_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parameter Analysis\n",
    "\n",
    "Analyze how parameters affect signal generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze parameter relationships\n",
    "if len(pattern_df) > 5 and param_cols:\n",
    "    # Find numeric parameters\n",
    "    numeric_params = [col for col in param_cols \n",
    "                     if pd.api.types.is_numeric_dtype(pattern_df[col])]\n",
    "    \n",
    "    if numeric_params:\n",
    "        # Create parameter sensitivity plots\n",
    "        fig, axes = plt.subplots(len(numeric_params), 2, figsize=(15, 5*len(numeric_params)))\n",
    "        if len(numeric_params) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, param in enumerate(numeric_params):\n",
    "            # Signal rate vs parameter\n",
    "            signal_param_df = signal_counts[[param, 'signal_rate']].dropna()\n",
    "            if len(signal_param_df) > 0:\n",
    "                axes[i, 0].scatter(signal_param_df[param], signal_param_df['signal_rate'], alpha=0.6)\n",
    "                axes[i, 0].set_xlabel(param)\n",
    "                axes[i, 0].set_ylabel('Signal Rate')\n",
    "                axes[i, 0].set_title(f'Signal Rate vs {param}')\n",
    "            \n",
    "            # Duration vs parameter\n",
    "            duration_param_df = pattern_df[[param, 'avg_signal_duration']].dropna()\n",
    "            if len(duration_param_df) > 0:\n",
    "                axes[i, 1].scatter(duration_param_df[param], duration_param_df['avg_signal_duration'], alpha=0.6)\n",
    "                axes[i, 1].set_xlabel(param)\n",
    "                axes[i, 1].set_ylabel('Avg Signal Duration')\n",
    "                axes[i, 1].set_title(f'Signal Duration vs {param}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Signal Correlation Analysis\n",
    "\n",
    "Analyze correlations between different parameter configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate signal correlation matrix\n",
    "if len(all_signals) > 5:\n",
    "    print(\"Calculating signal correlations...\")\n",
    "    \n",
    "    # Pivot signals to wide format\n",
    "    signal_matrix = []\n",
    "    strategy_info = []\n",
    "    \n",
    "    for signals in all_signals[:min(50, len(all_signals))]:  # Limit to 50 for performance\n",
    "        if not signals.empty:\n",
    "            strategy_hash = signals['strategy_hash'].iloc[0]\n",
    "            # Convert directions to numeric\n",
    "            signal_series = signals.set_index('timestamp')['direction'].map(\n",
    "                {'long': 1, 'short': -1, 'flat': 0}\n",
    "            ).fillna(0)\n",
    "            \n",
    "            signal_matrix.append(signal_series)\n",
    "            strategy_info.append(strategy_hash)\n",
    "    \n",
    "    if signal_matrix:\n",
    "        # Align all series to same index\n",
    "        signal_df = pd.DataFrame(signal_matrix).T\n",
    "        signal_df.columns = strategy_info\n",
    "        \n",
    "        # Calculate correlation\n",
    "        corr_matrix = signal_df.corr()\n",
    "        \n",
    "        # Plot correlation heatmap\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        mask = np.triu(np.ones_like(corr_matrix), k=1)\n",
    "        sns.heatmap(corr_matrix, mask=mask, cmap='coolwarm', center=0, \n",
    "                   vmin=-1, vmax=1, square=True, linewidths=0.5,\n",
    "                   cbar_kws={\"shrink\": 0.8})\n",
    "        plt.title(f'{strategy_type} Strategy Signal Correlations')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Find low correlation pairs\n",
    "        low_corr_threshold = 0.3\n",
    "        low_corr_pairs = []\n",
    "        \n",
    "        for i in range(len(corr_matrix)):\n",
    "            for j in range(i+1, len(corr_matrix)):\n",
    "                if abs(corr_matrix.iloc[i, j]) < low_corr_threshold:\n",
    "                    low_corr_pairs.append({\n",
    "                        'strategy1': corr_matrix.index[i],\n",
    "                        'strategy2': corr_matrix.index[j],\n",
    "                        'correlation': corr_matrix.iloc[i, j]\n",
    "                    })\n",
    "        \n",
    "        print(f\"\\nFound {len(low_corr_pairs)} low-correlation strategy pairs (< {low_corr_threshold})\")\n",
    "        if low_corr_pairs:\n",
    "            print(\"\\nTop diversification candidates:\")\n",
    "            print(pd.DataFrame(low_corr_pairs).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Estimation (Optional)\n",
    "\n",
    "If we have market data available, we can estimate performance without execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load market data for performance estimation\n",
    "if not combined_signals.empty and symbol:\n",
    "    try:\n",
    "        print(f\"\\nAttempting to load market data for {symbol}...\")\n",
    "        market_data = load_market_data(symbol)\n",
    "        \n",
    "        if not market_data.empty:\n",
    "            print(f\"Loaded {len(market_data):,} bars of market data\")\n",
    "            \n",
    "            # Calculate performance for a subset of strategies\n",
    "            perf_results = []\n",
    "            strategies_to_analyze = min(performance_limit, len(all_signals))\n",
    "            \n",
    "            print(f\"\\nCalculating performance for {strategies_to_analyze} strategies...\")\n",
    "            \n",
    "            for i, signals in enumerate(all_signals[:strategies_to_analyze]):\n",
    "                if not signals.empty:\n",
    "                    try:\n",
    "                        strategy_hash = signals['strategy_hash'].iloc[0]\n",
    "                        perf = calculate_strategy_performance(\n",
    "                            signals, \n",
    "                            market_data,\n",
    "                            initial_capital=100000\n",
    "                        )\n",
    "                        \n",
    "                        perf['strategy_hash'] = strategy_hash\n",
    "                        perf_results.append(perf)\n",
    "                        \n",
    "                        if (i + 1) % 10 == 0:\n",
    "                            print(f\"  Processed {i + 1}/{strategies_to_analyze} strategies\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  Error calculating performance for {strategy_hash}: {e}\")\n",
    "            \n",
    "            if perf_results:\n",
    "                perf_df = pd.DataFrame(perf_results)\n",
    "                \n",
    "                # Add strategy metadata\n",
    "                perf_df = perf_df.merge(\n",
    "                    filtered_strategies[['strategy_hash'] + param_cols],\n",
    "                    on='strategy_hash'\n",
    "                )\n",
    "                \n",
    "                print(\"\\nPerformance Summary:\")\n",
    "                print(perf_df[['total_return', 'sharpe_ratio', 'max_drawdown', \n",
    "                              'win_rate', 'profit_factor']].describe())\n",
    "                \n",
    "                # Plot performance distribution\n",
    "                fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "                \n",
    "                perf_df['sharpe_ratio'].hist(bins=30, ax=axes[0, 0])\n",
    "                axes[0, 0].set_title('Sharpe Ratio Distribution')\n",
    "                axes[0, 0].set_xlabel('Sharpe Ratio')\n",
    "                \n",
    "                perf_df['total_return'].hist(bins=30, ax=axes[0, 1])\n",
    "                axes[0, 1].set_title('Total Return Distribution')\n",
    "                axes[0, 1].set_xlabel('Total Return')\n",
    "                \n",
    "                perf_df.plot.scatter('max_drawdown', 'sharpe_ratio', ax=axes[1, 0])\n",
    "                axes[1, 0].set_title('Risk-Return Profile')\n",
    "                axes[1, 0].set_xlabel('Max Drawdown')\n",
    "                axes[1, 0].set_ylabel('Sharpe Ratio')\n",
    "                \n",
    "                perf_df.plot.scatter('win_rate', 'profit_factor', ax=axes[1, 1])\n",
    "                axes[1, 1].set_title('Win Rate vs Profit Factor')\n",
    "                axes[1, 1].set_xlabel('Win Rate')\n",
    "                axes[1, 1].set_ylabel('Profit Factor')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Save performance results\n",
    "                perf_df.to_csv(f'{strategy_type}_performance_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv', index=False)\n",
    "                print(f\"\\nPerformance results saved to CSV\")\n",
    "        else:\n",
    "            print(\"No market data found - skipping performance estimation\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Could not load market data: {e}\")\n",
    "        print(\"Skipping performance estimation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Recommendations\n",
    "\n",
    "Summarize findings and suggest next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary\n",
    "print(\"=\" * 80)\n",
    "print(f\"ANALYSIS SUMMARY: {strategy_type} Strategies\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(filtered_strategies) > 0:\n",
    "    print(f\"\\nâœ“ Analyzed {len(filtered_strategies)} {strategy_type} strategies\")\n",
    "    print(f\"âœ“ Total signal records: {len(combined_signals):,}\")\n",
    "    \n",
    "    if not signal_counts.empty:\n",
    "        print(f\"\\nðŸ“Š Signal Statistics:\")\n",
    "        print(f\"   - Average signal rate: {signal_counts['signal_rate'].mean():.2%}\")\n",
    "        print(f\"   - Signal rate range: {signal_counts['signal_rate'].min():.2%} - {signal_counts['signal_rate'].max():.2%}\")\n",
    "    \n",
    "    if len(pattern_df) > 0:\n",
    "        print(f\"\\nðŸ“ˆ Pattern Analysis:\")\n",
    "        print(f\"   - Avg signal duration: {pattern_df['avg_signal_duration'].mean():.1f} bars\")\n",
    "        print(f\"   - Long/Short ratio: {pattern_df['long_ratio'].mean():.2f} / {pattern_df['short_ratio'].mean():.2f}\")\n",
    "    \n",
    "    if 'perf_df' in locals() and not perf_df.empty:\n",
    "        print(f\"\\nðŸ’° Performance Estimates:\")\n",
    "        print(f\"   - Median Sharpe: {perf_df['sharpe_ratio'].median():.2f}\")\n",
    "        print(f\"   - Best Sharpe: {perf_df['sharpe_ratio'].max():.2f}\")\n",
    "        print(f\"   - Strategies with Sharpe > 1.0: {(perf_df['sharpe_ratio'] > 1.0).sum()}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Recommendations:\")\n",
    "    if len(filtered_strategies) < 20:\n",
    "        print(f\"   - Consider generating more {strategy_type} variations for robust analysis\")\n",
    "    \n",
    "    if len(low_corr_pairs) > 0:\n",
    "        print(f\"   - Found {len(low_corr_pairs)} low-correlation pairs suitable for ensemble\")\n",
    "    \n",
    "    if numeric_params:\n",
    "        print(f\"   - Key parameters to optimize: {', '.join(numeric_params)}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nâŒ No {strategy_type} strategies found in the store\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Run signal generation with this strategy type\")\n",
    "    print(\"2. Check available strategy types in the store\")\n",
    "    print(\"3. Adjust filter criteria (symbol, timeframe)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export key results\n",
    "if len(filtered_strategies) > 0:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Save strategy metadata\n",
    "    filtered_strategies.to_csv(f'{strategy_type}_strategies_{timestamp}.csv', index=False)\n",
    "    print(f\"\\nExported {len(filtered_strategies)} strategy definitions\")\n",
    "    \n",
    "    # Save signal statistics if available  \n",
    "    if not signal_counts.empty:\n",
    "        signal_counts.to_csv(f'{strategy_type}_signal_stats_{timestamp}.csv', index=False)\n",
    "        print(f\"Exported signal statistics\")\n",
    "    \n",
    "    # Save pattern analysis if available\n",
    "    if len(pattern_df) > 0:\n",
    "        pattern_df.to_csv(f'{strategy_type}_patterns_{timestamp}.csv', index=False) \n",
    "        print(f\"Exported pattern analysis\")\n",
    "    \n",
    "    print(f\"\\nAll results exported with timestamp: {timestamp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}