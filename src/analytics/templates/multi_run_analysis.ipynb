{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Run Cross-Strategy Analysis\n",
    "\n",
    "This notebook analyzes results across multiple parameter sweep runs to build comprehensive ensembles.\n",
    "\n",
    "**Use Cases:**\n",
    "- Combine results from different indicator sweeps (bollinger, rsi, momentum, etc.)\n",
    "- Build ensembles from diverse strategy types\n",
    "- Compare performance across different market conditions\n",
    "- Leverage strategy hashing to avoid duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "# List of run directories to analyze\n",
    "run_dirs = [\n",
    "    \"/path/to/results/run_20250623_143030\",  # bollinger run\n",
    "    \"/path/to/results/run_20250624_090000\",  # rsi run\n",
    "    # Add more runs as needed\n",
    "]\n",
    "output_name = \"multi_run_analysis\"\n",
    "min_sharpe = 1.0\n",
    "correlation_threshold = 0.7\n",
    "max_strategies_per_type = 5  # Limit strategies per type for diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Initialize DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "print(f\"Analyzing {len(run_dirs)} runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Strategy Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load strategy indices from all runs\n",
    "all_strategies = []\n",
    "run_metadata = {}\n",
    "\n",
    "for run_dir in run_dirs:\n",
    "    run_path = Path(run_dir)\n",
    "    if not run_path.exists():\n",
    "        print(f\"⚠️ Run directory not found: {run_dir}\")\n",
    "        continue\n",
    "        \n",
    "    # Load strategy index\n",
    "    index_path = run_path / 'strategy_index.parquet'\n",
    "    if index_path.exists():\n",
    "        strategies = pd.read_parquet(index_path)\n",
    "        strategies['run_dir'] = str(run_path)\n",
    "        strategies['run_id'] = run_path.name\n",
    "        all_strategies.append(strategies)\n",
    "        \n",
    "        # Load config if available\n",
    "        config_path = run_path / 'config.json'\n",
    "        if config_path.exists():\n",
    "            with open(config_path) as f:\n",
    "                config = json.load(f)\n",
    "                run_metadata[run_path.name] = {\n",
    "                    'config_name': config.get('name', 'unknown'),\n",
    "                    'symbols': config.get('symbols', []),\n",
    "                    'timeframe': config.get('timeframe', 'unknown')\n",
    "                }\n",
    "        \n",
    "        print(f\"✅ Loaded {len(strategies)} strategies from {run_path.name}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No strategy index found in {run_dir}\")\n",
    "\n",
    "# Combine all strategies\n",
    "if all_strategies:\n",
    "    combined_strategies = pd.concat(all_strategies, ignore_index=True)\n",
    "    print(f\"\\n📊 Total strategies across all runs: {len(combined_strategies)}\")\n",
    "    \n",
    "    # Check for duplicates using strategy hash\n",
    "    duplicates = combined_strategies.groupby('strategy_hash').size()\n",
    "    duplicates = duplicates[duplicates > 1]\n",
    "    if len(duplicates) > 0:\n",
    "        print(f\"⚠️ Found {len(duplicates)} duplicate strategies (same hash)\")\n",
    "        # Remove duplicates, keeping the first occurrence\n",
    "        combined_strategies = combined_strategies.drop_duplicates(subset=['strategy_hash'], keep='first')\n",
    "        print(f\"📊 Unique strategies: {len(combined_strategies)}\")\n",
    "else:\n",
    "    print(\"❌ No strategies loaded\")\n",
    "    combined_strategies = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unified Signal Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DuckDB views for all signal data\n",
    "if len(combined_strategies) > 0:\n",
    "    # Create a view for all signals across runs\n",
    "    signal_paths = []\n",
    "    for _, strategy in combined_strategies.iterrows():\n",
    "        full_path = Path(strategy['run_dir']) / strategy['trace_path']\n",
    "        if full_path.exists():\n",
    "            signal_paths.append(str(full_path))\n",
    "    \n",
    "    if signal_paths:\n",
    "        # Create union of all signals\n",
    "        print(f\"Creating unified view of {len(signal_paths)} signal files...\")\n",
    "        \n",
    "        # For performance, we'll create a view that reads files on demand\n",
    "        con.execute(\"CREATE OR REPLACE VIEW all_signals AS \")\n",
    "        \n",
    "        union_parts = []\n",
    "        for i, path in enumerate(signal_paths[:100]):  # Limit for initial testing\n",
    "            union_parts.append(f\"SELECT * FROM read_parquet('{path}')\")\n",
    "        \n",
    "        if union_parts:\n",
    "            query = \" UNION ALL \".join(union_parts)\n",
    "            con.execute(f\"CREATE OR REPLACE VIEW all_signals AS {query}\")\n",
    "            \n",
    "            # Test the view\n",
    "            signal_count = con.execute(\"SELECT COUNT(*) as cnt FROM all_signals\").df()['cnt'][0]\n",
    "            print(f\"✅ Created unified signal view with {signal_count:,} signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Run Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze strategy distribution across runs\n",
    "if len(combined_strategies) > 0:\n",
    "    print(\"Strategy Distribution:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # By run\n",
    "    by_run = combined_strategies.groupby('run_id').agg({\n",
    "        'strategy_hash': 'count',\n",
    "        'strategy_type': lambda x: x.value_counts().to_dict()\n",
    "    })\n",
    "    by_run.columns = ['total_strategies', 'strategy_types']\n",
    "    print(\"\\nBy Run:\")\n",
    "    for run_id, row in by_run.iterrows():\n",
    "        meta = run_metadata.get(run_id, {})\n",
    "        print(f\"\\n{run_id} ({meta.get('config_name', 'unknown')}):\")\n",
    "        print(f\"  Total: {row['total_strategies']}\")\n",
    "        print(f\"  Types: {row['strategy_types']}\")\n",
    "    \n",
    "    # Overall by type\n",
    "    print(\"\\nOverall by Strategy Type:\")\n",
    "    type_counts = combined_strategies['strategy_type'].value_counts()\n",
    "    for stype, count in type_counts.items():\n",
    "        print(f\"  {stype}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter High-Performance Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We need to calculate performance if not already in the parquet files\n",
    "# For now, assume performance metrics are in the strategy index\n",
    "\n",
    "if 'sharpe_ratio' in combined_strategies.columns:\n",
    "    # Filter by performance\n",
    "    high_performers = combined_strategies[combined_strategies['sharpe_ratio'] >= min_sharpe].copy()\n",
    "    print(f\"\\nHigh performers (Sharpe >= {min_sharpe}): {len(high_performers)}\")\n",
    "    \n",
    "    # Apply diversity constraint\n",
    "    diverse_performers = []\n",
    "    for stype in high_performers['strategy_type'].unique():\n",
    "        type_strategies = high_performers[high_performers['strategy_type'] == stype]\n",
    "        # Take top N from each type\n",
    "        top_n = type_strategies.nlargest(max_strategies_per_type, 'sharpe_ratio')\n",
    "        diverse_performers.append(top_n)\n",
    "    \n",
    "    diverse_performers = pd.concat(diverse_performers, ignore_index=True)\n",
    "    print(f\"Diverse high performers (max {max_strategies_per_type} per type): {len(diverse_performers)}\")\n",
    "    \n",
    "    # Display top strategies\n",
    "    print(\"\\nTop Strategies Across All Runs:\")\n",
    "    print(\"=\" * 80)\n",
    "    display_cols = ['strategy_type', 'sharpe_ratio', 'total_return', 'run_id']\n",
    "    print(diverse_performers.nlargest(20, 'sharpe_ratio')[display_cols].to_string(index=False))\n",
    "else:\n",
    "    print(\"⚠️ Performance metrics not found in strategy index. Need to calculate from signals.\")\n",
    "    diverse_performers = combined_strategies  # Use all for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Strategy Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For correlation analysis, we'll use the signal overlap approach\n",
    "# This is more efficient than loading all return series\n",
    "\n",
    "if len(diverse_performers) > 1:\n",
    "    print(\"Calculating strategy correlations using signal overlap...\")\n",
    "    \n",
    "    # Sample strategies for correlation calculation\n",
    "    sample_size = min(50, len(diverse_performers))\n",
    "    sampled_strategies = diverse_performers.sample(sample_size)\n",
    "    \n",
    "    correlation_query = f\"\"\"\n",
    "    WITH strategy_signals AS (\n",
    "        SELECT \n",
    "            strategy_hash,\n",
    "            DATE_TRUNC('hour', ts) as hour_ts,\n",
    "            AVG(val) as avg_signal\n",
    "        FROM all_signals\n",
    "        WHERE strategy_hash IN ({','.join([f\"'{h}'\" for h in sampled_strategies['strategy_hash']])})\n",
    "        GROUP BY strategy_hash, hour_ts\n",
    "    ),\n",
    "    signal_pairs AS (\n",
    "        SELECT \n",
    "            s1.strategy_hash as hash1,\n",
    "            s2.strategy_hash as hash2,\n",
    "            CORR(s1.avg_signal, s2.avg_signal) as correlation\n",
    "        FROM strategy_signals s1\n",
    "        JOIN strategy_signals s2 ON s1.hour_ts = s2.hour_ts\n",
    "        WHERE s1.strategy_hash < s2.strategy_hash\n",
    "        GROUP BY s1.strategy_hash, s2.strategy_hash\n",
    "        HAVING COUNT(*) > 100  -- Minimum overlap\n",
    "    )\n",
    "    SELECT * FROM signal_pairs\n",
    "    WHERE ABS(correlation) < {correlation_threshold}\n",
    "    ORDER BY correlation\n",
    "    \"\"\"\n",
    "    \n",
    "    # This query might be slow for many strategies\n",
    "    # For now, we'll skip the actual execution and provide a template\n",
    "    print(\"\\n💡 To run correlation analysis, execute the correlation query above\")\n",
    "    print(\"   or use the correlation analysis snippet for detailed analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Multi-Run Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple ensemble selection based on diversity\n",
    "ensemble = []\n",
    "selected_types = set()\n",
    "\n",
    "# First, take the best from each strategy type\n",
    "for stype in diverse_performers['strategy_type'].unique():\n",
    "    type_best = diverse_performers[diverse_performers['strategy_type'] == stype].nlargest(1, 'sharpe_ratio')\n",
    "    if len(type_best) > 0:\n",
    "        ensemble.append(type_best.iloc[0])\n",
    "        selected_types.add(stype)\n",
    "\n",
    "ensemble_df = pd.DataFrame(ensemble)\n",
    "print(f\"\\n🎯 Multi-Run Ensemble ({len(ensemble_df)} strategies from {len(selected_types)} types):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for _, strategy in ensemble_df.iterrows():\n",
    "    print(f\"\\n{strategy['strategy_type']} from {strategy['run_id']}:\")\n",
    "    print(f\"  Hash: {strategy['strategy_hash'][:8]}\")\n",
    "    if 'sharpe_ratio' in strategy:\n",
    "        print(f\"  Sharpe: {strategy['sharpe_ratio']:.2f}\")\n",
    "    if 'param_names' in strategy and pd.notna(strategy['param_names']):\n",
    "        print(f\"  Params: {strategy['param_names']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Multi-Run Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive export\n",
    "export_data = {\n",
    "    'analysis_info': {\n",
    "        'generated_at': datetime.now().isoformat(),\n",
    "        'runs_analyzed': run_dirs,\n",
    "        'total_strategies': len(combined_strategies),\n",
    "        'unique_strategies': len(combined_strategies['strategy_hash'].unique()),\n",
    "        'high_performers': len(high_performers) if 'high_performers' in locals() else 0\n",
    "    },\n",
    "    'run_metadata': run_metadata,\n",
    "    'ensemble': ensemble_df.to_dict('records'),\n",
    "    'strategy_type_distribution': combined_strategies['strategy_type'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "output_path = Path(f\"{output_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(export_data, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n✅ Results exported to {output_path}\")\n",
    "\n",
    "# Also save the combined strategy index\n",
    "combined_strategies.to_parquet(f\"{output_name}_strategies.parquet\")\n",
    "print(f\"✅ Combined strategy index saved to {output_name}_strategies.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize strategy distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Strategy types across runs\n",
    "type_by_run = combined_strategies.groupby(['run_id', 'strategy_type']).size().unstack(fill_value=0)\n",
    "type_by_run.plot(kind='bar', stacked=True, ax=axes[0])\n",
    "axes[0].set_title('Strategy Distribution by Run')\n",
    "axes[0].set_xlabel('Run ID')\n",
    "axes[0].set_ylabel('Number of Strategies')\n",
    "axes[0].legend(title='Strategy Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Performance distribution if available\n",
    "if 'sharpe_ratio' in combined_strategies.columns:\n",
    "    combined_strategies.boxplot(column='sharpe_ratio', by='strategy_type', ax=axes[1])\n",
    "    axes[1].set_title('Sharpe Ratio Distribution by Strategy Type')\n",
    "    axes[1].set_xlabel('Strategy Type')\n",
    "    axes[1].set_ylabel('Sharpe Ratio')\n",
    "    plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}