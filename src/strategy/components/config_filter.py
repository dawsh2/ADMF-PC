"""
Config-level Signal Filtering System

Allows filtering strategies based on expressions defined in configuration.
Filters are evaluated AFTER strategy generates a signal, determining whether
the signal should be accepted or ignored.

Supports:
- Simple filters: signal > 0 and price > vwap()
- Directional filters: Only take longs/shorts based on conditions
- Complex filters: Combine multiple conditions with AND/OR
- Parameterized filters: Use parameters that can be optimized
"""

import ast
import operator
import re
from typing import Dict, Any, Optional, Callable, List
import logging
import pandas as pd
import pytz

logger = logging.getLogger(__name__)

# Pre-create timezone object for performance
ET_TZ = pytz.timezone('US/Eastern')


class FilterExpressionError(Exception):
    """Raised when filter expression cannot be parsed or evaluated."""
    pass


class ConfigSignalFilter:
    """
    Evaluates filter expressions from configuration to accept/reject signals.
    
    Filter expressions have access to:
    - signal: The signal value generated by the strategy
    - price: Current price (close)
    - volume: Current volume
    - All computed features from FeatureHub
    - Special functions: ma(), vwap(), session_vwap(), etc.
    """
    
    # Allowed operators for security
    ALLOWED_OPS = {
        ast.Add: operator.add,
        ast.Sub: operator.sub,
        ast.Mult: operator.mul,
        ast.Div: operator.truediv,
        ast.Mod: operator.mod,
        ast.Pow: operator.pow,
        ast.Eq: operator.eq,
        ast.NotEq: operator.ne,
        ast.Lt: operator.lt,
        ast.LtE: operator.le,
        ast.Gt: operator.gt,
        ast.GtE: operator.ge,
        ast.And: lambda x, y: x and y,
        ast.Or: lambda x, y: x or y,
        ast.Not: operator.not_,
        ast.USub: operator.neg,
        ast.UAdd: operator.pos,
    }
    
    # Built-in functions available in filter expressions
    BUILTIN_FUNCS = {
        'abs': abs,
        'min': min,
        'max': max,
        'round': round,
    }
    
    def __init__(self):
        """Initialize the filter."""
        self._compiled_filters = {}
        
    def compile_filter(self, filter_expr: str, filter_id: str = "default") -> None:
        """
        Compile a filter expression for later evaluation.
        
        Args:
            filter_expr: Filter expression string (e.g., "signal > 0 and price > vwap()")
            filter_id: Unique identifier for this filter
        """
        try:
            # Clean up the expression - remove extra whitespace and newlines
            clean_expr = ' '.join(filter_expr.strip().split())
            
            # Parse the expression
            tree = ast.parse(clean_expr, mode='eval')
            
            # Validate it's safe (no function calls except allowed ones)
            self._validate_ast(tree)
            
            # Store the compiled AST
            self._compiled_filters[filter_id] = {
                'expr': clean_expr,
                'ast': tree,
                'code': compile(tree, clean_expr, 'eval')
            }
            
            logger.debug(f"Compiled filter '{filter_id}': {clean_expr}")
            
        except Exception as e:
            raise FilterExpressionError(f"Failed to compile filter '{filter_expr}': {e}")
    
    def evaluate_filter(self, 
                       signal: Dict[str, Any],
                       features: Dict[str, Any],
                       bar: Dict[str, Any],
                       filter_id: str = "default",
                       filter_params: Optional[Dict[str, Any]] = None) -> bool:
        """
        Evaluate a compiled filter expression.
        
        Args:
            signal: Signal dictionary from strategy
            features: Current feature values from FeatureHub
            bar: Current bar data
            filter_id: ID of the filter to evaluate
            filter_params: Parameter values for parameterized filters
            
        Returns:
            True if signal passes filter (accept), False otherwise (reject)
        """
        if filter_id not in self._compiled_filters:
            # No filter means accept all signals
            return True
            
        compiled = self._compiled_filters[filter_id]
        
        # Build evaluation context
        context = self._build_context(signal, features, bar, filter_params)
        
        try:
            # Evaluate the expression with minimal safe builtins
            # Some operations need these even if we don't use them directly
            # Create a fresh copy of built-ins to ensure they aren't modified
            import builtins
            safe_builtins = {
                "__builtins__": {
                    "__import__": None,  # Explicitly disable import
                    "__name__": "__main__",
                    "__doc__": None,
                    "None": None,
                    "True": True,
                    "False": False,
                    # Add the built-in functions we need - use fresh references
                    "abs": builtins.abs,
                    "min": builtins.min,
                    "max": builtins.max,
                    "round": builtins.round,
                    # Add more math functions that might be needed
                    "int": builtins.int,
                    "float": builtins.float,
                    "bool": builtins.bool,
                }
            }
            
            # Make a copy of context to ensure it doesn't get modified
            eval_context = context.copy()
            
            # Apply division by zero protection in the eval context
            # This needs to be done here because features might be added after initial context building
            if 'atr_sma_50' in eval_context and eval_context['atr_sma_50'] == 0:
                logger.debug("atr_sma_50 is 0 in eval context, setting to small value to avoid division by zero")
                eval_context['atr_sma_50'] = 0.0001
            
            # Also check for other common zero-value denominators
            zero_protection = {
                'volume_sma_20': 1.0,  # Default to 1 for volume averages
                'volume_sma_50': 1.0,
                'volatility_sma_20': 0.0001,
                'volatility_sma_50': 0.0001,
            }
            
            for feature, default in zero_protection.items():
                if feature in eval_context and eval_context[feature] == 0:
                    logger.debug(f"{feature} is 0 in eval context, setting to {default} to avoid division by zero")
                    eval_context[feature] = default
            
            # Double-check that built-ins are available in the context too
            # This ensures they work regardless of lookup order
            for name in ['abs', 'min', 'max', 'round']:
                if name not in eval_context or not callable(eval_context.get(name)):
                    eval_context[name] = getattr(builtins, name)
            
            result = eval(compiled['code'], safe_builtins, eval_context)
            
            # Log evaluation details for debugging
            logger.debug(f"Filter '{filter_id}' evaluated: {compiled['expr']} -> {result}")
            logger.debug(f"  Signal value: {context.get('signal', 'N/A')}, Price: {context.get('price', 'N/A')}")
            
            # Ensure result is boolean
            return bool(result)
            
        except Exception as e:
            logger.error(f"Error evaluating filter '{filter_id}': {e}")
            logger.error(f"Filter expression that failed: {compiled['expr']}")
            logger.debug(f"Context keys: {list(context.keys())}")
            
            # Debug specific error cases
            if "'NoneType' object is not callable" in str(e):
                # Try to find what's actually None
                import traceback
                logger.error(f"Full traceback:")
                logger.error(traceback.format_exc())
                
                # Check specific values that might be None
                critical_vars = ['close', 'vwap', 'atr_14', 'atr_sma_50', 'bar_of_day']
                logger.error(f"Critical variable values:")
                for var in critical_vars:
                    if var in context:
                        value = context[var]
                        logger.error(f"  {var}: {type(value).__name__} = {value}")
                    else:
                        logger.error(f"  {var}: NOT IN CONTEXT")
                
                # Check if any accessor functions are None
                accessor_funcs = ['ma', 'sma', 'ema', 'vwap_func', 'session_vwap', 'rsi', 'atr', 'atr_sma']
                logger.error(f"Accessor functions:")
                for func in accessor_funcs:
                    if func in context:
                        value = context[func]
                        logger.error(f"  {func}: {type(value).__name__} = {'<callable>' if callable(value) else value}")
                
                # Check builtins availability
                logger.error(f"Builtins in globals: {list(safe_builtins.get('__builtins__', {}).keys())}")
                
                # Try to eval just 'abs' to see if it works
                try:
                    test_abs = eval('abs', safe_builtins, context)
                    logger.error(f"eval('abs') = {test_abs}")
                    # Also check if abs is in context
                    if 'abs' in context:
                        logger.error(f"'abs' IS in context: {type(context['abs'])} = {context['abs']}")
                    else:
                        logger.error(f"'abs' is NOT in context")
                    # Try the actual problematic expression
                    test_expr = "abs(close - vwap)"
                    test_result = eval(test_expr, safe_builtins, context)
                    logger.error(f"eval('{test_expr}') = {test_result}")
                    
                    # Test more parts of the expression
                    test_exprs = [
                        "signal",
                        "signal == 0",
                        "atr_14",
                        "atr_sma_50", 
                        "atr_14 / atr_sma_50" if context.get('atr_sma_50', 0) != 0 else "0",
                        "bar_of_day",
                        "bar_of_day < 30",
                        "bar_of_day > 60",
                        "(bar_of_day < 30 or bar_of_day > 60)"
                    ]
                    for expr in test_exprs:
                        try:
                            result = eval(expr, safe_builtins, context)
                            logger.error(f"eval('{expr}') = {result}")
                        except Exception as e:
                            logger.error(f"eval('{expr}') FAILED: {e}")
                    
                    # Test the specific problematic parts
                    logger.error(f"\nTesting problematic expression parts:")
                    try:
                        # The full expression from the error
                        prob_expr = "atr_14 / atr_sma_50 >= 0.8 and atr_14 / atr_sma_50 <= 1.2"
                        result = eval(prob_expr, safe_builtins, context)
                        logger.error(f"eval('{prob_expr}') = {result}")
                    except Exception as e:
                        logger.error(f"eval('{prob_expr}') FAILED: {e}")
                        
                    # Test division by zero behavior
                    try:
                        div_test = "atr_14 / atr_sma_50"
                        result = eval(div_test, safe_builtins, context)
                        logger.error(f"eval('{div_test}') = {result} (type: {type(result)})")
                    except Exception as e:
                        logger.error(f"eval('{div_test}') FAILED: {e}")
                        
                    # Test what 'abs' actually is
                    try:
                        logger.error(f"\nDebugging 'abs' in more detail:")
                        logger.error(f"type(abs) in Python: {type(abs)}")
                        logger.error(f"abs callable: {callable(abs)}")
                        
                        # Check what's in the context for 'abs'
                        if 'abs' in context:
                            abs_val = context['abs']
                            logger.error(f"context['abs'] = {abs_val}")
                            logger.error(f"type(context['abs']) = {type(abs_val)}")
                            logger.error(f"context['abs'] is abs: {abs_val is abs}")
                            logger.error(f"context['abs'] callable: {callable(abs_val)}")
                        
                        # Also check safe_builtins
                        if '__builtins__' in safe_builtins and 'abs' in safe_builtins['__builtins__']:
                            builtin_abs = safe_builtins['__builtins__']['abs']
                            logger.error(f"safe_builtins abs = {builtin_abs}")
                            logger.error(f"safe_builtins abs is abs: {builtin_abs is abs}")
                        
                        # Debug each part of the complex expression
                        logger.error(f"\nDebugging expression parts in detail:")
                        
                        # Test each sub-expression that might have a callable
                        test_parts = [
                            ("atr_14", context.get('atr_14')),
                            ("atr_sma_50", context.get('atr_sma_50')),
                            ("close", context.get('close')),
                            ("vwap", context.get('vwap')),
                            ("abs", context.get('abs')),
                            ("signal", context.get('signal')),
                            ("bar_of_day", context.get('bar_of_day')),
                        ]
                        
                        for name, value in test_parts:
                            logger.error(f"{name}: {type(value)} = {value}, callable: {callable(value) if value is not None else 'N/A'}")
                        
                        # Check if any values are None
                        none_values = [name for name, value in test_parts if value is None]
                        if none_values:
                            logger.error(f"WARNING: These values are None: {none_values}")
                        
                        # Test problematic sub-expressions individually
                        problem_exprs = [
                            "atr_14 / atr_sma_50",
                            "abs(close - vwap)",
                            "abs(close - vwap) / vwap",
                            "(abs(close - vwap) / vwap > 0.004)",
                        ]
                        
                        for expr in problem_exprs:
                            try:
                                res = eval(expr, safe_builtins, context)
                                logger.error(f"eval('{expr}') = {res} (type: {type(res)})")
                            except Exception as e:
                                logger.error(f"eval('{expr}') FAILED: {type(e).__name__}: {e}")
                            
                    except Exception as e:
                        logger.error(f"Error in detailed debugging: {e}")
                        
                except Exception as test_e:
                    logger.error(f"eval test failed: {test_e}")
            
            # Log more details if it's the __import__ error
            if "__import__" in str(e):
                logger.error(f"Import-related error with filter: {compiled['expr']}")
                logger.error(f"Full exception: {type(e).__name__}: {e}")
            # On error, default to rejecting the signal for safety
            return False
    
    def evaluate_raw(self,
                    filter_expr: str,
                    signal: Dict[str, Any],
                    features: Dict[str, Any], 
                    bar: Dict[str, Any],
                    filter_params: Optional[Dict[str, Any]] = None) -> bool:
        """
        Evaluate a filter expression without pre-compilation.
        Useful for one-off evaluations.
        """
        temp_id = "_temp_filter"
        self.compile_filter(filter_expr, temp_id)
        result = self.evaluate_filter(signal, features, bar, temp_id, filter_params)
        # Clean up temporary filter
        del self._compiled_filters[temp_id]
        return result
    
    def _build_context(self,
                      signal: Dict[str, Any],
                      features: Dict[str, Any],
                      bar: Dict[str, Any],
                      filter_params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Build the evaluation context with all available variables and functions."""
        context = {}
        
        # Signal value
        context['signal'] = signal.get('signal_value', 0)
        
        # Current bar data
        context['price'] = bar.get('close', 0)
        context['close'] = bar.get('close', 0)
        context['open'] = bar.get('open', 0)
        context['high'] = bar.get('high', 0)
        context['low'] = bar.get('low', 0)
        context['volume'] = bar.get('volume', 0)
        
        # Time-based features
        if 'timestamp' in bar:
            try:
                ts = pd.to_datetime(bar['timestamp'])
                
                # Convert to ET timezone once for all calculations
                if ts.tzinfo is not None:
                    # Timestamp is timezone-aware, convert to ET
                    ts_et = ts.astimezone(ET_TZ)
                else:
                    # Assume UTC if not timezone-aware, then convert to ET
                    ts_et = ts.tz_localize('UTC').astimezone(ET_TZ)
                
                # Extract time components from ET timestamp
                context['hour'] = ts_et.hour
                context['minute'] = ts_et.minute
                context['time'] = ts_et.hour * 100 + ts_et.minute  # HHMM format
                
                # Intraday flag - true if within regular market hours (9:30 AM - 3:55 PM ET)
                context['intraday'] = (930 <= context['time'] < 1555)
                
                # Calculate bar_of_day only if needed (for backward compatibility)
                # This is now a simple calculation without creating new datetime objects
                if context['time'] >= 930:
                    minutes_since_930 = (context['time'] - 930) // 100 * 60 + (context['time'] % 100)
                    timeframe_minutes = bar.get('timeframe_minutes', 5)
                    context['bar_of_day'] = int(minutes_since_930 / timeframe_minutes)
                else:
                    context['bar_of_day'] = -1  # Pre-market
                    
            except Exception as e:
                # Only log errors, not debug info
                logger.warning(f"Failed to extract time features from timestamp {bar.get('timestamp')}: {e}")
                # Set default values so filter doesn't fail
                context['hour'] = 0
                context['minute'] = 0
                context['time'] = 0
                context['bar_of_day'] = 0
                context['intraday'] = False  # Default to outside market hours
        else:
            # No timestamp available - set default values
            context['hour'] = 0
            context['minute'] = 0
            context['time'] = 0
            context['bar_of_day'] = 0
            context['intraday'] = False  # Default to outside market hours
        
        # Feature accessor functions (add first, so raw values can override)
        # Make sure these all return callables, not None
        accessor_funcs = {
            'ma': self._make_ma_func(features),
            'ema': self._make_ema_func(features),
            'sma': self._make_sma_func(features),
            'vwap_func': self._make_vwap_func(features),  # Renamed to avoid conflict
            'session_vwap': self._make_session_vwap_func(features),
            'rsi': self._make_rsi_func(features),
            'atr': self._make_atr_func(features),
            'atr_sma': self._make_atr_sma_func(features),
            'volume_ratio': self._make_volume_ratio_func(features),
            'volatility_percentile': self._make_volatility_percentile_func(features),
            'vwap_distance': self._make_vwap_distance_func(features),
        }
        
        # Verify all accessor functions are callable before adding to context
        for name, func in accessor_funcs.items():
            if callable(func):
                context[name] = func
            else:
                logger.error(f"Accessor function '{name}' is not callable: {type(func)} = {func}")
                # Provide a dummy function that returns 0
                context[name] = lambda *args, **kwargs: 0
        
        # Define protected function names (built-ins + accessor functions)
        protected_names = set(self.BUILTIN_FUNCS.keys())
        protected_names.update(['ma', 'ema', 'sma', 'vwap_func', 'session_vwap', 
                               'rsi', 'atr', 'atr_sma', 'volume_ratio', 
                               'volatility_percentile', 'vwap_distance'])
        
        # All features from FeatureHub (includes raw vwap value if present)
        # But don't let features override protected function names
        for key, value in features.items():
            if key not in protected_names:
                context[key] = value
            else:
                logger.warning(f"Feature '{key}' conflicts with protected function name, skipping")
        
        # Add vwap from bar data if not in features
        if 'vwap' not in context and 'vwap' in bar:
            context['vwap'] = bar['vwap']
        
        # Handle composite features that might be referenced directly
        # This provides a temporary solution until proper composite feature support is implemented
        
        # Patterns for common composite features
        composite_patterns = [
            (r'(\w+)_sma_(\d+)', 'sma'),  # e.g., atr_sma_50, volume_sma_20
            (r'(\w+)_ema_(\d+)', 'ema'),  # e.g., rsi_ema_20
        ]
        
        # Add protection against division by zero for certain features
        # If atr_sma_50 is 0, set it to a small value to avoid division errors
        if 'atr_sma_50' in context and context['atr_sma_50'] == 0:
            logger.debug("atr_sma_50 is 0, setting to small value to avoid division by zero")
            context['atr_sma_50'] = 0.0001
        
        if hasattr(self, '_compiled_filters'):
            for filter_data in self._compiled_filters.values():
                expr = filter_data.get('expr', '')
                
                # Check each composite pattern
                for pattern, ma_type in composite_patterns:
                    matches = re.findall(pattern, expr)
                    for source, period_str in matches:
                        feature_name = f'{source}_{ma_type}_{period_str}'
                        
                        if feature_name not in context:
                            # Special handling for known composite features
                            if source == 'atr' and ma_type == 'sma':
                                # For atr_sma_N, try to get it from features first
                                if feature_name in features:
                                    context[feature_name] = features[feature_name]
                                else:
                                    # Try using the atr_sma function
                                    atr_sma_func = context.get('atr_sma')
                                    if atr_sma_func and callable(atr_sma_func):
                                        try:
                                            value = atr_sma_func(int(period_str))
                                            context[feature_name] = value if value is not None else 0
                                        except Exception as e:
                                            logger.warning(f"Error calling atr_sma({period_str}): {e}")
                                            context[feature_name] = 0
                                    else:
                                        # Last resort: if we have ATR, use its current value
                                        # (not a true SMA, but prevents errors)
                                        atr_value = features.get(f'atr_{14}', features.get('atr', 0))
                                        context[feature_name] = atr_value
                                        logger.warning(
                                            f"Composite feature {feature_name} not properly configured. "
                                            f"Using current ATR value: {atr_value}. "
                                            f"For proper SMA of ATR, configure feature manually."
                                        )
                            
                            elif source == 'volume' and ma_type == 'sma':
                                # volume_sma_N should already be handled by feature discovery
                                # But provide a fallback
                                if feature_name not in context:
                                    context[feature_name] = features.get(feature_name, 0)
                                    if context[feature_name] == 0:
                                        logger.warning(f"Feature {feature_name} not found in features")
                            
                            else:
                                # Generic composite feature - provide a default
                                base_value = features.get(source, context.get(source, 0))
                                context[feature_name] = base_value
                                logger.warning(
                                    f"Composite feature {feature_name} not supported. "
                                    f"Using base feature value: {base_value}"
                                )
        
        # Filter parameters (for optimization)
        if filter_params:
            # Don't let filter params override protected names either
            for key, value in filter_params.items():
                if key not in protected_names and key not in self.BUILTIN_FUNCS:
                    context[key] = value
                else:
                    logger.warning(f"Filter param '{key}' conflicts with protected name, skipping")
        
        # Also add built-in functions to context as a safety measure
        # Having them in both globals and locals ensures they're accessible
        for name, func in self.BUILTIN_FUNCS.items():
            if name not in context:
                context[name] = func
            elif context[name] is not func:
                logger.warning(f"Built-in '{name}' was overridden in context, restoring it")
                context[name] = func
        
        return context
    
    def _make_ma_func(self, features: Dict[str, Any]) -> Callable:
        """Create MA accessor function."""
        def ma(period: int = 20) -> float:
            # Try SMA first, then EMA
            value = features.get(f'sma_{period}')
            if value is None:
                value = features.get(f'ema_{period}')
            if value is None:
                # Try volume moving average
                value = features.get(f'volume_sma_{period}')
            return value if value is not None else 0
        return ma
    
    def _make_sma_func(self, features: Dict[str, Any]) -> Callable:
        """Create SMA accessor function."""
        def sma(period: int = 20) -> float:
            return features.get(f'sma_{period}', 0)
        return sma
    
    def _make_ema_func(self, features: Dict[str, Any]) -> Callable:
        """Create EMA accessor function."""
        def ema(period: int = 20) -> float:
            return features.get(f'ema_{period}', 0)
        return ema
    
    def _make_vwap_func(self, features: Dict[str, Any]) -> Callable:
        """Create VWAP accessor function."""
        def vwap() -> float:
            return features.get('vwap', 0)
        return vwap
    
    def _make_session_vwap_func(self, features: Dict[str, Any]) -> Callable:
        """Create session VWAP accessor function."""
        def session_vwap() -> float:
            return features.get('session_vwap', features.get('vwap', 0))
        return session_vwap
    
    def _make_rsi_func(self, features: Dict[str, Any]) -> Callable:
        """Create RSI accessor function."""
        def rsi(period: int = 14) -> float:
            return features.get(f'rsi_{period}', 50)  # Default to neutral
        return rsi
    
    def _make_atr_func(self, features: Dict[str, Any]) -> Callable:
        """Create ATR accessor function."""
        def atr(period: int = 14) -> float:
            return features.get(f'atr_{period}', 0)
        return atr
    
    def _make_atr_sma_func(self, features: Dict[str, Any]) -> Callable:
        """Create ATR SMA accessor function."""
        def atr_sma(period: int = 50) -> float:
            # Look for pre-computed atr_sma_N feature
            return features.get(f'atr_sma_{period}', 0)
        return atr_sma
    
    def _make_volume_ratio_func(self, features: Dict[str, Any]) -> Callable:
        """Create volume ratio accessor function."""
        def volume_ratio(period: int = 20) -> float:
            return features.get(f'volume_ratio_{period}', 1.0)  # Default to neutral
        return volume_ratio
    
    def _make_volatility_percentile_func(self, features: Dict[str, Any]) -> Callable:
        """Create volatility percentile accessor function."""
        def volatility_percentile(period: int = 50) -> float:
            return features.get(f'volatility_percentile_{period}', 0.5)  # Default to middle
        return volatility_percentile
    
    def _make_vwap_distance_func(self, features: Dict[str, Any]) -> Callable:
        """Create VWAP distance accessor function."""
        def vwap_distance() -> float:
            return features.get('vwap_distance', 0)
        return vwap_distance
    
    def _validate_ast(self, tree: ast.AST) -> None:
        """
        Validate AST is safe to evaluate (no imports, exec, etc.).
        Only allows mathematical operations and allowed function calls.
        """
        for node in ast.walk(tree):
            # Check operators
            if isinstance(node, (ast.BinOp, ast.UnaryOp, ast.Compare, ast.BoolOp)):
                op_type = type(node.op) if hasattr(node, 'op') else type(node)
                if op_type not in self.ALLOWED_OPS and not isinstance(node, (ast.Compare, ast.BoolOp)):
                    raise FilterExpressionError(f"Operator {op_type.__name__} not allowed")
            
            # Check for forbidden constructs
            elif isinstance(node, (ast.Import, ast.ImportFrom, ast.FunctionDef, 
                                 ast.ClassDef, ast.Delete)):
                raise FilterExpressionError(f"Forbidden construct: {type(node).__name__}")
            
            # Allow only specific function calls
            elif isinstance(node, ast.Call):
                if isinstance(node.func, ast.Name):
                    func_name = node.func.id
                    # Allow built-in functions and our special functions
                    allowed_funcs = list(self.BUILTIN_FUNCS.keys()) + [
                        'ma', 'sma', 'ema', 'vwap', 'session_vwap', 'rsi', 'atr', 'atr_sma',
                        'volume_ratio', 'volatility_percentile', 'vwap_distance'
                    ]
                    if func_name not in allowed_funcs:
                        raise FilterExpressionError(f"Function '{func_name}' not allowed")
                else:
                    # No attribute access or complex function calls
                    raise FilterExpressionError("Complex function calls not allowed")


def create_filter_from_config(config: Dict[str, Any]) -> Optional[ConfigSignalFilter]:
    """
    Create a ConfigSignalFilter from strategy configuration.
    
    Config format:
    {
        'threshold': 'signal > 0 and price > vwap()',  # New way
        # or 'filter': 'signal > 0 and price > vwap()',  # Deprecated
        'filter_params': {
            'threshold': 0.5,
            'period': 20
        }
    }
    """
    # Support both 'threshold' (new) and 'filter' (deprecated)
    filter_expr = config.get('threshold') or config.get('filter')
    if not filter_expr:
        return None
        
    filter_obj = ConfigSignalFilter()
    filter_obj.compile_filter(filter_expr)
    
    return filter_obj


# Example usage in comments:
"""
# In strategy configuration:
strategy:
  sma_crossover:
    params: {fast: 10, slow: 30}
    filter: signal > 0 and price > vwap()  # Only long signals above VWAP

# Or with parameters:
strategy:
  momentum:
    params: {period: 14}
    filter: abs(signal) > ${threshold} and volume > ma(volume, ${vol_period})
    filter_params:
      threshold: 0.5
      vol_period: 20

# In the component state or coordinator:
filter_obj = create_filter_from_config(strategy_config)

# When processing signals:
if filter_obj:
    if filter_obj.evaluate_filter(signal, features, bar, filter_params=config.get('filter_params')):
        # Accept signal
        publish_signal(signal)
    else:
        # Reject signal
        logger.debug(f"Signal rejected by filter: {signal}")
"""