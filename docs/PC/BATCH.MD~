# Parallel Parameter Optimization for Event-Driven Trading Systems

## Overview

This document outlines a high-performance approach to parameter optimization for event-driven trading systems. Instead of running separate backtests for each parameter combination, we process multiple parameter sets simultaneously in a single market data pass, dramatically reducing optimization time.

## Key Concept: Single-Pass Multi-Parameter Backtesting

Traditional parameter optimization involves iterating through parameter combinations sequentially, with each combination requiring a complete pass through the market data. For large datasets or extensive parameter spaces, this becomes extremely time-consuming:

```
Traditional Approach:
For each parameter combination:
    For each bar in market data:
        Process bar with current parameters
```

Our proposed approach processes all (or batched groups of) parameter combinations simultaneously:

```
Optimized Approach:
For each bar in market data:
    For each parameter combination:
        Process bar with this parameter set
```

This inverts the nested loops, reducing data iteration from O(parameters × bars) to O(bars).

## Implementation Architecture

### 1. Scoped Container Architecture

Each parameter combination runs in its own isolated "scoped container":

```
┌─ Market Data Handler (Shared, Read-Only) ─┐
│                                           │
│  ┌─ Parameter Set 1 Container ─┐          │
│  │ Strategy                    │          │
│  │ Portfolio                   │ ◄─┐      │
│  │ Risk Manager                │   │      │
│  │ Execution Handler           │   │      │
│  └───────────────────────────┘    │      │
│                                    │      │
│  ┌─ Parameter Set 2 Container ─┐   │      │
│  │ Strategy                    │   │      │
│  │ Portfolio                   │ ◄─┼──────┼── BAR
│  │ Risk Manager                │   │      │   Events
│  │ Execution Handler           │   │      │
│  └───────────────────────────┘    │      │
│                                    │      │
│  ┌─ Parameter Set N Container ─┐   │      │
│  │ Strategy                    │   │      │
│  │ Portfolio                   │ ◄─┘      │
│  │ Risk Manager                │          │
│  │ Execution Handler           │          │
│  └───────────────────────────┘           │
│                                           │
└───────────────────────────────────────────┘
```

### 2. Configurable Batching System

The system supports adjustable batching to balance between speed and memory usage:

- **Sequential Mode** (batch size = 1): Current behavior, one parameter set at a time
- **Parallel Mode** (batch size > 1): Multiple parameter sets processed per data pass
- **Full Parallel Mode** (batch size = ∞): All parameter sets in a single pass
- **Auto Mode**: System determines optimal batch size based on memory constraints

### 3. Implementation Outline

```python
class BatchedParameterOptimizer:
    def __init__(self, batch_size=None, memory_limit=None):
        self.batch_size = batch_size
        self.memory_limit = memory_limit
    
    def optimize(self, parameter_space, objective_func):
        # Generate all parameter combinations
        all_params = list(parameter_space.sample())
        total_params = len(all_params)
        
        # Determine optimal batch size
        batch_size = self._determine_batch_size(total_params, all_params[0])
        
        results = []
        
        # Process in batches
        for batch_idx in range(0, total_params, batch_size):
            batch_params = all_params[batch_idx:batch_idx+batch_size]
            
            # Run single-pass backtest for this batch
            batch_results = self._run_batch_backtest(batch_params)
            results.extend(batch_results)
            
            # Free memory
            gc.collect()
        
        # Find and return best parameters
        best_idx = max(range(len(results)), 
                      key=lambda i: results[i]['performance'])
        return all_params[best_idx]

    def _run_batch_backtest(self, batch_params):
        # Create shared read-only data handler
        data_handler = self._create_shared_data_handler()
        
        # Create container for each parameter set
        containers = []
        for params in batch_params:
            container = self._create_scoped_container(params)
            containers.append(container)
            
            # Register data handler event subscriber
            self._subscribe_to_data_events(container, data_handler)
        
        # Initialize all containers
        for container in containers:
            self._initialize_container(container)
        
        # Run single market data pass (emits events to all containers)
        while data_handler.update_bars():
            pass  # Bar events are handled by subscribers
        
        # Collect results from all containers
        return [self._evaluate_container_performance(container) 
                for container in containers]
```

### 4. Memory Management

- **Shared Data Handler**: All parameter combinations share a single, read-only data handler
- **Memory Monitoring**: System tracks memory usage and can adjust batch size dynamically
- **Garbage Collection**: Explicit cleanup after each batch
- **Memory Limit Configuration**: User-defined memory constraints for different hardware environments

## Command-Line Interface

```
$ python optimize.py --batch-mode=auto --memory-limit=8000
```

Available options:
- `--batch-mode`: `auto`, `single`, `all`, or `custom`
- `--batch-size`: Number of parameter sets per batch (for custom mode)
- `--memory-limit`: Memory limit in MB

## Configuration

```yaml
optimization:
  batch_mode: auto  # single, all, auto, custom
  batch_size: 100   # Only used in custom mode
  memory_limit: 8000  # MB
  parallel_workers: 4  # CPU cores to use
```

## Backward Compatibility

This system maintains complete backward compatibility with the existing sequential approach. The default setting (batch_size=1) will behave identically to the current implementation, while allowing gradual adoption of parallel processing for improved performance.

## Benefits

1. **Dramatic Speed Improvement**: 10-100x faster optimization for large parameter spaces
2. **Resource Efficiency**: Optimal utilization of available memory and CPU resources
3. **Flexible Configuration**: Adaptable to different hardware environments
4. **Backward Compatibility**: Can run in sequential mode exactly like the current system

By implementing this approach, we can transform optimization tasks that currently take hours into processes that complete in minutes, dramatically accelerating strategy development and research.
